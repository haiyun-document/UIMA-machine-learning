<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_29) on Sun Dec 04 00:56:57 UTC 2011 -->
<TITLE>
Overview (Hadoop-common 0.22.0 API)
</TITLE>

<META NAME="date" CONTENT="2011-12-04">

<LINK REL ="stylesheet" TYPE="text/css" HREF="stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="Overview (Hadoop-common 0.22.0 API)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Overview</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">Package</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">Class</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">Use</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="overview-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;PREV&nbsp;
&nbsp;NEXT</FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="index.html?overview-summary.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="overview-summary.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<CENTER>
<H1>
Hadoop-common 0.22.0 API
</H1>
</CENTER>
Hadoop is a distributed computing platform.
<P>
<B>See:</B>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<A HREF="#overview_description"><B>Description</B></A>
<P>

<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Core</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/package-summary.html">org.apache.hadoop</A></B></TD>
<TD>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/classification/package-summary.html">org.apache.hadoop.classification</A></B></TD>
<TD>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/conf/package-summary.html">org.apache.hadoop.conf</A></B></TD>
<TD>Configuration of system parameters.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/fs/package-summary.html">org.apache.hadoop.fs</A></B></TD>
<TD>An abstract file system API.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/fs/ftp/package-summary.html">org.apache.hadoop.fs.ftp</A></B></TD>
<TD>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/fs/kfs/package-summary.html">org.apache.hadoop.fs.kfs</A></B></TD>
<TD>A client for the Kosmos filesystem (KFS)</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/fs/permission/package-summary.html">org.apache.hadoop.fs.permission</A></B></TD>
<TD>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/fs/s3/package-summary.html">org.apache.hadoop.fs.s3</A></B></TD>
<TD>A distributed, block-based implementation of <A HREF="org/apache/hadoop/fs/FileSystem.html" title="class in org.apache.hadoop.fs"><CODE>FileSystem</CODE></A> that uses <a href="http://aws.amazon.com/s3">Amazon S3</a>
as a backing store.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/fs/s3native/package-summary.html">org.apache.hadoop.fs.s3native</A></B></TD>
<TD>
A distributed implementation of <A HREF="org/apache/hadoop/fs/FileSystem.html" title="class in org.apache.hadoop.fs"><CODE>FileSystem</CODE></A> for reading and writing files on
<a href="http://aws.amazon.com/s3">Amazon S3</a>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/io/package-summary.html">org.apache.hadoop.io</A></B></TD>
<TD>Generic i/o code for use when reading and writing data to the network,
to databases, and to files.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/io/compress/package-summary.html">org.apache.hadoop.io.compress</A></B></TD>
<TD>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/io/file/tfile/package-summary.html">org.apache.hadoop.io.file.tfile</A></B></TD>
<TD>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/io/nativeio/package-summary.html">org.apache.hadoop.io.nativeio</A></B></TD>
<TD>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/io/serializer/package-summary.html">org.apache.hadoop.io.serializer</A></B></TD>
<TD>
This package provides a mechanism for using different serialization frameworks
in Hadoop.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/io/serializer/avro/package-summary.html">org.apache.hadoop.io.serializer.avro</A></B></TD>
<TD>
This package provides Avro serialization in Hadoop.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/log/package-summary.html">org.apache.hadoop.log</A></B></TD>
<TD>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/metrics/package-summary.html">org.apache.hadoop.metrics</A></B></TD>
<TD>This package defines an API for reporting performance metric information.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/metrics/file/package-summary.html">org.apache.hadoop.metrics.file</A></B></TD>
<TD>Implementation of the metrics package that writes the metrics to a file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/metrics/ganglia/package-summary.html">org.apache.hadoop.metrics.ganglia</A></B></TD>
<TD>Implementation of the metrics package that sends metric data to 
<a href="http://ganglia.sourceforge.net/">Ganglia</a>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/metrics/spi/package-summary.html">org.apache.hadoop.metrics.spi</A></B></TD>
<TD>The Service Provider Interface for the Metrics API.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/net/package-summary.html">org.apache.hadoop.net</A></B></TD>
<TD>Network-related classes.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/record/package-summary.html">org.apache.hadoop.record</A></B></TD>
<TD>
    (DEPRECATED) Hadoop record I/O contains classes and a record description language
    translator for simplifying serialization and deserialization of records in a
    language-neutral manner.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/record/compiler/package-summary.html">org.apache.hadoop.record.compiler</A></B></TD>
<TD>
    (DEPRECATED) This package contains classes needed for code generation
    from the hadoop record compiler.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/record/compiler/ant/package-summary.html">org.apache.hadoop.record.compiler.ant</A></B></TD>
<TD>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/record/compiler/generated/package-summary.html">org.apache.hadoop.record.compiler.generated</A></B></TD>
<TD>
    (DEPRECATED) This package contains code generated by JavaCC from the
    Hadoop record syntax file rcc.jj.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/record/meta/package-summary.html">org.apache.hadoop.record.meta</A></B></TD>
<TD>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/security/package-summary.html">org.apache.hadoop.security</A></B></TD>
<TD>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/security/authorize/package-summary.html">org.apache.hadoop.security.authorize</A></B></TD>
<TD>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/security/token/package-summary.html">org.apache.hadoop.security.token</A></B></TD>
<TD>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/security/token/delegation/package-summary.html">org.apache.hadoop.security.token.delegation</A></B></TD>
<TD>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/util/package-summary.html">org.apache.hadoop.util</A></B></TD>
<TD>Common utilities.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/util/bloom/package-summary.html">org.apache.hadoop.util.bloom</A></B></TD>
<TD>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/util/hash/package-summary.html">org.apache.hadoop.util.hash</A></B></TD>
<TD>&nbsp;</TD>
</TR>
</TABLE>

<P>
&nbsp;
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>contrib: FailMon</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="org/apache/hadoop/contrib/failmon/package-summary.html">org.apache.hadoop.contrib.failmon</A></B></TD>
<TD>&nbsp;</TD>
</TR>
</TABLE>

<P>
&nbsp;<A NAME="overview_description"><!-- --></A>
<P>
Hadoop is a distributed computing platform.

<p>Hadoop primarily consists of the <a 
href="http://hadoop.apache.org/hdfs/">Hadoop Distributed FileSystem 
(HDFS)</a> and an 
implementation of the <a href="http://hadoop.apache.org/mapreduce/">
Map-Reduce</a> programming paradigm.</p>


<p>Hadoop is a software framework that lets one easily write and run applications 
that process vast amounts of data. Here's what makes Hadoop especially useful:</p>
<ul>
  <li>
    <b>Scalable</b>: Hadoop can reliably store and process petabytes.
  </li>
  <li>
    <b>Economical</b>: It distributes the data and processing across clusters 
    of commonly available computers. These clusters can number into the thousands 
    of nodes.
  </li>
  <li>
    <b>Efficient</b>: By distributing the data, Hadoop can process it in parallel 
    on the nodes where the data is located. This makes it extremely rapid.
  </li>
  <li>
    <b>Reliable</b>: Hadoop automatically maintains multiple copies of data and 
    automatically redeploys computing tasks based on failures.
  </li>
</ul>  

<h2>Requirements</h2>

<h3>Platforms</h3>

<ul>
  <li>
    Hadoop was been demonstrated on GNU/Linux clusters with 2000 nodes.
  </li>
  <li>
    Win32 is supported as a <i>development</i> platform. Distributed operation 
    has not been well tested on Win32, so this is not a <i>production</i> 
    platform.
  </li>  
</ul>
  
<h3>Requisite Software</h3>

<ol>
  <li>
    Java 1.6.x, preferably from 
    <a href="http://java.sun.com/javase/downloads/">Sun</a>. 
    Set <tt>JAVA_HOME</tt> to the root of your Java installation.
  </li>
  <li>
    ssh must be installed and sshd must be running to use Hadoop's
    scripts to manage remote Hadoop daemons.
  </li>
  <li>
    rsync may be installed to use Hadoop's scripts to manage remote
    Hadoop installations.
  </li>
</ol>

<h4>Additional requirements for Windows</h4>

<ol>
  <li>
    <a href="http://www.cygwin.com/">Cygwin</a> - Required for shell support in 
    addition to the required software above.
  </li>
</ol>
  
<h3>Installing Required Software</h3>

<p>If your platform does not have the required software listed above, you
will have to install it.</p>

<p>For example on Ubuntu Linux:</p>
<p><blockquote><pre>
$ sudo apt-get install ssh<br>
$ sudo apt-get install rsync<br>
</pre></blockquote></p>

<p>On Windows, if you did not install the required software when you
installed cygwin, start the cygwin installer and select the packages:</p>
<ul>
  <li>openssh - the "Net" category</li>
  <li>rsync - the "Net" category</li>
</ul>

<h2>Getting Started</h2>

<p>First, you need to get a copy of the Hadoop code.</p>

<p>Edit the file <tt>conf/hadoop-env.sh</tt> to define at least
<tt>JAVA_HOME</tt>.</p>

<p>Try the following command:</p>
<tt>bin/hadoop</tt>
<p>This will display the documentation for the Hadoop command script.</p>

<h2>Standalone operation</h2>

<p>By default, Hadoop is configured to run things in a non-distributed
mode, as a single Java process.  This is useful for debugging, and can
be demonstrated as follows:</p>
<tt>
mkdir input<br>
cp conf/*.xml input<br>
bin/hadoop jar hadoop-*-examples.jar grep input output 'dfs[a-z.]+'<br>
cat output/*
</tt>
<p>This will display counts for each match of the <a
href="http://java.sun.com/j2se/1.4.2/docs/api/java/util/regex/Pattern.html">
regular expression.</a></p>

<p>Note that input is specified as a <em>directory</em> containing input
files and that output is also specified as a directory where parts are
written.</p>

<h2>Distributed operation</h2>

To configure Hadoop for distributed operation you must specify the
following:

<ol>

<li>The NameNode (Distributed Filesystem master) host.  This is
specified with the configuration property <tt><a
 href="../core-default.html#fs.default.name">fs.default.name</a></tt>.
</li>

<li>The org.apache.hadoop.mapred.JobTracker (MapReduce master)
host and port.  This is specified with the configuration property
<tt><a
href="../mapred-default.html#mapred.job.tracker">mapred.job.tracker</a></tt>.
</li>

<li>A <em>slaves</em> file that lists the names of all the hosts in
the cluster.  The default slaves file is <tt>conf/slaves</tt>.

</ol>

<h3>Pseudo-distributed configuration</h3>

You can in fact run everything on a single host.  To run things this
way, put the following in:
<br/>
<br/>
conf/core-site.xml:
<xmp><configuration>

  <property>
    <name>fs.default.name</name>
    <value>hdfs://localhost/</value>
  </property>

</configuration></xmp>

conf/hdfs-site.xml:
<xmp><configuration>

  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>

</configuration></xmp>

conf/mapred-site.xml:
<xmp><configuration>

  <property>
    <name>mapred.job.tracker</name>
    <value>localhost:9001</value>
  </property>

</configuration></xmp>

<p>(We also set the HDFS replication level to 1 in order to
reduce warnings when running on a single node.)</p>

<p>Now check that the command <br><tt>ssh localhost</tt><br> does not
require a password.  If it does, execute the following commands:</p>

<p><tt>ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa<br>
cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
</tt></p>

<h3>Bootstrapping</h3>

<p>A new distributed filesystem must be formatted with the following
command, run on the master node:</p>

<p><tt>bin/hadoop namenode -format</tt></p>

<p>The Hadoop daemons are started with the following command:</p>

<p><tt>bin/start-all.sh</tt></p>

<p>Daemon log output is written to the <tt>logs/</tt> directory.</p>

<p>Input files are copied into the distributed filesystem as follows:</p>

<p><tt>bin/hadoop fs -put input input</tt></p>

<h3>Distributed execution</h3>

<p>Things are run as before, but output must be copied locally to
examine it:</p>

<tt>
bin/hadoop jar hadoop-*-examples.jar grep input output 'dfs[a-z.]+'<br>
bin/hadoop fs -get output output
cat output/*
</tt>

<p>When you're done, stop the daemons with:</p>

<p><tt>bin/stop-all.sh</tt></p>

<h3>Fully-distributed operation</h3>

<p>Fully distributed operation is just like the pseudo-distributed operation
described above, except, specify:</p>

<ol>

<li>The hostname or IP address of your master server in the value
for <tt><a
href="../core-default.html#fs.default.name">fs.default.name</a></tt>,
  as <tt><em>hdfs://master.example.com/</em></tt> in <tt>conf/core-site.xml</tt>.</li>

<li>The host and port of the your master server in the value
of <tt><a href="../mapred-default.html#mapred.job.tracker">mapred.job.tracker</a></tt>
as <tt><em>master.example.com</em>:<em>port</em></tt> in <tt>conf/mapred-site.xml</tt>.</li>

<li>Directories for <tt><a
href="../hdfs-default.html#dfs.name.dir">dfs.name.dir</a></tt> and
<tt><a href="../hdfs-default.html#dfs.data.dir">dfs.data.dir</a> 
in <tt>conf/hdfs-site.xml</tt>.
</tt>These are local directories used to hold distributed filesystem
data on the master node and slave nodes respectively.  Note
that <tt>dfs.data.dir</tt> may contain a space- or comma-separated
list of directory names, so that data may be stored on multiple local
devices.</li>

<li><tt><a href="../mapred-default.html#mapred.local.dir">mapred.local.dir</a></tt>
  in <tt>conf/mapred-site.xml</tt>, the local directory where temporary 
  MapReduce data is stored.  It also may be a list of directories.</li>

<li><tt><a
href="../mapred-default.html#mapred.map.tasks">mapred.map.tasks</a></tt>
and <tt><a
href="../mapred-default.html#mapred.reduce.tasks">mapred.reduce.tasks</a></tt> 
in <tt>conf/mapred-site.xml</tt>.
As a rule of thumb, use 10x the
number of slave processors for <tt>mapred.map.tasks</tt>, and 2x the
number of slave processors for <tt>mapred.reduce.tasks</tt>.</li>

</ol>

<p>Finally, list all slave hostnames or IP addresses in your
<tt>conf/slaves</tt> file, one per line.  Then format your filesystem
and start your cluster on your master node, as above.
<P>

<P>
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Overview</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">Package</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">Class</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">Use</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="overview-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;PREV&nbsp;
&nbsp;NEXT</FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="index.html?overview-summary.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="overview-summary.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>
Copyright &copy; 2009 The Apache Software Foundation
</BODY>
</HTML>
