<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>
<!-- Mandatory properties that are to be set and uncommented before running the tests -->

<property>
  <name>test.system.hdrc.hadoophome</name>
  <value>$(TO_DO_HADOOP_INSTALL)/share/hadoop-current</value>
  <description> This is the path to the home directory of the hadoop deployment.
  </description>
</property>
<property>
  <name>test.system.hdrc.hadoopconfdir</name>
  <value>$(TO_DO_HADOOP_INSTALL)/conf/hadoop</value>
  <description> This is the path to the configuration directory of the hadoop
  cluster that is deployed.
  </description>
</property>

<property>
  <name>test.system.hdrc.tt.hostfile</name>
  <value>slaves.localcopy.txt</value>
  <description> File name containing the hostnames where the TaskTrackers are running.
  </description>
</property>

<property>
  <name>test.system.mr.clusterprocess.impl.class</name>
  <value>org.apache.hadoop.mapreduce.test.system.MRCluster$MRProcessManager</value>
  <description>
  Cluster process manager for the Mapreduce subsystem of the cluster. The value
  org.apache.hadoop.mapreduce.test.system.MRCluster$MultiMRProcessManager can
  be used to enable multi user support.
  </description>
</property>

<property>
   <name>test.system.hdrc.deployed.scripts.dir</name>
   <value>./src/test/system/scripts</value>
   <description>
     This directory hosts the scripts in the deployed location where
     the system test client runs.
   </description>
</property>

<property>
  <name>test.system.hdrc.hadoopnewconfdir</name>
  <value>$(TO_DO_GLOBAL_TMP_DIR)/newconf</value>
  <description>
  The directory where the new config files will be copied to in all
  the clusters is pointed out this directory. 
  </description>
</property>

<property>
  <name>test.system.hdrc.suspend.cmd</name>
  <value>kill -SIGSTOP</value>
  <description>
    Command for suspending the given process.
  </description>
</property>

<property>
  <name>test.system.hdrc.resume.cmd</name>
  <value>kill -SIGCONT</value>
  <description>
  Command for resuming the given suspended process.
  </description>
</property>
<property>
  <name>test.system.hdrc.hadoop.local.confdir</name>
  <value>$(TO_DO_GLOBAL_TMP_DIR)/localconf</value>
  <description>
    A local directory where a new config file is placed before
    being pushed into new config location on the cluster.
  </description>
</property>

<!-- Mandatory keys to be set for the multi user support to be enabled.  -->

 <property>
  <name>test.system.mr.clusterprocess.impl.class</name>
  <value>org.apache.hadoop.mapreduce.test.system.MRCluster$MultiMRProcessManager</value>
  <description>
    Enabling multi user based cluster process manger.
  </description>
</property>

<property>
  <name>test.system.hdrc.multi-user.list.path</name>
  <value>$(TO_DO_HADOOP_INSTALL)/conf/hadoop/proxyusers</value>
  <description>
  Multi user list for creating the proxy users.
  </description>
</property>

<property>
  <name>test.system.hdrc.multi-user.binary.path</name>
  <value>$(TO_DO_HADOOP_INSTALL)/conf/hadoop/runAs</value>
  <description>
    Local file system path on gate way to cluster-controller binary including the binary name.
    To build the binary the following commands need to be executed:
     % ant run-as -Drun-as.hadoop.home.dir=(HADOOP_HOME of setup cluster)
     % cp build-fi/system/c++-build/runAs test.system.hdrc.multi-user.binary.path
    Location of the cluster is important security precaution.
    The binary should be owned by root and test user group permission should be set such a
    way that it can be executed by binary. Example usage would be:
     % sudo chown root binary
     % sudo chmod 6511 binary
    Change permission appropriately to make it more secure.
  </description>
</property>

<property>
  <name>test.system.hdrc.multi-user.managinguser.jobtracker</name>
  <value>*</value>
  <description>
    User value for managing the particular daemon, please note that these user should be
    present on gateways also, an example configuration for the above would be 
    key name = test.system.hdrc.multi-user.managinguser.jobtracker
    key value = guest
    Please note the daemon names are all lower case, corresponding to hadoop-daemon.sh command.
  </description>
</property>
<property>
  <name>test.system.hdrc.multi-user.managinguser.tasktracker</name>
  <value>*</value>
</property>
 
</configuration>
