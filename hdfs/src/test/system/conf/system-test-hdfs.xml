<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
<!-- Mandatory properties that are to be set and uncommented before running the tests -->

<property>
  <name>test.system.hdrc.hadoophome</name>
  <value>$(TO_DO_HADOOP_INSTALL)/share/hadoop-current</value>
  <description> This is the path to the home directory of the hadoop deployment.
  </description>
</property>
<property>
  <name>test.system.hdrc.hadoopconfdir</name>
  <value>$(TO_DO_HADOOP_INSTALL)/conf/hadoop</value>
  <description> This is the path to the configuration directory of the hadoop
  cluster that is deployed.
  </description>
</property>

<property>
  <name>test.system.hdrc.dn.hostfile</name>
  <value>slaves.localcopy.txt</value>
  <description> File name containing the hostnames where the DataNodes are running.
  </description>
</property>

<property>
  <name>test.system.hdfs.clusterprocess.impl.class</name>
  <value>org.apache.hadoop.hdfs.test.system.HDFSCluster$HDFSProcessManager</value>
  <description>
  Cluster process manager for the Hdfs subsystem of the cluster. The value
  org.apache.hadoop.hdfs.test.system.HDFSCluster$MultiUserHDFSProcessManager can
  be used to enable multi user support.
  </description>
</property>

<property>
   <name>test.system.hdrc.deployed.scripts.dir</name>
   <value>./src/test/system/scripts</value>
   <description>
     This directory hosts the scripts in the deployed location where
     the system test client runs.
   </description>
</property>

<property>
  <name>test.system.hdrc.hadoopnewconfdir</name>
  <value>$(TO_DO_GLOBAL_TMP_DIR)/newconf</value>
  <description>
  The directory where the new config files will be copied to in all
  the clusters is pointed out this directory. 
  </description>
</property>

<property>
  <name>test.system.hdrc.suspend.cmd</name>
  <value>kill -SIGSTOP</value>
  <description>
    Command for suspending the given process.
  </description>
</property>

<property>
  <name>test.system.hdrc.resume.cmd</name>
  <value>kill -SIGCONT</value>
  <description>
  Command for resuming the given suspended process.
  </description>
</property>
<property>
  <name>test.system.hdrc.hadoop.local.confdir</name>
  <value>$(TO_DO_GLOBAL_TMP_DIR)/localconf</value>
  <description>
    A local directory where a new config file is placed before
    being pushed into new config location on the cluster.
  </description>
</property>

<!-- Mandatory keys to be set for the multi user support to be enabled.  -->

<property>
  <name>test.system.hdfs.clusterprocess.impl.class</name>
  <value>org.apache.hadoop.hdfs.test.system.HDFSCluster$MultiUserHDFSProcessManager</value>
  <description>
    Enabling multi user based cluster process manger.
  </description>
</property>
<property>
  <name>test.system.hdrc.multi-user.list.path</name>
  <value>$(TO_DO_HADOOP_INSTALL)/conf/hadoop/proxyusers</value>
  <description>
  Multi user list for creating the proxy users.
  </description>
</property>
<property>
  <name>test.system.hdrc.multi-user.binary.path</name>
  <value>$(TO_DO_HADOOP_INSTALL)/conf/hadoop/runAs</value>
  <description>
    Local file system path on gate way to cluster-controller binary including the binary name.
    To build the binary the following commands need to be executed:
     % ant run-as -Drun-as.hadoop.home.dir=(HADOOP_HOME of setup cluster)
     % cp build-fi/system/c++-build/runAs test.system.hdrc.multi-user.binary.path
    Location of the cluster is important security precaution.
    The binary should be owned by root and test user group permission should be set such a
    way that it can be executed by binary. Example usage would be:
     % sudo chown root binary
     % sudo chmod 6511 binary
    Change permission appropriately to make it more secure.
  </description>
</property>
<property>
  <name>test.system.hdrc.multi-user.managinguser.namenode</name>
  <value>*</value>
  <description>
    User value for managing the particular daemon, please note that these user should be
    present on gateways also, an example configuration for the above would be 
    key name = test.system.hdrc.multi-user.managinguser.namenode
    key value = guest
    Please note the daemon names are all lower case, corresponding to hadoop-daemon.sh command.
  </description>
</property>
<property>
  <name>test.system.hdrc.multi-user.managinguser.datanode</name>
  <value>*</value>
</property>
 
</configuration>
