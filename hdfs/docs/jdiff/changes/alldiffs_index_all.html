<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Frameset//EN""http://www.w3.org/TR/REC-html40/frameset.dtd">
<HTML>
<HEAD>
<meta name="generator" content="JDiff v1.0.9">
<!-- Generated by the JDiff Javadoc doclet -->
<!-- (http://www.jdiff.org) -->
<meta name="description" content="JDiff is a Javadoc doclet which generates an HTML report of all the packages, classes, constructors, methods, and fields which have been removed, added or changed in any way, including their documentation, when two APIs are compared.">
<meta name="keywords" content="diff, jdiff, javadiff, java diff, java difference, API difference, difference between two APIs, API diff, Javadoc, doclet">
<TITLE>
All Differences Index
</TITLE>
<LINK REL="stylesheet" TYPE="text/css" HREF="../stylesheet-jdiff.css" TITLE="Style">
</HEAD>
<BODY>
<a NAME="topheader"></a>
<table summary="Index for All Differences" width="100%" border="0" cellspacing="0" cellpadding="0">
  <tr>
  <td bgcolor="#FFFFCC">
<font size="+1"><a href="alldiffs_index_all.html" class="staysblack">All Differences</a></font>
  </td>
  </tr>
  <tr>
  <td bgcolor="#FFFFFF">
  <FONT SIZE="-1">
<A HREF="alldiffs_index_removals.html" class="hiddenlink">Removals</A>
  </FONT>
  </td>
  </tr>
  <tr>
  <td bgcolor="#FFFFFF">
  <FONT SIZE="-1">
<A HREF="alldiffs_index_additions.html"class="hiddenlink">Additions</A>
  </FONT>
  </td>
  </tr>
  <tr>
  <td bgcolor="#FFFFFF">
  <FONT SIZE="-1">
<A HREF="alldiffs_index_changes.html"class="hiddenlink">Changes</A>
  </FONT>
  </td>
  </tr>
  <tr>
  <td>
<font size="-2"><b>Bold</b>&nbsp;is&nbsp;New,&nbsp;<strike>strike</strike>&nbsp;is&nbsp;deleted</font>
  </td>
  </tr>
</table><br>
<!-- Method abandonBlock -->
<A NAME="A"></A>
<br><font size="+2">A</font>&nbsp;
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>abandonBlock</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.abandonBlock_changed(org.apache.hadoop.hdfs.protocol.Block, java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>Block, String, String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method abandonBlock -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.abandonBlock_changed(org.apache.hadoop.hdfs.protocol.Block, java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>Block, String, String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Field ACT_CHECKPOINT -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.ACT_CHECKPOINT" class="hiddenlink" target="rightframe">ACT_CHECKPOINT</A>
</nobr><br>
<!-- Field ACT_SHUTDOWN -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.ACT_SHUTDOWN" class="hiddenlink" target="rightframe">ACT_SHUTDOWN</A>
</nobr><br>
<!-- Field ACT_UNKNOWN -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.ACT_UNKNOWN" class="hiddenlink" target="rightframe">ACT_UNKNOWN</A>
</nobr><br>
<!-- Method addBlock -->
<i>addBlock</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock_changed(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo[])" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String, Block, DatanodeInfo[]</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method addBlock -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock_changed(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo[])" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String, Block, DatanodeInfo[]</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method adjustCrcChannelPosition -->
<i>adjustCrcChannelPosition</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.adjustCrcChannelPosition_added(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, BlockWriteStreams, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method adjustCrcChannelPosition -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.adjustCrcChannelPosition_added(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, BlockWriteStreams, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method append -->
<i>append</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.append_changed(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method append -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.append_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method append -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.append_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Field AUDIT_FORMAT -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.AUDIT_FORMAT" class="hiddenlink" target="rightframe"><strike>AUDIT_FORMAT</strike></A>
</nobr><br>
<!-- Field BACKUP -->
<A NAME="B"></A>
<br><font size="+2">B</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.HdfsConstants.StartupOption.html#org.apache.hadoop.hdfs.server.common.HdfsConstants.StartupOption.BACKUP" class="hiddenlink" target="rightframe">BACKUP</A>
</nobr><br>
<!-- Class BackupNode -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#BackupNode" class="hiddenlink" target="rightframe"><b>BackupNode</b></A><br>
<!-- Class BackupStorage -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#BackupStorage" class="hiddenlink" target="rightframe"><b>BackupStorage</b></A><br>
<!-- Class Block -->
<A HREF="org.apache.hadoop.hdfs.protocol.Block.html" class="hiddenlink" target="rightframe">Block</A><br>
<!-- Field BLOCK_FILE_PREFIX -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.BLOCK_FILE_PREFIX" class="hiddenlink" target="rightframe">BLOCK_FILE_PREFIX</A>
</nobr><br>
<!-- Field blockFilePattern -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.blockFilePattern" class="hiddenlink" target="rightframe">blockFilePattern</A>
</nobr><br>
<!-- Class BlockListAsLongs -->
<i>BlockListAsLongs</i><br>
&nbsp;&nbsp;<A HREF="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.protocol</A><br>
<!-- Constructor BlockListAsLongs -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.html#org.apache.hadoop.hdfs.protocol.BlockListAsLongs.ctor_added(java.util.List, java.util.List)" class="hiddenlink" target="rightframe"><b>BlockListAsLongs</b>
(<code>List, List</code>)</A></nobr>&nbsp;constructor<br>
<!-- Constructor BlockListAsLongs -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.html#org.apache.hadoop.hdfs.protocol.BlockListAsLongs.ctor_added()" class="hiddenlink" target="rightframe"><b>BlockListAsLongs</b>
()</A></nobr>&nbsp;constructor<br>
<!-- Class BlockListAsLongs.BlockReportIterator -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#BlockListAsLongs.BlockReportIterator" class="hiddenlink" target="rightframe"><b>BlockListAsLongs.BlockReportIterator</b></A><br>
<!-- Class BlockManager -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#BlockManager" class="hiddenlink" target="rightframe"><b>BlockManager</b></A><br>
<!-- Class BlockMetaDataInfo -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#BlockMetaDataInfo" class="hiddenlink" target="rightframe"><strike>BlockMetaDataInfo</strike></A><br>
<!-- Class BlockMissingException -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#BlockMissingException" class="hiddenlink" target="rightframe"><b>BlockMissingException</b></A><br>
<!-- Class BlockPlacementPolicy -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#BlockPlacementPolicy" class="hiddenlink" target="rightframe"><b>BlockPlacementPolicy</b></A><br>
<!-- Class BlockPlacementPolicy.NotEnoughReplicasException -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#BlockPlacementPolicy.NotEnoughReplicasException" class="hiddenlink" target="rightframe"><b>BlockPlacementPolicy.NotEnoughReplicasException</b></A><br>
<!-- Class BlockPlacementPolicyDefault -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#BlockPlacementPolicyDefault" class="hiddenlink" target="rightframe"><b>BlockPlacementPolicyDefault</b></A><br>
<!-- Class BlockReader -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#BlockReader" class="hiddenlink" target="rightframe"><b>BlockReader</b></A><br>
<!-- Class BlockRecoveryCommand -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#BlockRecoveryCommand" class="hiddenlink" target="rightframe"><b>BlockRecoveryCommand</b></A><br>
<!-- Class BlockRecoveryCommand.RecoveringBlock -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#BlockRecoveryCommand.RecoveringBlock" class="hiddenlink" target="rightframe"><b>BlockRecoveryCommand.RecoveringBlock</b></A><br>
<!-- Field blocksTotal -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.blocksTotal" class="hiddenlink" target="rightframe"><strike>blocksTotal</strike></A>
</nobr><br>
<!-- Method byteArray2String -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.byteArray2String_added(byte[][])" class="hiddenlink" target="rightframe"><b>byteArray2String</b>
(<code>byte[][]</code>)</A></nobr><br>
<!-- Method bytes2byteArray -->
<i>bytes2byteArray</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.bytes2byteArray_added(byte[], byte)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>byte[], byte</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSUtil
</A></nobr><br>
<!-- Method bytes2byteArray -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.bytes2byteArray_added(byte[], int, byte)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>byte[], int, byte</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSUtil
</A></nobr><br>
<!-- Method bytes2String -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.bytes2String_added(byte[])" class="hiddenlink" target="rightframe"><b>bytes2String</b>
(<code>byte[]</code>)</A></nobr><br>
<!-- Method cancelDelegationToken -->
<A NAME="C"></A>
<br><font size="+2">C</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>cancelDelegationToken</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.cancelDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method cancelDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.cancelDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method cancelDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.cancelDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method cancelDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.cancelDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method cancelDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.cancelDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Class CancelDelegationTokenServlet -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#CancelDelegationTokenServlet" class="hiddenlink" target="rightframe"><b>CancelDelegationTokenServlet</b></A><br>
<!-- Field capacityRemainingGB -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.capacityRemainingGB" class="hiddenlink" target="rightframe"><strike>capacityRemainingGB</strike></A>
</nobr><br>
<!-- Field capacityTotalGB -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.capacityTotalGB" class="hiddenlink" target="rightframe"><strike>capacityTotalGB</strike></A>
</nobr><br>
<!-- Field capacityUsedGB -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.capacityUsedGB" class="hiddenlink" target="rightframe"><strike>capacityUsedGB</strike></A>
</nobr><br>
<!-- Method checkAndUpdate -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.checkAndUpdate_added(long, java.io.File, java.io.File, org.apache.hadoop.hdfs.server.datanode.FSDataset.FSVolume)" class="hiddenlink" target="rightframe"><b>checkAndUpdate</b>
(<code>long, File, File, FSVolume</code>)</A></nobr><br>
<!-- Method checkDiskError -->
<i>checkDiskError</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.checkDiskError_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Method checkDiskError -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.checkDiskError_removed(java.io.IOException)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>IOException</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Method checkDiskError -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.checkDiskError_added(java.lang.Exception)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Exception</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Method checkDiskError -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.checkDiskError_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Field CHECKPOINT -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.HdfsConstants.StartupOption.html#org.apache.hadoop.hdfs.server.common.HdfsConstants.StartupOption.CHECKPOINT" class="hiddenlink" target="rightframe">CHECKPOINT</A>
</nobr><br>
<!-- Class CheckpointCommand -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#CheckpointCommand" class="hiddenlink" target="rightframe"><b>CheckpointCommand</b></A><br>
<!-- Class CheckpointSignature -->
<i>CheckpointSignature</i><br>
&nbsp;&nbsp;<A HREF="org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.namenode</A><br>
<!-- Constructor CheckpointSignature -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.html#org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.ctor_added()" class="hiddenlink" target="rightframe"><b>CheckpointSignature</b>
()</A></nobr>&nbsp;constructor<br>
<!-- Class ChecksumDistributedFileSystem -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#ChecksumDistributedFileSystem" class="hiddenlink" target="rightframe"><strike>ChecksumDistributedFileSystem</strike></A><br>
<!-- Field ckptState -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.ckptState" class="hiddenlink" target="rightframe">ckptState</A>
</nobr><br>
<!-- Class ClientDatanodeProtocol -->
<A HREF="org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol.html" class="hiddenlink" target="rightframe"><i>ClientDatanodeProtocol</i></A><br>
<!-- Class ClientProtocol -->
<A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html" class="hiddenlink" target="rightframe"><i>ClientProtocol</i></A><br>
<!-- Method close -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html#org.apache.hadoop.hdfs.server.namenode.FSEditLog.close_removed()" class="hiddenlink" target="rightframe"><strike>close</strike>
()</A></nobr><br>
<!-- Method compare -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.GenerationStamp.html#org.apache.hadoop.hdfs.server.common.GenerationStamp.compare_removed(long, long)" class="hiddenlink" target="rightframe"><strike>compare</strike>
(<code>long, long</code>)</A></nobr><br>
<!-- Method complete -->
<i>complete</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.complete_changed(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String, Block</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method complete -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.complete_changed(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String, Block</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method completeFile -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile_changed(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">completeFile
(<code>String, String, Block</code>)</A></nobr><br>
<!-- Method concat -->
<i>concat</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.concat_added(java.lang.String, java.lang.String[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method concat -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.concat_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path, Path[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method concat -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.concat_added(java.lang.String, java.lang.String[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method concat -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concat_added(java.lang.String, java.lang.String[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method concat -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.concat_added(java.lang.String, java.lang.String[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Field CONTENT_LENGTH -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.StreamFile.html#org.apache.hadoop.hdfs.server.namenode.StreamFile.CONTENT_LENGTH" class="hiddenlink" target="rightframe">CONTENT_LENGTH</A>
</nobr><br>
<!-- Class ContentSummaryServlet -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#ContentSummaryServlet" class="hiddenlink" target="rightframe"><b>ContentSummaryServlet</b></A><br>
<!-- Method convertToArrayLongs -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.html#org.apache.hadoop.hdfs.protocol.BlockListAsLongs.convertToArrayLongs_removed(org.apache.hadoop.hdfs.protocol.Block[])" class="hiddenlink" target="rightframe"><strike>convertToArrayLongs</strike>
(<code>Block[]</code>)</A></nobr><br>
<!-- Method corruptPreUpgradeStorage -->
<i>corruptPreUpgradeStorage</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.corruptPreUpgradeStorage_removed(java.io.File)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>File</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.common.Storage
</A></nobr><br>
<!-- Method corruptPreUpgradeStorage -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataStorage.html#org.apache.hadoop.hdfs.server.datanode.DataStorage.corruptPreUpgradeStorage_removed(java.io.File)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>File</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataStorage
</A></nobr><br>
<!-- Method corruptPreUpgradeStorage -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage_removed(java.io.File)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>File</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSImage
</A></nobr><br>
<!-- Field corruptReplicas -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.corruptReplicas" class="hiddenlink" target="rightframe"><strike>corruptReplicas</strike></A>
</nobr><br>
<!-- Field count -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.QuotaExceededException.html#org.apache.hadoop.hdfs.protocol.QuotaExceededException.count" class="hiddenlink" target="rightframe">count</A>
</nobr><br>
<!-- Method create -->
<i>create</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.create_removed(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean, short, long, org.apache.hadoop.util.Progressable, int)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>String, FsPermission, boolean, short, long, Progressable, int</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method create -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.create_added(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, short, long, org.apache.hadoop.util.Progressable, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, FsPermission, EnumSet, boolean, short, long, Progressable, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method create -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.create_added(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, short, long, org.apache.hadoop.util.Progressable, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, FsPermission, EnumSet, short, long, Progressable, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method create -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.create_changed(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, org.apache.hadoop.io.EnumSetWritable, boolean, short, long)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, FsPermission, String, EnumSetWritable, boolean, short, long</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method create -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.create_changed(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, org.apache.hadoop.io.EnumSetWritable, boolean, short, long)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, FsPermission, String, EnumSetWritable, boolean, short, long</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method createDataNode -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode_added(java.lang.String[], org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)" class="hiddenlink" target="rightframe"><b>createDataNode</b>
(<code>String[], Configuration, SecureResources</code>)</A></nobr><br>
<!-- Method createEditLogFile -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html#org.apache.hadoop.hdfs.server.namenode.FSEditLog.createEditLogFile_removed(java.io.File)" class="hiddenlink" target="rightframe"><strike>createEditLogFile</strike>
(<code>File</code>)</A></nobr><br>
<!-- Method createInterDataNodeProtocolProxy -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.createInterDataNodeProtocolProxy_changed(org.apache.hadoop.hdfs.protocol.DatanodeID, org.apache.hadoop.conf.Configuration, int)" class="hiddenlink" target="rightframe">createInterDataNodeProtocolProxy
(<code>DatanodeID, Configuration, int</code>)</A></nobr><br>
<!-- Method createNonRecursive -->
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.createNonRecursive_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, int, short, long, org.apache.hadoop.util.Progressable)" class="hiddenlink" target="rightframe"><b>createNonRecursive</b>
(<code>Path, FsPermission, EnumSet, int, short, long, Progressable</code>)</A></nobr><br>
<!-- Method createRbw -->
<i>createRbw</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.createRbw_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method createRbw -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.createRbw_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method createSymlink -->
<i>createSymlink</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.createSymlink_added(java.lang.String, java.lang.String, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method createSymlink -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.createSymlink_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, FsPermission, boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method createSymlink -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.createSymlink_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.PermissionStatus, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, PermissionStatus, boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method createSymlink -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.createSymlink_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, FsPermission, boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method createTemporary -->
<i>createTemporary</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.createTemporary_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method createTemporary -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.createTemporary_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method createUri -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FileDataServlet.html#org.apache.hadoop.hdfs.server.namenode.FileDataServlet.createUri_changed(java.lang.String, org.apache.hadoop.hdfs.protocol.HdfsFileStatus, org.apache.hadoop.security.UserGroupInformation, org.apache.hadoop.hdfs.protocol.ClientProtocol, javax.servlet.http.HttpServletRequest, java.lang.String)" class="hiddenlink" target="rightframe">createUri
(<code>String, HdfsFileStatus, UserGroupInformation, ClientProtocol, HttpServletRequest, String</code>)</A></nobr><br>
<!-- Class DataNode -->
<A NAME="D"></A>
<br><font size="+2">D</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html" class="hiddenlink" target="rightframe">DataNode</A><br>
<!-- Class DatanodeCommand -->
<A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeCommand.html" class="hiddenlink" target="rightframe">DatanodeCommand</A><br>
<!-- Class DatanodeDescriptor -->
<i>DatanodeDescriptor</i><br>
&nbsp;&nbsp;<A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.namenode</A><br>
<!-- Constructor DatanodeDescriptor -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.ctor_removed(org.apache.hadoop.hdfs.protocol.DatanodeID, java.lang.String, java.lang.String, long, long, long, int)" class="hiddenlink" target="rightframe"><strike>DatanodeDescriptor</strike>
(<code>DatanodeID, String, String, long, long, long, int</code>)</A></nobr>&nbsp;constructor<br>
<!-- Constructor DatanodeDescriptor -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.ctor_removed(org.apache.hadoop.hdfs.protocol.DatanodeID, long, long, long, int)" class="hiddenlink" target="rightframe"><strike>DatanodeDescriptor</strike>
(<code>DatanodeID, long, long, long, int</code>)</A></nobr>&nbsp;constructor<br>
<!-- Constructor DatanodeDescriptor -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.ctor_added(org.apache.hadoop.hdfs.protocol.DatanodeID, java.lang.String, java.lang.String, long, long, long, int, int)" class="hiddenlink" target="rightframe"><b>DatanodeDescriptor</b>
(<code>DatanodeID, String, String, long, long, long, int, int</code>)</A></nobr>&nbsp;constructor<br>
<!-- Constructor DatanodeDescriptor -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.ctor_added(org.apache.hadoop.hdfs.protocol.DatanodeID, long, long, long, int, int)" class="hiddenlink" target="rightframe"><b>DatanodeDescriptor</b>
(<code>DatanodeID, long, long, long, int, int</code>)</A></nobr>&nbsp;constructor<br>
<!-- Class DatanodeInfo -->
<A HREF="org.apache.hadoop.hdfs.protocol.DatanodeInfo.html" class="hiddenlink" target="rightframe">DatanodeInfo</A><br>
<!-- Class DatanodeJspHelper -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html#DatanodeJspHelper" class="hiddenlink" target="rightframe"><b>DatanodeJspHelper</b></A><br>
<!-- Class DataNodeMetrics -->
<A HREF="org.apache.hadoop.hdfs.server.datanode.metrics.DataNodeMetrics.html" class="hiddenlink" target="rightframe">DataNodeMetrics</A><br>
<!-- Class DataNodeMXBean -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html#DataNodeMXBean" class="hiddenlink" target="rightframe"><b><i>DataNodeMXBean</i></b></A><br>
<!-- Class DatanodeProtocol -->
<A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.html" class="hiddenlink" target="rightframe"><i>DatanodeProtocol</i></A><br>
<!-- Class DatanodeRegistration -->
<A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.html" class="hiddenlink" target="rightframe">DatanodeRegistration</A><br>
<!-- Class DataStorage -->
<A HREF="org.apache.hadoop.hdfs.server.datanode.DataStorage.html" class="hiddenlink" target="rightframe">DataStorage</A><br>
<!-- Class DataTransferProtocol -->
<A HREF="org.apache.hadoop.hdfs.protocol.DataTransferProtocol.html" class="hiddenlink" target="rightframe"><i>DataTransferProtocol</i></A><br>
<!-- Class DataTransferProtocol.BlockConstructionStage -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DataTransferProtocol.BlockConstructionStage" class="hiddenlink" target="rightframe"><b>DataTransferProtocol.BlockConstructionStage</b></A><br>
<!-- Class DataTransferProtocol.Op -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DataTransferProtocol.Op" class="hiddenlink" target="rightframe"><b>DataTransferProtocol.Op</b></A><br>
<!-- Class DataTransferProtocol.PacketHeader -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DataTransferProtocol.PacketHeader" class="hiddenlink" target="rightframe"><b>DataTransferProtocol.PacketHeader</b></A><br>
<!-- Class DataTransferProtocol.PipelineAck -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DataTransferProtocol.PipelineAck" class="hiddenlink" target="rightframe"><b>DataTransferProtocol.PipelineAck</b></A><br>
<!-- Class DataTransferProtocol.Receiver -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DataTransferProtocol.Receiver" class="hiddenlink" target="rightframe"><b>DataTransferProtocol.Receiver</b></A><br>
<!-- Class DataTransferProtocol.Sender -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DataTransferProtocol.Sender" class="hiddenlink" target="rightframe"><b>DataTransferProtocol.Sender</b></A><br>
<!-- Class DataTransferProtocol.Status -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DataTransferProtocol.Status" class="hiddenlink" target="rightframe"><b>DataTransferProtocol.Status</b></A><br>
<!-- Field DEFAULT_BYTES_PER_CHECKSUM -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.FSConstants.html#org.apache.hadoop.hdfs.protocol.FSConstants.DEFAULT_BYTES_PER_CHECKSUM" class="hiddenlink" target="rightframe">DEFAULT_BYTES_PER_CHECKSUM</A>
</nobr><br>
<!-- Field DEFAULT_FILE_BUFFER_SIZE -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.FSConstants.html#org.apache.hadoop.hdfs.protocol.FSConstants.DEFAULT_FILE_BUFFER_SIZE" class="hiddenlink" target="rightframe">DEFAULT_FILE_BUFFER_SIZE</A>
</nobr><br>
<!-- Field DEFAULT_REPLICATION_FACTOR -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.FSConstants.html#org.apache.hadoop.hdfs.protocol.FSConstants.DEFAULT_REPLICATION_FACTOR" class="hiddenlink" target="rightframe">DEFAULT_REPLICATION_FACTOR</A>
</nobr><br>
<!-- Field DEFAULT_WRITE_PACKET_SIZE -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.FSConstants.html#org.apache.hadoop.hdfs.protocol.FSConstants.DEFAULT_WRITE_PACKET_SIZE" class="hiddenlink" target="rightframe">DEFAULT_WRITE_PACKET_SIZE</A>
</nobr><br>
<!-- Class DelegationTokenFetcher -->
<A HREF="pkg_org.apache.hadoop.hdfs.tools.html#DelegationTokenFetcher" class="hiddenlink" target="rightframe"><b>DelegationTokenFetcher</b></A><br>
<!-- Method delete -->
<i>delete</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.delete_removed(org.apache.hadoop.fs.Path)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Path</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method delete -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.delete_removed(org.apache.hadoop.fs.Path)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Path</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.HftpFileSystem
</A></nobr><br>
<!-- Method delete -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.delete_changed(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method delete -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.delete_changed(java.lang.String, boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method delete -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete_changed(java.lang.String, boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Class DeprecatedUTF8 -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#DeprecatedUTF8" class="hiddenlink" target="rightframe"><b>DeprecatedUTF8</b></A><br>
<!-- Method detachBlock -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.detachBlock_removed(org.apache.hadoop.hdfs.protocol.Block, int)" class="hiddenlink" target="rightframe"><strike>detachBlock</strike>
(<code>Block, int</code>)</A></nobr><br>
<!-- Field df -->
<i>df</i><br>
&nbsp;in&nbsp;
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.df" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.HftpFileSystem</A>
</nobr><br>
<!-- Field df -->
&nbsp;in&nbsp;
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.ListPathsServlet.html#org.apache.hadoop.hdfs.server.namenode.ListPathsServlet.df" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.namenode.ListPathsServlet</A>
</nobr><br>
<!-- Class DFSAdmin -->
<A HREF="org.apache.hadoop.hdfs.tools.DFSAdmin.html" class="hiddenlink" target="rightframe">DFSAdmin</A><br>
<!-- Class DFSck -->
<i>DFSck</i><br>
&nbsp;&nbsp;<A HREF="org.apache.hadoop.hdfs.tools.DFSck.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.tools</A><br>
<!-- Constructor DFSck -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSck.html#org.apache.hadoop.hdfs.tools.DFSck.ctor_added(org.apache.hadoop.conf.Configuration, java.io.PrintStream)" class="hiddenlink" target="rightframe"><b>DFSck</b>
(<code>Configuration, PrintStream</code>)</A></nobr>&nbsp;constructor<br>
<!-- Constructor DFSck -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSck.html#org.apache.hadoop.hdfs.tools.DFSck.ctor_changed(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe">DFSck
(<code>Configuration</code>)</A></nobr>&nbsp;constructor<br>
<!-- Class DFSClient -->
<i>DFSClient</i><br>
&nbsp;&nbsp;<A HREF="org.apache.hadoop.hdfs.DFSClient.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs</A><br>
<!-- Constructor DFSClient -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.ctor_changed(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe">DFSClient
(<code>Configuration</code>)</A></nobr>&nbsp;constructor<br>
<!-- Class DFSClient.BlockReader -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#DFSClient.BlockReader" class="hiddenlink" target="rightframe"><strike>DFSClient.BlockReader</strike></A><br>
<!-- Class DFSClient.DFSDataInputStream -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#DFSClient.DFSDataInputStream" class="hiddenlink" target="rightframe"><b>DFSClient.DFSDataInputStream</b></A><br>
<!-- Class DFSConfigKeys -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#DFSConfigKeys" class="hiddenlink" target="rightframe"><b>DFSConfigKeys</b></A><br>
<!-- Class DFSInputStream -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#DFSInputStream" class="hiddenlink" target="rightframe"><b>DFSInputStream</b></A><br>
<!-- Class DFSUtil -->
<A HREF="org.apache.hadoop.hdfs.DFSUtil.html" class="hiddenlink" target="rightframe">DFSUtil</A><br>
<!-- Class DFSUtil.ErrorSimulator -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#DFSUtil.ErrorSimulator" class="hiddenlink" target="rightframe"><b>DFSUtil.ErrorSimulator</b></A><br>
<!-- Class DirectoryListing -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DirectoryListing" class="hiddenlink" target="rightframe"><b>DirectoryListing</b></A><br>
<!-- Class DirectoryScanner -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html#DirectoryScanner" class="hiddenlink" target="rightframe"><b>DirectoryScanner</b></A><br>
<!-- Class DistributedFileSystem -->
<i>DistributedFileSystem</i><br>
&nbsp;&nbsp;<A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs</A><br>
<!-- Constructor DistributedFileSystem -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.ctor_changed(java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe">DistributedFileSystem
(<code>InetSocketAddress, Configuration</code>)</A></nobr>&nbsp;constructor<br>
<!-- Class DistributedFileSystem.DiskStatus -->
<i>DistributedFileSystem.DiskStatus</i><br>
&nbsp;&nbsp;<A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.DiskStatus.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs</A><br>
<!-- Constructor DistributedFileSystem.DiskStatus -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.DiskStatus.html#org.apache.hadoop.hdfs.DistributedFileSystem.DiskStatus.ctor_added(org.apache.hadoop.fs.FsStatus)" class="hiddenlink" target="rightframe"><b>DistributedFileSystem.DiskStatus</b>
(<code>FsStatus</code>)</A></nobr>&nbsp;constructor<br>
<!-- Field DN_KEEPALIVE_TIMEOUT -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.HdfsConstants.html#org.apache.hadoop.hdfs.server.common.HdfsConstants.DN_KEEPALIVE_TIMEOUT" class="hiddenlink" target="rightframe">DN_KEEPALIVE_TIMEOUT</A>
</nobr><br>
<!-- Field DNA_ACCESSKEYUPDATE -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.DNA_ACCESSKEYUPDATE" class="hiddenlink" target="rightframe">DNA_ACCESSKEYUPDATE</A>
</nobr><br>
<!-- Method doGet -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FsckServlet.html#org.apache.hadoop.hdfs.server.namenode.FsckServlet.doGet_changed(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)" class="hiddenlink" target="rightframe">doGet
(<code>HttpServletRequest, HttpServletResponse</code>)</A></nobr><br>
<!-- Method doWork -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.html#org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork_added()" class="hiddenlink" target="rightframe"><b>doWork</b>
()</A></nobr><br>
<!-- Class DSQuotaExceededException -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DSQuotaExceededException" class="hiddenlink" target="rightframe"><b>DSQuotaExceededException</b></A><br>
<!-- Field editLog -->
<A NAME="E"></A>
<br><font size="+2">E</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.editLog" class="hiddenlink" target="rightframe">editLog</A>
</nobr><br>
<!-- Method endCheckpoint -->
<i>endCheckpoint</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.endCheckpoint_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, CheckpointSignature</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method endCheckpoint -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.endCheckpoint_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, CheckpointSignature</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<!-- Method equals -->
<i>equals</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DatanodeInfo.html#org.apache.hadoop.hdfs.protocol.DatanodeInfo.equals_changed(java.lang.Object)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>Object</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.DatanodeInfo
</A></nobr><br>
<!-- Method equals -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.equals_changed(java.lang.Object)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>Object</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor
</A></nobr><br>
<!-- Method equals -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.html#org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.equals_changed(java.lang.Object)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>Object</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration
</A></nobr><br>
<!-- Method equalsWithWildcard -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.GenerationStamp.html#org.apache.hadoop.hdfs.server.common.GenerationStamp.equalsWithWildcard_removed(long, long)" class="hiddenlink" target="rightframe"><strike>equalsWithWildcard</strike>
(<code>long, long</code>)</A></nobr><br>
<!-- Method errorReport -->
<i>errorReport</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.errorReport_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, int, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method errorReport -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.errorReport_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, int, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<!-- Field exportedKeys -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.html#org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.exportedKeys" class="hiddenlink" target="rightframe">exportedKeys</A>
</nobr><br>
<!-- Field FATAL -->
<A NAME="F"></A>
<br><font size="+2">F</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.FATAL" class="hiddenlink" target="rightframe">FATAL</A>
</nobr><br>
<!-- Field FATAL_DISK_ERROR -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.FATAL_DISK_ERROR" class="hiddenlink" target="rightframe">FATAL_DISK_ERROR</A>
</nobr><br>
<!-- Method fileAsURI -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Util.html#org.apache.hadoop.hdfs.server.common.Util.fileAsURI_added(java.io.File)" class="hiddenlink" target="rightframe"><b>fileAsURI</b>
(<code>File</code>)</A></nobr><br>
<!-- Class FileDataServlet -->
<A HREF="org.apache.hadoop.hdfs.server.namenode.FileDataServlet.html" class="hiddenlink" target="rightframe">FileDataServlet</A><br>
<!-- Method filename2id -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.filename2id_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>filename2id</b>
(<code>String</code>)</A></nobr><br>
<!-- Field filesTotal -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.filesTotal" class="hiddenlink" target="rightframe"><strike>filesTotal</strike></A>
</nobr><br>
<!-- Method fsck -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.html#org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.fsck_changed()" class="hiddenlink" target="rightframe">fsck
()</A></nobr><br>
<!-- Class FsckServlet -->
<A HREF="org.apache.hadoop.hdfs.server.namenode.FsckServlet.html" class="hiddenlink" target="rightframe">FsckServlet</A><br>
<!-- Class FSClusterStats -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#FSClusterStats" class="hiddenlink" target="rightframe"><b><i>FSClusterStats</i></b></A><br>
<!-- Class FSConstants -->
<A HREF="org.apache.hadoop.hdfs.protocol.FSConstants.html" class="hiddenlink" target="rightframe"><i>FSConstants</i></A><br>
<!-- Class FSDataset -->
<A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html" class="hiddenlink" target="rightframe">FSDataset</A><br>
<!-- Class FSDatasetInterface -->
<A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html" class="hiddenlink" target="rightframe"><i>FSDatasetInterface</i></A><br>
<!-- Class FSDatasetMBean -->
<A HREF="org.apache.hadoop.hdfs.server.datanode.metrics.FSDatasetMBean.html" class="hiddenlink" target="rightframe"><i>FSDatasetMBean</i></A><br>
<!-- Class FSEditLog -->
<A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html" class="hiddenlink" target="rightframe">FSEditLog</A><br>
<!-- Class FSEditLogLoader -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#FSEditLogLoader" class="hiddenlink" target="rightframe"><b>FSEditLogLoader</b></A><br>
<!-- Class FSImage -->
<i>FSImage</i><br>
&nbsp;&nbsp;<A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.namenode</A><br>
<!-- Constructor FSImage -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.ctor_removed(java.io.File)" class="hiddenlink" target="rightframe"><strike>FSImage</strike>
(<code>File</code>)</A></nobr>&nbsp;constructor<br>
<!-- Class FSImageSerialization -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#FSImageSerialization" class="hiddenlink" target="rightframe"><b>FSImageSerialization</b></A><br>
<!-- Class FSInodeInfo -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#FSInodeInfo" class="hiddenlink" target="rightframe"><b><i>FSInodeInfo</i></b></A><br>
<!-- Class FSNamesystem -->
<A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html" class="hiddenlink" target="rightframe">FSNamesystem</A><br>
<!-- Class FSNamesystemMBean -->
<A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.html" class="hiddenlink" target="rightframe"><i>FSNamesystemMBean</i></A><br>
<!-- Class FSNamesystemMetrics -->
<i>FSNamesystemMetrics</i><br>
&nbsp;&nbsp;<A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.namenode.metrics</A><br>
<!-- Constructor FSNamesystemMetrics -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.ctor_changed(org.apache.hadoop.hdfs.server.namenode.FSNamesystem, org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe">FSNamesystemMetrics
(<code>FSNamesystem, Configuration</code>)</A></nobr>&nbsp;constructor<br>
<!-- Field fsNamesystemObject -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.fsNamesystemObject" class="hiddenlink" target="rightframe"><strike>fsNamesystemObject</strike></A>
</nobr><br>
<!-- Method fsync -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.fsync_changed(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">fsync
(<code>String, String</code>)</A></nobr><br>
<!-- Class GenerationStamp -->
<A NAME="G"></A>
<br><font size="+2">G</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<A HREF="org.apache.hadoop.hdfs.server.common.GenerationStamp.html" class="hiddenlink" target="rightframe">GenerationStamp</A><br>
<!-- Method getAction -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeCommand.html#org.apache.hadoop.hdfs.server.protocol.DatanodeCommand.getAction_changed()" class="hiddenlink" target="rightframe">getAction
()</A></nobr><br>
<!-- Method getAdditionalBlock -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock_changed(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, java.util.HashMap)" class="hiddenlink" target="rightframe">getAdditionalBlock
(<code>String, String, Block, HashMap</code>)</A></nobr><br>
<!-- Method getAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.html#org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.getAddress_added()" class="hiddenlink" target="rightframe"><b>getAddress</b>
()</A></nobr><br>
<!-- Method getBlockCapacity -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockCapacity_added()" class="hiddenlink" target="rightframe"><b>getBlockCapacity</b>
()</A></nobr><br>
<!-- Method getBlockId -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.getBlockId_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>getBlockId</b>
(<code>String</code>)</A></nobr><br>
<!-- Method getBlockKeys -->
<i>getBlockKeys</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockKeys_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method getBlockKeys -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.getBlockKeys_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<!-- Method getBlockListAsLongs -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.html#org.apache.hadoop.hdfs.protocol.BlockListAsLongs.getBlockListAsLongs_added()" class="hiddenlink" target="rightframe"><b>getBlockListAsLongs</b>
()</A></nobr><br>
<!-- Method getBlockLocations -->
<i>getBlockLocations</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getBlockLocations_changed(java.lang.String, long, long)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, long, long</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method getBlockLocations -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations_changed(java.lang.String, long, long)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, long, long</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method getBlockLocations -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations_removed(java.lang.String, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>String, long, long</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method getBlockLocations -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations_removed(java.lang.String, long, long, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>String, long, long, boolean</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method getBlockMetaDataInfo -->
<i>getBlockMetaDataInfo</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getBlockMetaDataInfo_removed(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Method getBlockMetaDataInfo -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.getBlockMetaDataInfo_removed(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol
</A></nobr><br>
<!-- Method getBlockReport -->
<i>getBlockReport</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.getBlockReport_changed()" class="hiddenlink" target="rightframe">type&nbsp;
()&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method getBlockReport -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.getBlockReport_changed()" class="hiddenlink" target="rightframe">type&nbsp;
()&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method getBlockReportIterator -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.html#org.apache.hadoop.hdfs.protocol.BlockListAsLongs.getBlockReportIterator_added()" class="hiddenlink" target="rightframe"><b>getBlockReportIterator</b>
()</A></nobr><br>
<!-- Method getBlockToken -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlock.html#org.apache.hadoop.hdfs.protocol.LocatedBlock.getBlockToken_added()" class="hiddenlink" target="rightframe"><b>getBlockToken</b>
()</A></nobr><br>
<!-- Method getCanonicalServiceName -->
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.getCanonicalServiceName_added()" class="hiddenlink" target="rightframe"><b>getCanonicalServiceName</b>
()</A></nobr><br>
<!-- Method getCapacity -->
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.DiskStatus.html#org.apache.hadoop.hdfs.DistributedFileSystem.DiskStatus.getCapacity_removed()" class="hiddenlink" target="rightframe"><strike>getCapacity</strike>
()</A></nobr><br>
<!-- Method getChannelPosition -->
<i>getChannelPosition</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.getChannelPosition_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, BlockWriteStreams</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method getChannelPosition -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.getChannelPosition_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, BlockWriteStreams</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method getContentSummary -->
<i>getContentSummary</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.getContentSummary_added(org.apache.hadoop.fs.Path)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.HftpFileSystem
</A></nobr><br>
<!-- Method getContentSummary -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getContentSummary_changed(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method getCorruptReplicaBlocks -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getCorruptReplicaBlocks_added()" class="hiddenlink" target="rightframe"><b>getCorruptReplicaBlocks</b>
()</A></nobr><br>
<!-- Method getCorruptReplicaBlocksCount -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getCorruptReplicaBlocksCount_removed()" class="hiddenlink" target="rightframe"><strike>getCorruptReplicaBlocksCount</strike>
()</A></nobr><br>
<!-- Method getDatanodeRegistration -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getDatanodeRegistration_added()" class="hiddenlink" target="rightframe"><b>getDatanodeRegistration</b>
()</A></nobr><br>
<!-- Method getDateFormat -->
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.getDateFormat_added()" class="hiddenlink" target="rightframe"><b>getDateFormat</b>
()</A></nobr><br>
<!-- Method getDeadNodes -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDeadNodes_added()" class="hiddenlink" target="rightframe"><b>getDeadNodes</b>
()</A></nobr><br>
<!-- Method getDecommissioningNodes -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDecommissioningNodes_added()" class="hiddenlink" target="rightframe"><b>getDecommissioningNodes</b>
()</A></nobr><br>
<!-- Method getDecomNodes -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDecomNodes_added()" class="hiddenlink" target="rightframe"><b>getDecomNodes</b>
()</A></nobr><br>
<!-- Method getDefaultPort -->
<i>getDefaultPort</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getDefaultPort_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method getDefaultPort -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.getDefaultPort_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.HftpFileSystem
</A></nobr><br>
<!-- Method getDelegationToken -->
<i>getDelegationToken</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getDelegationToken_added(org.apache.hadoop.io.Text)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Text</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method getDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getDelegationToken_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method getDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getDelegationToken_added(org.apache.hadoop.io.Text)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Text</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method getDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.getDelegationToken_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.HftpFileSystem
</A></nobr><br>
<!-- Method getDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getDelegationToken_added(org.apache.hadoop.io.Text)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Text</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method getDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDelegationToken_added(org.apache.hadoop.io.Text)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Text</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method getDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getDelegationToken_added(org.apache.hadoop.io.Text)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Text</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method getDelegationTokenSecretManager -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDelegationTokenSecretManager_added()" class="hiddenlink" target="rightframe"><b>getDelegationTokenSecretManager</b>
()</A></nobr><br>
<!-- Class GetDelegationTokenServlet -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#GetDelegationTokenServlet" class="hiddenlink" target="rightframe"><b>GetDelegationTokenServlet</b></A><br>
<!-- Method getDFSClient -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.StreamFile.html#org.apache.hadoop.hdfs.server.namenode.StreamFile.getDFSClient_changed(javax.servlet.http.HttpServletRequest)" class="hiddenlink" target="rightframe">getDFSClient
(<code>HttpServletRequest</code>)</A></nobr><br>
<!-- Method getDFSNameNodeAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDFSNameNodeAddress_removed()" class="hiddenlink" target="rightframe"><strike>getDFSNameNodeAddress</strike>
()</A></nobr><br>
<!-- Method getDiskStatus -->
<i>getDiskStatus</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getDiskStatus_changed()" class="hiddenlink" target="rightframe">type&nbsp;
()&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method getDiskStatus -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getDiskStatus_changed()" class="hiddenlink" target="rightframe">type&nbsp;
()&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method getEditLogSize -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.getEditLogSize_changed()" class="hiddenlink" target="rightframe">getEditLogSize
()</A></nobr><br>
<!-- Method getExcessBlocks -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getExcessBlocks_added()" class="hiddenlink" target="rightframe"><b>getExcessBlocks</b>
()</A></nobr><br>
<!-- Method getFileBlockLocations -->
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getFileBlockLocations_added(org.apache.hadoop.fs.Path, long, long)" class="hiddenlink" target="rightframe"><b>getFileBlockLocations</b>
(<code>Path, long, long</code>)</A></nobr><br>
<!-- Method getFileChecksum -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getFileChecksum_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>getFileChecksum</b>
(<code>String</code>)</A></nobr><br>
<!-- Method getFileInfo -->
<i>getFileInfo</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getFileInfo_changed(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method getFileInfo -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo_changed(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method getFileInfo -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo_changed(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method getFileLinkInfo -->
<i>getFileLinkInfo</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getFileLinkInfo_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method getFileLinkInfo -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileLinkInfo_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method getFileLinkInfo -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getFileLinkInfo_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method getFree -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFree_added()" class="hiddenlink" target="rightframe"><b>getFree</b>
()</A></nobr><br>
<!-- Method getFSNamesystem -->
<i>getFSNamesystem</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.getFSNamesystem_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSImage
</A></nobr><br>
<!-- Method getFSNamesystem -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFSNamesystem_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method getFSNamesystem -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.UpgradeObjectNamenode.html#org.apache.hadoop.hdfs.server.namenode.UpgradeObjectNamenode.getFSNamesystem_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.UpgradeObjectNamenode
</A></nobr><br>
<!-- Method getGenerationStamp -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.getGenerationStamp_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>getGenerationStamp</b>
(<code>String</code>)</A></nobr><br>
<!-- Method getHints -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getHints_removed(java.lang.String, long, long)" class="hiddenlink" target="rightframe"><strike>getHints</strike>
(<code>String, long, long</code>)</A></nobr><br>
<!-- Method getHostPortString -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getHostPortString_added(java.net.InetSocketAddress)" class="hiddenlink" target="rightframe"><b>getHostPortString</b>
(<code>InetSocketAddress</code>)</A></nobr><br>
<!-- Method getHttpAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.html#org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.getHttpAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getHttpAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method getHttpPort -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getHttpPort_added()" class="hiddenlink" target="rightframe"><b>getHttpPort</b>
()</A></nobr><br>
<!-- Method getHttpServerAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getHttpServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getHttpServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Class GetImageServlet -->
<A HREF="org.apache.hadoop.hdfs.server.namenode.GetImageServlet.html" class="hiddenlink" target="rightframe">GetImageServlet</A><br>
<!-- Method getInfoAddr -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getInfoAddr_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getInfoAddr</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method getInfoPort -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getInfoPort_added()" class="hiddenlink" target="rightframe"><b>getInfoPort</b>
()</A></nobr><br>
<!-- Method getInfoServer -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getInfoServer_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getInfoServer</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method getLastLocatedBlock -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlocks.html#org.apache.hadoop.hdfs.protocol.LocatedBlocks.getLastLocatedBlock_added()" class="hiddenlink" target="rightframe"><b>getLastLocatedBlock</b>
()</A></nobr><br>
<!-- Method getLinkTarget -->
<i>getLinkTarget</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getLinkTarget_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method getLinkTarget -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getLinkTarget_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method getLinkTarget -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getLinkTarget_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method getListing -->
<i>getListing</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getListing_changed(java.lang.String, byte[], boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, byte[], boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method getListing -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing_changed(java.lang.String, byte[], boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, byte[], boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method getListing -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getListing_changed(java.lang.String, byte[], boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, byte[], boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method getLiveNodes -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getLiveNodes_added()" class="hiddenlink" target="rightframe"><b>getLiveNodes</b>
()</A></nobr><br>
<!-- Method getName -->
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getName_removed()" class="hiddenlink" target="rightframe"><strike>getName</strike>
()</A></nobr><br>
<!-- Method getNamenode -->
<i>getNamenode</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getNamenode_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method getNamenode -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenode_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Method getNamenodeAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddress_added()" class="hiddenlink" target="rightframe"><b>getNamenodeAddress</b>
()</A></nobr><br>
<!-- Method getNameNodeAddrForClient -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getNameNodeAddrForClient_added()" class="hiddenlink" target="rightframe"><b>getNameNodeAddrForClient</b>
()</A></nobr><br>
<!-- Method getNamesystem -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getNamesystem_removed()" class="hiddenlink" target="rightframe"><strike>getNamesystem</strike>
()</A></nobr><br>
<!-- Method getNonDfsUsedSpace -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNonDfsUsedSpace_added()" class="hiddenlink" target="rightframe"><b>getNonDfsUsedSpace</b>
()</A></nobr><br>
<!-- Method getNumDeadDataNodes -->
<i>getNumDeadDataNodes</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNumDeadDataNodes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method getNumDeadDataNodes -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.getNumDeadDataNodes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean
</A></nobr><br>
<!-- Method getNumFailedVolumes -->
<i>getNumFailedVolumes</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.getNumFailedVolumes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method getNumFailedVolumes -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.metrics.FSDatasetMBean.html#org.apache.hadoop.hdfs.server.datanode.metrics.FSDatasetMBean.getNumFailedVolumes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.metrics.FSDatasetMBean
</A></nobr><br>
<!-- Method getNumLiveDataNodes -->
<i>getNumLiveDataNodes</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNumLiveDataNodes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method getNumLiveDataNodes -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.getNumLiveDataNodes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean
</A></nobr><br>
<!-- Method getOutputStreamIterator -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html#org.apache.hadoop.hdfs.server.namenode.FSEditLog.getOutputStreamIterator_added(org.apache.hadoop.hdfs.server.namenode.JournalStream.JournalType)" class="hiddenlink" target="rightframe"><b>getOutputStreamIterator</b>
(<code>JournalType</code>)</A></nobr><br>
<!-- Method getPendingDeletionBlocks -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPendingDeletionBlocks_added()" class="hiddenlink" target="rightframe"><b>getPendingDeletionBlocks</b>
()</A></nobr><br>
<!-- Method getPercentRemaining -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPercentRemaining_added()" class="hiddenlink" target="rightframe"><b>getPercentRemaining</b>
()</A></nobr><br>
<!-- Method getPercentUsed -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPercentUsed_added()" class="hiddenlink" target="rightframe"><b>getPercentUsed</b>
()</A></nobr><br>
<!-- Method getPreferredBlockSize -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getPreferredBlockSize_changed(java.lang.String)" class="hiddenlink" target="rightframe">getPreferredBlockSize
(<code>String</code>)</A></nobr><br>
<!-- Method getRandomDatanode -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getRandomDatanode_removed()" class="hiddenlink" target="rightframe"><strike>getRandomDatanode</strike>
()</A></nobr><br>
<!-- Method getRawCapacity -->
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getRawCapacity_changed()" class="hiddenlink" target="rightframe">getRawCapacity
()</A></nobr><br>
<!-- Method getRawUsed -->
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getRawUsed_changed()" class="hiddenlink" target="rightframe">getRawUsed
()</A></nobr><br>
<!-- Method getRemaining -->
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.DiskStatus.html#org.apache.hadoop.hdfs.DistributedFileSystem.DiskStatus.getRemaining_removed()" class="hiddenlink" target="rightframe"><strike>getRemaining</strike>
()</A></nobr><br>
<!-- Method getReplica -->
<i>getReplica</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.getReplica_added(long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method getReplica -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.getReplica_added(long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method getReplicaVisibleLength -->
<i>getReplicaVisibleLength</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol.html#org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol.getReplicaVisibleLength_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol
</A></nobr><br>
<!-- Method getReplicaVisibleLength -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getReplicaVisibleLength_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Method getReplicaVisibleLength -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.getReplicaVisibleLength_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method getReplicaVisibleLength -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.getReplicaVisibleLength_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method getRestoreFailedStorage -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.getRestoreFailedStorage_added()" class="hiddenlink" target="rightframe"><b>getRestoreFailedStorage</b>
()</A></nobr><br>
<!-- Method getRole -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getRole_added()" class="hiddenlink" target="rightframe"><b>getRole</b>
()</A></nobr><br>
<!-- Method getRpcPort -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getRpcPort_added()" class="hiddenlink" target="rightframe"><b>getRpcPort</b>
()</A></nobr><br>
<!-- Method getRpcServerAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getRpcServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getRpcServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method getSafemode -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getSafemode_added()" class="hiddenlink" target="rightframe"><b>getSafemode</b>
()</A></nobr><br>
<!-- Method getServerDefaults -->
<i>getServerDefaults</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getServerDefaults_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method getServerDefaults -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getServerDefaults_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method getServerDefaults -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getServerDefaults_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method getServerDefaults -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getServerDefaults_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method getServiceAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getServiceAddress_added(org.apache.hadoop.conf.Configuration, boolean)" class="hiddenlink" target="rightframe"><b>getServiceAddress</b>
(<code>Configuration, boolean</code>)</A></nobr><br>
<!-- Method getServiceRpcServerAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getServiceRpcServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getServiceRpcServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method getStats -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getStats_changed()" class="hiddenlink" target="rightframe">getStats
()</A></nobr><br>
<!-- Method getStatus -->
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getStatus_added(org.apache.hadoop.fs.Path)" class="hiddenlink" target="rightframe"><b>getStatus</b>
(<code>Path</code>)</A></nobr><br>
<!-- Method getStorageDirs -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs_added(org.apache.hadoop.conf.Configuration, java.lang.String)" class="hiddenlink" target="rightframe"><b>getStorageDirs</b>
(<code>Configuration, String</code>)</A></nobr><br>
<!-- Method getStreamingAddr -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getStreamingAddr_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getStreamingAddr</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method getThreads -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getThreads_added()" class="hiddenlink" target="rightframe"><b>getThreads</b>
()</A></nobr><br>
<!-- Method getTotal -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getTotal_added()" class="hiddenlink" target="rightframe"><b>getTotal</b>
()</A></nobr><br>
<!-- Method getTotalBlocks -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getTotalBlocks_added()" class="hiddenlink" target="rightframe"><b>getTotalBlocks</b>
()</A></nobr><br>
<!-- Method getTotalFiles -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getTotalFiles_added()" class="hiddenlink" target="rightframe"><b>getTotalFiles</b>
()</A></nobr><br>
<!-- Method getUsed -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getUsed_added()" class="hiddenlink" target="rightframe"><b>getUsed</b>
()</A></nobr><br>
<!-- Method getVersion -->
<i>getVersion</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getVersion_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Method getVersion -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getVersion_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method getVolumeFailures -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.getVolumeFailures_added()" class="hiddenlink" target="rightframe"><b>getVolumeFailures</b>
()</A></nobr><br>
<!-- Method getVolumeInfo -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getVolumeInfo_added()" class="hiddenlink" target="rightframe"><b>getVolumeInfo</b>
()</A></nobr><br>
<!-- Field GRANDFATHER_GENERATION_STAMP -->
<i>GRANDFATHER_GENERATION_STAMP</i><br>
&nbsp;in&nbsp;
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.GRANDFATHER_GENERATION_STAMP" class="hiddenlink" target="rightframe"><strike>org.apache.hadoop.hdfs.protocol.Block</strike></A>
</nobr><br>
<!-- Field GRANDFATHER_GENERATION_STAMP -->
&nbsp;in&nbsp;
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.GenerationStamp.html#org.apache.hadoop.hdfs.server.common.GenerationStamp.GRANDFATHER_GENERATION_STAMP" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.common.GenerationStamp</A>
</nobr><br>
<!-- Method hasEnoughResource -->
<A NAME="H"></A>
<br><font size="+2">H</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>hasEnoughResource</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.hasEnoughResource_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method hasEnoughResource -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.hasEnoughResource_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method hashCode -->
<i>hashCode</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DatanodeInfo.html#org.apache.hadoop.hdfs.protocol.DatanodeInfo.hashCode_changed()" class="hiddenlink" target="rightframe">type&nbsp;
()&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.DatanodeInfo
</A></nobr><br>
<!-- Method hashCode -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.hashCode_changed()" class="hiddenlink" target="rightframe">type&nbsp;
()&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor
</A></nobr><br>
<!-- Method hashCode -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.html#org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.hashCode_changed()" class="hiddenlink" target="rightframe">type&nbsp;
()&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration
</A></nobr><br>
<!-- Field HDFS_URI_SCHEME -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.FSConstants.html#org.apache.hadoop.hdfs.protocol.FSConstants.HDFS_URI_SCHEME" class="hiddenlink" target="rightframe">HDFS_URI_SCHEME</A>
</nobr><br>
<!-- Class HDFSConcat -->
<A HREF="pkg_org.apache.hadoop.hdfs.tools.html#HDFSConcat" class="hiddenlink" target="rightframe"><b>HDFSConcat</b></A><br>
<!-- Class HdfsConfiguration -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#HdfsConfiguration" class="hiddenlink" target="rightframe"><b>HdfsConfiguration</b></A><br>
<!-- Class HdfsConstants -->
<A HREF="org.apache.hadoop.hdfs.server.common.HdfsConstants.html" class="hiddenlink" target="rightframe"><i>HdfsConstants</i></A><br>
<!-- Class HdfsConstants.BlockUCState -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.common.html#HdfsConstants.BlockUCState" class="hiddenlink" target="rightframe"><b>HdfsConstants.BlockUCState</b></A><br>
<!-- Class HdfsConstants.NamenodeRole -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.common.html#HdfsConstants.NamenodeRole" class="hiddenlink" target="rightframe"><b>HdfsConstants.NamenodeRole</b></A><br>
<!-- Class HdfsConstants.ReplicaState -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.common.html#HdfsConstants.ReplicaState" class="hiddenlink" target="rightframe"><b>HdfsConstants.ReplicaState</b></A><br>
<!-- Class HdfsConstants.StartupOption -->
<A HREF="org.apache.hadoop.hdfs.server.common.HdfsConstants.StartupOption.html" class="hiddenlink" target="rightframe">HdfsConstants.StartupOption</A><br>
<!-- Class HdfsFileStatus -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#HdfsFileStatus" class="hiddenlink" target="rightframe"><b>HdfsFileStatus</b></A><br>
<!-- Class HdfsLocatedFileStatus -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#HdfsLocatedFileStatus" class="hiddenlink" target="rightframe"><b>HdfsLocatedFileStatus</b></A><br>
<!-- Field HFTP_DATE_FORMAT -->
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.HFTP_DATE_FORMAT" class="hiddenlink" target="rightframe">HFTP_DATE_FORMAT</A>
</nobr><br>
<!-- Field HFTP_SERVICE_NAME_KEY -->
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.HFTP_SERVICE_NAME_KEY" class="hiddenlink" target="rightframe">HFTP_SERVICE_NAME_KEY</A>
</nobr><br>
<!-- Field HFTP_TIMEZONE -->
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.HFTP_TIMEZONE" class="hiddenlink" target="rightframe">HFTP_TIMEZONE</A>
</nobr><br>
<!-- Class HftpFileSystem -->
<A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html" class="hiddenlink" target="rightframe">HftpFileSystem</A><br>
<!-- Class HsftpFileSystem.DummyTrustManager -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#HsftpFileSystem.DummyTrustManager" class="hiddenlink" target="rightframe"><b>HsftpFileSystem.DummyTrustManager</b></A><br>
<!-- Field httpAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.httpAddress" class="hiddenlink" target="rightframe">httpAddress</A>
</nobr><br>
<!-- Field httpServer -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.httpServer" class="hiddenlink" target="rightframe">httpServer</A>
</nobr><br>
<!-- Field imageDigest -->
<A NAME="I"></A>
<br><font size="+2">I</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.imageDigest" class="hiddenlink" target="rightframe">imageDigest</A>
</nobr><br>
<!-- Method initialize -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.initialize_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>initialize</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method initReplicaRecovery -->
<i>initReplicaRecovery</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.initReplicaRecovery_added(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>RecoveringBlock</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Method initReplicaRecovery -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.initReplicaRecovery_added(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>RecoveringBlock</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method initReplicaRecovery -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.initReplicaRecovery_added(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>RecoveringBlock</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method initReplicaRecovery -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.initReplicaRecovery_added(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>RecoveringBlock</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol
</A></nobr><br>
<!-- Class INodeSymlink -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#INodeSymlink" class="hiddenlink" target="rightframe"><b>INodeSymlink</b></A><br>
<!-- Method instantiateDataNode -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode_added(java.lang.String[], org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)" class="hiddenlink" target="rightframe"><b>instantiateDataNode</b>
(<code>String[], Configuration, SecureResources</code>)</A></nobr><br>
<!-- Class InterDatanodeProtocol -->
<A HREF="org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.html" class="hiddenlink" target="rightframe"><i>InterDatanodeProtocol</i></A><br>
<!-- Method invalidateBlock -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateBlock_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo)" class="hiddenlink" target="rightframe"><strike>invalidateBlock</strike>
(<code>Block, DatanodeInfo</code>)</A></nobr><br>
<!-- Method is203LayoutVersion -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.is203LayoutVersion_added(int)" class="hiddenlink" target="rightframe"><b>is203LayoutVersion</b>
(<code>int</code>)</A></nobr><br>
<!-- Method isConversionNeeded -->
<i>isConversionNeeded</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.isConversionNeeded_removed(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>StorageDirectory</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.common.Storage
</A></nobr><br>
<!-- Method isConversionNeeded -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataStorage.html#org.apache.hadoop.hdfs.server.datanode.DataStorage.isConversionNeeded_removed(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>StorageDirectory</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataStorage
</A></nobr><br>
<!-- Method isConversionNeeded -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.isConversionNeeded_removed(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>StorageDirectory</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSImage
</A></nobr><br>
<!-- Method isDirectory -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.isDirectory_removed(java.lang.String)" class="hiddenlink" target="rightframe"><strike>isDirectory</strike>
(<code>String</code>)</A></nobr><br>
<!-- Method isLastBlockComplete -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlocks.html#org.apache.hadoop.hdfs.protocol.LocatedBlocks.isLastBlockComplete_added()" class="hiddenlink" target="rightframe"><b>isLastBlockComplete</b>
()</A></nobr><br>
<!-- Method isMetaFilename -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.isMetaFilename_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>isMetaFilename</b>
(<code>String</code>)</A></nobr><br>
<!-- Method isPreUpgradableLayout -->
<i>isPreUpgradableLayout</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.isPreUpgradableLayout_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>StorageDirectory</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.common.Storage
</A></nobr><br>
<!-- Method isPreUpgradableLayout -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataStorage.html#org.apache.hadoop.hdfs.server.datanode.DataStorage.isPreUpgradableLayout_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>StorageDirectory</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataStorage
</A></nobr><br>
<!-- Method isPreUpgradableLayout -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.isPreUpgradableLayout_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>StorageDirectory</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSImage
</A></nobr><br>
<!-- Method isUpgradeFinalized -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.isUpgradeFinalized_added()" class="hiddenlink" target="rightframe"><b>isUpgradeFinalized</b>
()</A></nobr><br>
<!-- Method isValidRequestor -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.GetImageServlet.html#org.apache.hadoop.hdfs.server.namenode.GetImageServlet.isValidRequestor_added(java.lang.String, org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>isValidRequestor</b>
(<code>String, Configuration</code>)</A></nobr><br>
<!-- Method iterator -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.html#org.apache.hadoop.hdfs.protocol.BlockListAsLongs.iterator_added()" class="hiddenlink" target="rightframe"><b>iterator</b>
()</A></nobr><br>
<!-- Field JA_CHECKPOINT_TIME -->
<A NAME="J"></A>
<br><font size="+2">J</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.JA_CHECKPOINT_TIME" class="hiddenlink" target="rightframe">JA_CHECKPOINT_TIME</A>
</nobr><br>
<!-- Field JA_IS_ALIVE -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.JA_IS_ALIVE" class="hiddenlink" target="rightframe">JA_IS_ALIVE</A>
</nobr><br>
<!-- Field JA_JOURNAL -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.JA_JOURNAL" class="hiddenlink" target="rightframe">JA_JOURNAL</A>
</nobr><br>
<!-- Field JA_JSPOOL_START -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.JA_JSPOOL_START" class="hiddenlink" target="rightframe">JA_JSPOOL_START</A>
</nobr><br>
<!-- Class JMXGet -->
<A HREF="pkg_org.apache.hadoop.hdfs.tools.html#JMXGet" class="hiddenlink" target="rightframe"><b>JMXGet</b></A><br>
<!-- Method journal -->
<i>journal</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.journal_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, int, byte[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, int, int, byte[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method journal -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.journal_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, int, byte[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, int, int, byte[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<!-- Method journalSize -->
<i>journalSize</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.journalSize_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method journalSize -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.journalSize_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<!-- Class JspHelper -->
<i>JspHelper</i><br>
&nbsp;&nbsp;<A HREF="pkg_org.apache.hadoop.hdfs.server.common.html#JspHelper" class="hiddenlink" target="rightframe"><b>org.apache.hadoop.hdfs.server.common</b></A><br>
<!-- Class JspHelper -->
&nbsp;&nbsp;<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#JspHelper" class="hiddenlink" target="rightframe"><strike>JspHelper</strike></A><br>
<!-- Class KeyUpdateCommand -->
<A NAME="K"></A>
<br><font size="+2">K</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#KeyUpdateCommand" class="hiddenlink" target="rightframe"><b>KeyUpdateCommand</b></A><br>
<!-- Field LAYOUT_VERSIONS_203 -->
<A NAME="L"></A>
<br><font size="+2">L</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.LAYOUT_VERSIONS_203" class="hiddenlink" target="rightframe">LAYOUT_VERSIONS_203</A>
</nobr><br>
<!-- Class LayoutVersion -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#LayoutVersion" class="hiddenlink" target="rightframe"><b>LayoutVersion</b></A><br>
<!-- Class LayoutVersion.Feature -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#LayoutVersion.Feature" class="hiddenlink" target="rightframe"><b>LayoutVersion.Feature</b></A><br>
<!-- Method listCorruptFileBlocks -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.listCorruptFileBlocks_added(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe"><b>listCorruptFileBlocks</b>
(<code>String, String</code>)</A></nobr><br>
<!-- Method listLocatedStatus -->
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.listLocatedStatus_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.PathFilter)" class="hiddenlink" target="rightframe"><b>listLocatedStatus</b>
(<code>Path, PathFilter</code>)</A></nobr><br>
<!-- Method listPaths -->
<i>listPaths</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.listPaths_removed(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>String</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method listPaths -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.listPaths_added(java.lang.String, byte[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, byte[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method listPaths -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.listPaths_added(java.lang.String, byte[], boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, byte[], boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Class ListPathsServlet -->
<A HREF="org.apache.hadoop.hdfs.server.namenode.ListPathsServlet.html" class="hiddenlink" target="rightframe">ListPathsServlet</A><br>
<!-- Method listStorageDirectories -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.listStorageDirectories_added()" class="hiddenlink" target="rightframe"><b>listStorageDirectories</b>
()</A></nobr><br>
<!-- Method loadNamesystem -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>loadNamesystem</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Class LocatedBlock -->
<A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlock.html" class="hiddenlink" target="rightframe">LocatedBlock</A><br>
<!-- Class LocatedBlocks -->
<i>LocatedBlocks</i><br>
&nbsp;&nbsp;<A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlocks.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.protocol</A><br>
<!-- Constructor LocatedBlocks -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlocks.html#org.apache.hadoop.hdfs.protocol.LocatedBlocks.ctor_removed(long, java.util.List, boolean)" class="hiddenlink" target="rightframe"><strike>LocatedBlocks</strike>
(<code>long, List, boolean</code>)</A></nobr>&nbsp;constructor<br>
<!-- Constructor LocatedBlocks -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlocks.html#org.apache.hadoop.hdfs.protocol.LocatedBlocks.ctor_added(long, boolean, java.util.List, org.apache.hadoop.hdfs.protocol.LocatedBlock, boolean)" class="hiddenlink" target="rightframe"><b>LocatedBlocks</b>
(<code>long, boolean, List, LocatedBlock, boolean</code>)</A></nobr>&nbsp;constructor<br>
<!-- Constructor LocatedBlocks -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlocks.html#org.apache.hadoop.hdfs.protocol.LocatedBlocks.ctor_added()" class="hiddenlink" target="rightframe"><b>LocatedBlocks</b>
()</A></nobr>&nbsp;constructor<br>
<!-- Method locatedBlocks2Locations -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.locatedBlocks2Locations_added(org.apache.hadoop.hdfs.protocol.LocatedBlocks)" class="hiddenlink" target="rightframe"><b>locatedBlocks2Locations</b>
(<code>LocatedBlocks</code>)</A></nobr><br>
<!-- Method logOpenFile -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html#org.apache.hadoop.hdfs.server.namenode.FSEditLog.logOpenFile_changed(java.lang.String, org.apache.hadoop.hdfs.server.namenode.INodeFileUnderConstruction)" class="hiddenlink" target="rightframe">logOpenFile
(<code>String, INodeFileUnderConstruction</code>)</A></nobr><br>
<!-- Method logSync -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html#org.apache.hadoop.hdfs.server.namenode.FSEditLog.logSync_changed()" class="hiddenlink" target="rightframe">logSync
()</A></nobr><br>
<!-- Method logUpdateMasterKey -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.logUpdateMasterKey_added(org.apache.hadoop.security.token.delegation.DelegationKey)" class="hiddenlink" target="rightframe"><b>logUpdateMasterKey</b>
(<code>DelegationKey</code>)</A></nobr><br>
<!-- Method makeInstance -->
<A NAME="M"></A>
<br><font size="+2">M</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance_removed(java.lang.String[], org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><strike>makeInstance</strike>
(<code>String[], Configuration</code>)</A></nobr><br>
<!-- Field METADATA_EXTENSION -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.METADATA_EXTENSION" class="hiddenlink" target="rightframe">METADATA_EXTENSION</A>
</nobr><br>
<!-- Field metaFilePattern -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.metaFilePattern" class="hiddenlink" target="rightframe">metaFilePattern</A>
</nobr><br>
<!-- Field missingBlocks -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.missingBlocks" class="hiddenlink" target="rightframe"><strike>missingBlocks</strike></A>
</nobr><br>
<!-- Method mkdir -->
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.mkdir_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)" class="hiddenlink" target="rightframe"><b>mkdir</b>
(<code>Path, FsPermission</code>)</A></nobr><br>
<!-- Method mkdirs -->
<i>mkdirs</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.mkdirs_changed(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, FsPermission, boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method mkdirs -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs_changed(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, FsPermission, boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method mkdirs -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs_changed(java.lang.String, org.apache.hadoop.fs.permission.PermissionStatus, boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, PermissionStatus, boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method mkdirs -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.mkdirs_changed(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, FsPermission, boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method moveCurrent -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.moveCurrent_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe"><b>moveCurrent</b>
(<code>StorageDirectory</code>)</A></nobr><br>
<!-- Method moveLastCheckpoint -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.moveLastCheckpoint_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe"><b>moveLastCheckpoint</b>
(<code>StorageDirectory</code>)</A></nobr><br>
<!-- Class NameNode -->
<A NAME="N"></A>
<br><font size="+2">N</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>NameNode</i><br>
&nbsp;&nbsp;<A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.namenode</A><br>
<!-- Constructor NameNode -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.ctor_added(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.common.HdfsConstants.NamenodeRole)" class="hiddenlink" target="rightframe"><b>NameNode</b>
(<code>Configuration, NamenodeRole</code>)</A></nobr>&nbsp;constructor<br>
<!-- Field namenode -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.namenode" class="hiddenlink" target="rightframe"><strike>namenode</strike></A>
</nobr><br>
<!-- Class NameNodeActivityMBean -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.metrics.html#NameNodeActivityMBean" class="hiddenlink" target="rightframe"><b>NameNodeActivityMBean</b></A><br>
<!-- Class NameNodeActivtyMBean -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.metrics.html#NameNodeActivtyMBean" class="hiddenlink" target="rightframe"><strike>NameNodeActivtyMBean</strike></A><br>
<!-- Class NamenodeCommand -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#NamenodeCommand" class="hiddenlink" target="rightframe"><b>NamenodeCommand</b></A><br>
<!-- Class NamenodeFsck -->
<i>NamenodeFsck</i><br>
&nbsp;&nbsp;<A HREF="org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.namenode</A><br>
<!-- Constructor NamenodeFsck -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.html#org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.ctor_removed(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.namenode.NameNode, java.util.Map, javax.servlet.http.HttpServletResponse)" class="hiddenlink" target="rightframe"><strike>NamenodeFsck</strike>
(<code>Configuration, NameNode, Map, HttpServletResponse</code>)</A></nobr>&nbsp;constructor<br>
<!-- Class NamenodeFsck.FsckResult -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#NamenodeFsck.FsckResult" class="hiddenlink" target="rightframe"><strike>NamenodeFsck.FsckResult</strike></A><br>
<!-- Class NameNodeMetrics -->
<i>NameNodeMetrics</i><br>
&nbsp;&nbsp;<A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.namenode.metrics</A><br>
<!-- Constructor NameNodeMetrics -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.ctor_changed(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.common.HdfsConstants.NamenodeRole)" class="hiddenlink" target="rightframe">NameNodeMetrics
(<code>Configuration, NamenodeRole</code>)</A></nobr>&nbsp;constructor<br>
<!-- Class NameNodeMXBean -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#NameNodeMXBean" class="hiddenlink" target="rightframe"><b><i>NameNodeMXBean</i></b></A><br>
<!-- Class NamenodeProtocol -->
<A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html" class="hiddenlink" target="rightframe"><i>NamenodeProtocol</i></A><br>
<!-- Class NamenodeProtocols -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#NamenodeProtocols" class="hiddenlink" target="rightframe"><b><i>NamenodeProtocols</i></b></A><br>
<!-- Class NamenodeRegistration -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#NamenodeRegistration" class="hiddenlink" target="rightframe"><b>NamenodeRegistration</b></A><br>
<!-- Class NamespaceInfo -->
<A HREF="org.apache.hadoop.hdfs.server.protocol.NamespaceInfo.html" class="hiddenlink" target="rightframe">NamespaceInfo</A><br>
<!-- Field namesystem -->
<i>namesystem</i><br>
&nbsp;in&nbsp;
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.namesystem" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.namenode.FSImage</A>
</nobr><br>
<!-- Field namesystem -->
&nbsp;in&nbsp;
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.namesystem" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.namenode.NameNode</A>
</nobr><br>
<!-- Field needKeyUpdate -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.needKeyUpdate" class="hiddenlink" target="rightframe">needKeyUpdate</A>
</nobr><br>
<!-- Field newImageDigest -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.newImageDigest" class="hiddenlink" target="rightframe">newImageDigest</A>
</nobr><br>
<!-- Method nextGenerationStamp -->
<i>nextGenerationStamp</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp_removed(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method nextGenerationStamp -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.nextGenerationStamp_removed(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol
</A></nobr><br>
<!-- Class NodeRegistration -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#NodeRegistration" class="hiddenlink" target="rightframe"><b><i>NodeRegistration</i></b></A><br>
<!-- Field nodeRegistration -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.nodeRegistration" class="hiddenlink" target="rightframe">nodeRegistration</A>
</nobr><br>
<!-- Field NOTIFY -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.NOTIFY" class="hiddenlink" target="rightframe">NOTIFY</A>
</nobr><br>
<!-- Class NSQuotaExceededException -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#NSQuotaExceededException" class="hiddenlink" target="rightframe"><b>NSQuotaExceededException</b></A><br>
<!-- Method numCorruptReplicas -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.numCorruptReplicas_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe"><b>numCorruptReplicas</b>
(<code>Block</code>)</A></nobr><br>
<!-- Field numcreateSymlinkOps -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.numcreateSymlinkOps" class="hiddenlink" target="rightframe">numcreateSymlinkOps</A>
</nobr><br>
<!-- Method numDeadDataNodes -->
<i>numDeadDataNodes</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.numDeadDataNodes_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method numDeadDataNodes -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.numDeadDataNodes_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean
</A></nobr><br>
<!-- Field numExpiredHeartbeats -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.numExpiredHeartbeats" class="hiddenlink" target="rightframe">numExpiredHeartbeats</A>
</nobr><br>
<!-- Field numFileInfoOps -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.numFileInfoOps" class="hiddenlink" target="rightframe">numFileInfoOps</A>
</nobr><br>
<!-- Field numFilesDeleted -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.numFilesDeleted" class="hiddenlink" target="rightframe">numFilesDeleted</A>
</nobr><br>
<!-- Field numFilesInGetListingOps -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.numFilesInGetListingOps" class="hiddenlink" target="rightframe">numFilesInGetListingOps</A>
</nobr><br>
<!-- Field numgetLinkTargetOps -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.numgetLinkTargetOps" class="hiddenlink" target="rightframe">numgetLinkTargetOps</A>
</nobr><br>
<!-- Method numLiveDataNodes -->
<i>numLiveDataNodes</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.numLiveDataNodes_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method numLiveDataNodes -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.numLiveDataNodes_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean
</A></nobr><br>
<!-- Field OP_BLOCK_CHECKSUM -->
<A NAME="O"></A>
<br><font size="+2">O</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DataTransferProtocol.html#org.apache.hadoop.hdfs.protocol.DataTransferProtocol.OP_BLOCK_CHECKSUM" class="hiddenlink" target="rightframe">OP_BLOCK_CHECKSUM</A>
</nobr><br>
<!-- Field OP_COPY_BLOCK -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DataTransferProtocol.html#org.apache.hadoop.hdfs.protocol.DataTransferProtocol.OP_COPY_BLOCK" class="hiddenlink" target="rightframe">OP_COPY_BLOCK</A>
</nobr><br>
<!-- Field OP_READ_BLOCK -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DataTransferProtocol.html#org.apache.hadoop.hdfs.protocol.DataTransferProtocol.OP_READ_BLOCK" class="hiddenlink" target="rightframe">OP_READ_BLOCK</A>
</nobr><br>
<!-- Field OP_READ_METADATA -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DataTransferProtocol.html#org.apache.hadoop.hdfs.protocol.DataTransferProtocol.OP_READ_METADATA" class="hiddenlink" target="rightframe">OP_READ_METADATA</A>
</nobr><br>
<!-- Field OP_REPLACE_BLOCK -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DataTransferProtocol.html#org.apache.hadoop.hdfs.protocol.DataTransferProtocol.OP_REPLACE_BLOCK" class="hiddenlink" target="rightframe">OP_REPLACE_BLOCK</A>
</nobr><br>
<!-- Field OP_STATUS_CHECKSUM_OK -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DataTransferProtocol.html#org.apache.hadoop.hdfs.protocol.DataTransferProtocol.OP_STATUS_CHECKSUM_OK" class="hiddenlink" target="rightframe">OP_STATUS_CHECKSUM_OK</A>
</nobr><br>
<!-- Field OP_STATUS_ERROR -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DataTransferProtocol.html#org.apache.hadoop.hdfs.protocol.DataTransferProtocol.OP_STATUS_ERROR" class="hiddenlink" target="rightframe">OP_STATUS_ERROR</A>
</nobr><br>
<!-- Field OP_STATUS_ERROR_ACCESS_TOKEN -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DataTransferProtocol.html#org.apache.hadoop.hdfs.protocol.DataTransferProtocol.OP_STATUS_ERROR_ACCESS_TOKEN" class="hiddenlink" target="rightframe">OP_STATUS_ERROR_ACCESS_TOKEN</A>
</nobr><br>
<!-- Field OP_STATUS_ERROR_CHECKSUM -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DataTransferProtocol.html#org.apache.hadoop.hdfs.protocol.DataTransferProtocol.OP_STATUS_ERROR_CHECKSUM" class="hiddenlink" target="rightframe">OP_STATUS_ERROR_CHECKSUM</A>
</nobr><br>
<!-- Field OP_STATUS_ERROR_EXISTS -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DataTransferProtocol.html#org.apache.hadoop.hdfs.protocol.DataTransferProtocol.OP_STATUS_ERROR_EXISTS" class="hiddenlink" target="rightframe">OP_STATUS_ERROR_EXISTS</A>
</nobr><br>
<!-- Field OP_STATUS_ERROR_INVALID -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DataTransferProtocol.html#org.apache.hadoop.hdfs.protocol.DataTransferProtocol.OP_STATUS_ERROR_INVALID" class="hiddenlink" target="rightframe">OP_STATUS_ERROR_INVALID</A>
</nobr><br>
<!-- Field OP_STATUS_SUCCESS -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DataTransferProtocol.html#org.apache.hadoop.hdfs.protocol.DataTransferProtocol.OP_STATUS_SUCCESS" class="hiddenlink" target="rightframe">OP_STATUS_SUCCESS</A>
</nobr><br>
<!-- Field OP_WRITE_BLOCK -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DataTransferProtocol.html#org.apache.hadoop.hdfs.protocol.DataTransferProtocol.OP_WRITE_BLOCK" class="hiddenlink" target="rightframe">OP_WRITE_BLOCK</A>
</nobr><br>
<!-- Method open -->
<i>open</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.open_added(java.lang.String, int, boolean, org.apache.hadoop.fs.FileSystem.Statistics)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, int, boolean, Statistics</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method open -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.open_added(java.lang.String, int, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, int, boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method open -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.open_changed(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method open -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html#org.apache.hadoop.hdfs.server.namenode.FSEditLog.open_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSEditLog
</A></nobr><br>
<!-- Package org.apache.hadoop.fs -->
<A HREF="changes-summary.html#org.apache.hadoop.fs" class="hiddenlink" target="rightframe"><b>org.apache.hadoop.fs</b></A><br>
<!-- Package org.apache.hadoop.hdfs -->
<A HREF="pkg_org.apache.hadoop.hdfs.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs</A><br>
<!-- Package org.apache.hadoop.hdfs.protocol -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.protocol</A><br>
<!-- Package org.apache.hadoop.hdfs.security.token.block -->
<A HREF="changes-summary.html#org.apache.hadoop.hdfs.security.token.block" class="hiddenlink" target="rightframe"><b>org.apache.hadoop.hdfs.security.token.block</b></A><br>
<!-- Package org.apache.hadoop.hdfs.security.token.delegation -->
<A HREF="changes-summary.html#org.apache.hadoop.hdfs.security.token.delegation" class="hiddenlink" target="rightframe"><b>org.apache.hadoop.hdfs.security.token.delegation</b></A><br>
<!-- Package org.apache.hadoop.hdfs.server.common -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.common.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.common</A><br>
<!-- Package org.apache.hadoop.hdfs.server.datanode -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.datanode</A><br>
<!-- Package org.apache.hadoop.hdfs.server.datanode.metrics -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.metrics.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.datanode.metrics</A><br>
<!-- Package org.apache.hadoop.hdfs.server.namenode -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.namenode</A><br>
<!-- Package org.apache.hadoop.hdfs.server.namenode.metrics -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.metrics.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.namenode.metrics</A><br>
<!-- Package org.apache.hadoop.hdfs.server.protocol -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.protocol</A><br>
<!-- Package org.apache.hadoop.hdfs.tools -->
<A HREF="pkg_org.apache.hadoop.hdfs.tools.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.tools</A><br>
<!-- Package org.apache.hadoop.hdfs.tools.offlineImageViewer -->
<A HREF="changes-summary.html#org.apache.hadoop.hdfs.tools.offlineImageViewer" class="hiddenlink" target="rightframe"><b>org.apache.hadoop.hdfs.tools.offlineImageViewer</b></A><br>
<!-- Package org.apache.hadoop.hdfs.util -->
<A HREF="changes-summary.html#org.apache.hadoop.hdfs.util" class="hiddenlink" target="rightframe"><b>org.apache.hadoop.hdfs.util</b></A><br>
<!-- Field pathName -->
<A NAME="P"></A>
<br><font size="+2">P</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.QuotaExceededException.html#org.apache.hadoop.hdfs.protocol.QuotaExceededException.pathName" class="hiddenlink" target="rightframe">pathName</A>
</nobr><br>
<!-- Field pendingReplicationBlocks -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.pendingReplicationBlocks" class="hiddenlink" target="rightframe"><strike>pendingReplicationBlocks</strike></A>
</nobr><br>
<!-- Method pickOneAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.pickOneAddress_removed(java.lang.String)" class="hiddenlink" target="rightframe"><strike>pickOneAddress</strike>
(<code>String</code>)</A></nobr><br>
<!-- Field PKT_HEADER_LEN -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.PKT_HEADER_LEN" class="hiddenlink" target="rightframe"><strike>PKT_HEADER_LEN</strike></A>
</nobr><br>
<!-- Method primitiveCreate -->
<i>primitiveCreate</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.primitiveCreate_added(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, short, long, org.apache.hadoop.util.Progressable, int, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, FsPermission, EnumSet, boolean, short, long, Progressable, int, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method primitiveCreate -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.primitiveCreate_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, int, short, long, org.apache.hadoop.util.Progressable, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path, FsPermission, EnumSet, int, short, long, Progressable, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method primitiveMkdir -->
<i>primitiveMkdir</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.primitiveMkdir_added(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, FsPermission</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method primitiveMkdir -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.primitiveMkdir_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path, FsPermission</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method printTopology -->
<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSAdmin.html#org.apache.hadoop.hdfs.tools.DFSAdmin.printTopology_added()" class="hiddenlink" target="rightframe"><b>printTopology</b>
()</A></nobr><br>
<!-- Field quota -->
<A NAME="Q"></A>
<br><font size="+2">Q</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.QuotaExceededException.html#org.apache.hadoop.hdfs.protocol.QuotaExceededException.quota" class="hiddenlink" target="rightframe">quota</A>
</nobr><br>
<!-- Class QuotaExceededException -->
<i>QuotaExceededException</i><br>
&nbsp;&nbsp;<A HREF="org.apache.hadoop.hdfs.protocol.QuotaExceededException.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.protocol</A><br>
<!-- Constructor QuotaExceededException -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.QuotaExceededException.html#org.apache.hadoop.hdfs.protocol.QuotaExceededException.ctor_removed(long, long, long, long)" class="hiddenlink" target="rightframe"><strike>QuotaExceededException</strike>
(<code>long, long, long, long</code>)</A></nobr>&nbsp;constructor<br>
<!-- Constructor QuotaExceededException -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.QuotaExceededException.html#org.apache.hadoop.hdfs.protocol.QuotaExceededException.ctor_added(long, long)" class="hiddenlink" target="rightframe"><b>QuotaExceededException</b>
(<code>long, long</code>)</A></nobr>&nbsp;constructor<br>
<!-- Constructor QuotaExceededException -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.QuotaExceededException.html#org.apache.hadoop.hdfs.protocol.QuotaExceededException.ctor_added()" class="hiddenlink" target="rightframe"><b>QuotaExceededException</b>
()</A></nobr>&nbsp;constructor<br>
<!-- Constructor QuotaExceededException -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.QuotaExceededException.html#org.apache.hadoop.hdfs.protocol.QuotaExceededException.ctor_changed(java.lang.String)" class="hiddenlink" target="rightframe">QuotaExceededException
(<code>String</code>)</A></nobr>&nbsp;constructor<br>
<!-- Method randomDataNode -->
<A NAME="R"></A>
<br><font size="+2">R</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.randomDataNode_removed()" class="hiddenlink" target="rightframe"><strike>randomDataNode</strike>
()</A></nobr><br>
<!-- Method read -->
<i>read</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DatanodeInfo.html#org.apache.hadoop.hdfs.protocol.DatanodeInfo.read_added(java.io.DataInput)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>DataInput</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.DatanodeInfo
</A></nobr><br>
<!-- Method read -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlock.html#org.apache.hadoop.hdfs.protocol.LocatedBlock.read_added(java.io.DataInput)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>DataInput</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.LocatedBlock
</A></nobr><br>
<!-- Field READ_TIMEOUT_EXTENSION -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.HdfsConstants.html#org.apache.hadoop.hdfs.server.common.HdfsConstants.READ_TIMEOUT_EXTENSION" class="hiddenlink" target="rightframe">READ_TIMEOUT_EXTENSION</A>
</nobr><br>
<!-- Method readFields -->
<i>readFields</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.common.GenerationStamp.html#org.apache.hadoop.hdfs.server.common.GenerationStamp.readFields_removed(java.io.DataInput)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>DataInput</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.common.GenerationStamp
</A></nobr><br>
<!-- Method readFields -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.common.StorageInfo.html#org.apache.hadoop.hdfs.server.common.StorageInfo.readFields_added(java.io.DataInput)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>DataInput</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.common.StorageInfo
</A></nobr><br>
<!-- Method readFields -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeCommand.html#org.apache.hadoop.hdfs.server.protocol.DatanodeCommand.readFields_changed(java.io.DataInput)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>DataInput</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeCommand
</A></nobr><br>
<!-- Method readId -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.readId_added(java.io.DataInput)" class="hiddenlink" target="rightframe"><b>readId</b>
(<code>DataInput</code>)</A></nobr><br>
<!-- Field readMetadataOp -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.metrics.DataNodeMetrics.html#org.apache.hadoop.hdfs.server.datanode.metrics.DataNodeMetrics.readMetadataOp" class="hiddenlink" target="rightframe"><strike>readMetadataOp</strike></A>
</nobr><br>
<!-- Method recoverAppend -->
<i>recoverAppend</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.recoverAppend_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method recoverAppend -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.recoverAppend_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method recoverBlock -->
<i>recoverBlock</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol.html#org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol.recoverBlock_removed(org.apache.hadoop.hdfs.protocol.Block, boolean, org.apache.hadoop.hdfs.protocol.DatanodeInfo[])" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, boolean, DatanodeInfo[]</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol
</A></nobr><br>
<!-- Method recoverBlock -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock_removed(org.apache.hadoop.hdfs.protocol.Block, boolean, org.apache.hadoop.hdfs.protocol.DatanodeInfo[])" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, boolean, DatanodeInfo[]</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Method recoverBlocks -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlocks_changed(java.util.Collection)" class="hiddenlink" target="rightframe">recoverBlocks
(<code>Collection</code>)</A></nobr><br>
<!-- Method recoverClose -->
<i>recoverClose</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.recoverClose_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method recoverClose -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.recoverClose_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method recoverLease -->
<i>recoverLease</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.recoverLease_added(org.apache.hadoop.fs.Path)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method recoverLease -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.recoverLease_added(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method recoverLease -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.recoverLease_added(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method recoverRbw -->
<i>recoverRbw</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.recoverRbw_added(org.apache.hadoop.hdfs.protocol.Block, long, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method recoverRbw -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.recoverRbw_added(org.apache.hadoop.hdfs.protocol.Block, long, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Class RecoveryInProgressException -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#RecoveryInProgressException" class="hiddenlink" target="rightframe"><b>RecoveryInProgressException</b></A><br>
<!-- Method refreshSuperUserGroupsConfiguration -->
<i>refreshSuperUserGroupsConfiguration</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.refreshSuperUserGroupsConfiguration_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method refreshSuperUserGroupsConfiguration -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSAdmin.html#org.apache.hadoop.hdfs.tools.DFSAdmin.refreshSuperUserGroupsConfiguration_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.tools.DFSAdmin
</A></nobr><br>
<!-- Method refreshUserToGroupsMappings -->
<i>refreshUserToGroupsMappings</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.refreshUserToGroupsMappings_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method refreshUserToGroupsMappings -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSAdmin.html#org.apache.hadoop.hdfs.tools.DFSAdmin.refreshUserToGroupsMappings_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.tools.DFSAdmin
</A></nobr><br>
<!-- Method register -->
<i>register</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.register_changed(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>NamenodeRegistration</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method register -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.register_removed(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>DatanodeRegistration</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol
</A></nobr><br>
<!-- Method register -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.register_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<!-- Method registerDatanode -->
<i>registerDatanode</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.registerDatanode_added(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>DatanodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method registerDatanode -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.registerDatanode_added(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>DatanodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol
</A></nobr><br>
<!-- Field registry -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.registry" class="hiddenlink" target="rightframe"><strike>registry</strike></A>
</nobr><br>
<!-- Method rename -->
<i>rename</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.rename_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, Rename[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method rename -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.rename_changed(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method rename -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.rename_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Options.Rename[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path, Path, Rename[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method rename -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.rename_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, Rename[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method rename -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.rename_changed(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method rename -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.rename_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, Rename[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method renameTo -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo_removed(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe"><strike>renameTo</strike>
(<code>String, String</code>)</A></nobr><br>
<!-- Method renewDelegationToken -->
<i>renewDelegationToken</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.renewDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method renewDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.renewDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method renewDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.renewDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method renewDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method renewDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.renewDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Class RenewDelegationTokenServlet -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#RenewDelegationTokenServlet" class="hiddenlink" target="rightframe"><b>RenewDelegationTokenServlet</b></A><br>
<!-- Method renewLease -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease_changed(java.lang.String)" class="hiddenlink" target="rightframe">renewLease
(<code>String</code>)</A></nobr><br>
<!-- Class Replica -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html#Replica" class="hiddenlink" target="rightframe"><b><i>Replica</i></b></A><br>
<!-- Class ReplicaInfo -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html#ReplicaInfo" class="hiddenlink" target="rightframe"><b>ReplicaInfo</b></A><br>
<!-- Class ReplicaNotFoundException -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html#ReplicaNotFoundException" class="hiddenlink" target="rightframe"><b>ReplicaNotFoundException</b></A><br>
<!-- Class ReplicaRecoveryInfo -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#ReplicaRecoveryInfo" class="hiddenlink" target="rightframe"><b>ReplicaRecoveryInfo</b></A><br>
<!-- Method restoreFailedStorage -->
<i>restoreFailedStorage</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.restoreFailedStorage_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method restoreFailedStorage -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.restoreFailedStorage_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method restoreFailedStorage -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.restoreFailedStorage_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method restoreFaileStorage -->
<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSAdmin.html#org.apache.hadoop.hdfs.tools.DFSAdmin.restoreFaileStorage_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>restoreFaileStorage</b>
(<code>String</code>)</A></nobr><br>
<!-- Field role -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.role" class="hiddenlink" target="rightframe">role</A>
</nobr><br>
<!-- Method rollEditLog -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog_changed()" class="hiddenlink" target="rightframe">rollEditLog
()</A></nobr><br>
<!-- Method rollFsImage -->
<i>rollFsImage</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.rollFsImage_changed(org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>CheckpointSignature</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method rollFsImage -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollFsImage_changed(org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>CheckpointSignature</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<!-- Field rpcAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.rpcAddress" class="hiddenlink" target="rightframe">rpcAddress</A>
</nobr><br>
<!-- Method run -->
<i>run</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.html#org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.run_removed(java.lang.String[])" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>String[]</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NamenodeFsck
</A></nobr><br>
<!-- Method run -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSck.html#org.apache.hadoop.hdfs.tools.DFSck.run_changed(java.lang.String[])" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String[]</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.tools.DFSck
</A></nobr><br>
<!-- Class SafeModeException -->
<A NAME="S"></A>
<br><font size="+2">S</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>SafeModeException</i><br>
&nbsp;&nbsp;<A HREF="org.apache.hadoop.hdfs.server.namenode.SafeModeException.html" class="hiddenlink" target="rightframe">org.apache.hadoop.hdfs.server.namenode</A><br>
<!-- Constructor SafeModeException -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.SafeModeException.html#org.apache.hadoop.hdfs.server.namenode.SafeModeException.ctor_added()" class="hiddenlink" target="rightframe"><b>SafeModeException</b>
()</A></nobr>&nbsp;constructor<br>
<!-- Method saveCurrent -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.saveCurrent_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe"><b>saveCurrent</b>
(<code>StorageDirectory</code>)</A></nobr><br>
<!-- Method saveFSImage -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.saveFSImage_removed()" class="hiddenlink" target="rightframe"><strike>saveFSImage</strike>
()</A></nobr><br>
<!-- Method saveNamespace -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.saveNamespace_changed()" class="hiddenlink" target="rightframe">saveNamespace
()</A></nobr><br>
<!-- Field scheduledReplicationBlocks -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.scheduledReplicationBlocks" class="hiddenlink" target="rightframe"><strike>scheduledReplicationBlocks</strike></A>
</nobr><br>
<!-- Class SecondaryNameNode -->
<A HREF="org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.html" class="hiddenlink" target="rightframe">SecondaryNameNode</A><br>
<!-- Class SecureDataNodeStarter -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html#SecureDataNodeStarter" class="hiddenlink" target="rightframe"><b>SecureDataNodeStarter</b></A><br>
<!-- Class SecureDataNodeStarter.SecureResources -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html#SecureDataNodeStarter.SecureResources" class="hiddenlink" target="rightframe"><b>SecureDataNodeStarter.SecureResources</b></A><br>
<!-- Method secureMain -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain_added(java.lang.String[], org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)" class="hiddenlink" target="rightframe"><b>secureMain</b>
(<code>String[], SecureResources</code>)</A></nobr><br>
<!-- Method sendHeartbeat -->
<i>sendHeartbeat</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.sendHeartbeat_changed(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, long, long, long, int, int, int)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>DatanodeRegistration, long, long, long, int, int, int</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method sendHeartbeat -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.sendHeartbeat_changed(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, long, long, long, int, int, int)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>DatanodeRegistration, long, long, long, int, int, int</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol
</A></nobr><br>
<!-- Field serialVersionUID -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.QuotaExceededException.html#org.apache.hadoop.hdfs.protocol.QuotaExceededException.serialVersionUID" class="hiddenlink" target="rightframe">serialVersionUID</A>
</nobr><br>
<!-- Field SERVER_DEFAULTS_VALIDITY_PERIOD -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.SERVER_DEFAULTS_VALIDITY_PERIOD" class="hiddenlink" target="rightframe">SERVER_DEFAULTS_VALIDITY_PERIOD</A>
</nobr><br>
<!-- Class ServerCommand -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#ServerCommand" class="hiddenlink" target="rightframe"><b>ServerCommand</b></A><br>
<!-- Field serviceRPCAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.serviceRPCAddress" class="hiddenlink" target="rightframe">serviceRPCAddress</A>
</nobr><br>
<!-- Field serviceRpcServer -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.serviceRpcServer" class="hiddenlink" target="rightframe">serviceRpcServer</A>
</nobr><br>
<!-- Method setBlockToken -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlock.html#org.apache.hadoop.hdfs.protocol.LocatedBlock.setBlockToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe"><b>setBlockToken</b>
(<code>Token</code>)</A></nobr><br>
<!-- Method setBufferCapacity -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html#org.apache.hadoop.hdfs.server.namenode.FSEditLog.setBufferCapacity_added(int)" class="hiddenlink" target="rightframe"><b>setBufferCapacity</b>
(<code>int</code>)</A></nobr><br>
<!-- Method setChannelPosition -->
<i>setChannelPosition</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.setChannelPosition_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, BlockWriteStreams, long, long</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method setChannelPosition -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.setChannelPosition_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, BlockWriteStreams, long, long</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method setHttpServerAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.setHttpServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>setHttpServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method setImageDigest -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.setImageDigest_added(org.apache.hadoop.io.MD5Hash)" class="hiddenlink" target="rightframe"><b>setImageDigest</b>
(<code>MD5Hash</code>)</A></nobr><br>
<!-- Method setOwner -->
<i>setOwner</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.setOwner_changed(java.lang.String, java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String, String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method setOwner -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setOwner_changed(java.lang.String, java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String, String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method setPermission -->
<i>setPermission</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.setPermission_changed(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, FsPermission</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method setPermission -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setPermission_changed(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, FsPermission</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method setQuota -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota_changed(java.lang.String, long, long)" class="hiddenlink" target="rightframe">setQuota
(<code>String, long, long</code>)</A></nobr><br>
<!-- Method setReplication -->
<i>setReplication</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.setReplication_changed(java.lang.String, short)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, short</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method setReplication -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setReplication_changed(java.lang.String, short)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, short</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method setRestoreFailedStorage -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.setRestoreFailedStorage_added(boolean)" class="hiddenlink" target="rightframe"><b>setRestoreFailedStorage</b>
(<code>boolean</code>)</A></nobr><br>
<!-- Method setRpcServerAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.setRpcServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>setRpcServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method setRpcServiceServerAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.setRpcServiceServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>setRpcServiceServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method setServiceAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.setServiceAddress_added(org.apache.hadoop.conf.Configuration, java.lang.String)" class="hiddenlink" target="rightframe"><b>setServiceAddress</b>
(<code>Configuration, String</code>)</A></nobr><br>
<!-- Method setTimes -->
<i>setTimes</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.setTimes_changed(java.lang.String, long, long)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, long, long</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method setTimes -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setTimes_changed(java.lang.String, long, long)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, long, long</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method startCheckpoint -->
<i>startCheckpoint</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.startCheckpoint_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method startCheckpoint -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.startCheckpoint_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<!-- Field stopRequested -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.stopRequested" class="hiddenlink" target="rightframe">stopRequested</A>
</nobr><br>
<!-- Class Storage -->
<A HREF="org.apache.hadoop.hdfs.server.common.Storage.html" class="hiddenlink" target="rightframe">Storage</A><br>
<!-- Class StorageInfo -->
<A HREF="org.apache.hadoop.hdfs.server.common.StorageInfo.html" class="hiddenlink" target="rightframe">StorageInfo</A><br>
<!-- Class StreamFile -->
<A HREF="org.apache.hadoop.hdfs.server.namenode.StreamFile.html" class="hiddenlink" target="rightframe">StreamFile</A><br>
<!-- Method string2Bytes -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.string2Bytes_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>string2Bytes</b>
(<code>String</code>)</A></nobr><br>
<!-- Method stringAsURI -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Util.html#org.apache.hadoop.hdfs.server.common.Util.stringAsURI_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>stringAsURI</b>
(<code>String</code>)</A></nobr><br>
<!-- Method stringCollectionAsURIs -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Util.html#org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs_added(java.util.Collection)" class="hiddenlink" target="rightframe"><b>stringCollectionAsURIs</b>
(<code>Collection</code>)</A></nobr><br>
<!-- Method stringifyToken -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.stringifyToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe"><b>stringifyToken</b>
(<code>Token</code>)</A></nobr><br>
<!-- Method toNodeRole -->
<A NAME="T"></A>
<br><font size="+2">T</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.HdfsConstants.StartupOption.html#org.apache.hadoop.hdfs.server.common.HdfsConstants.StartupOption.toNodeRole_added()" class="hiddenlink" target="rightframe"><b>toNodeRole</b>
()</A></nobr><br>
<!-- Method toString -->
<i>toString</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlock.html#org.apache.hadoop.hdfs.protocol.LocatedBlock.toString_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.LocatedBlock
</A></nobr><br>
<!-- Method toString -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlocks.html#org.apache.hadoop.hdfs.protocol.LocatedBlocks.toString_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.LocatedBlocks
</A></nobr><br>
<!-- Method toString -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.html#org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.toString_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode
</A></nobr><br>
<!-- Field totalLoad -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.totalLoad" class="hiddenlink" target="rightframe"><strike>totalLoad</strike></A>
</nobr><br>
<!-- Method totalRawCapacity -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.totalRawCapacity_removed()" class="hiddenlink" target="rightframe"><strike>totalRawCapacity</strike>
()</A></nobr><br>
<!-- Method totalRawUsed -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.totalRawUsed_removed()" class="hiddenlink" target="rightframe"><strike>totalRawUsed</strike>
()</A></nobr><br>
<!-- Field underReplicatedBlocks -->
<A NAME="U"></A>
<br><font size="+2">U</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.underReplicatedBlocks" class="hiddenlink" target="rightframe"><strike>underReplicatedBlocks</strike></A>
</nobr><br>
<!-- Method unlinkBlock -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.unlinkBlock_added(org.apache.hadoop.hdfs.protocol.Block, int)" class="hiddenlink" target="rightframe"><b>unlinkBlock</b>
(<code>Block, int</code>)</A></nobr><br>
<!-- Class UnregisteredDatanodeException -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#UnregisteredDatanodeException" class="hiddenlink" target="rightframe"><strike>UnregisteredDatanodeException</strike></A><br>
<!-- Class UnregisteredNodeException -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#UnregisteredNodeException" class="hiddenlink" target="rightframe"><b>UnregisteredNodeException</b></A><br>
<!-- Class UnresolvedPathException -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#UnresolvedPathException" class="hiddenlink" target="rightframe"><b>UnresolvedPathException</b></A><br>
<!-- Class UnsupportedActionException -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#UnsupportedActionException" class="hiddenlink" target="rightframe"><b>UnsupportedActionException</b></A><br>
<!-- Method updateBlock -->
<i>updateBlock</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.updateBlock_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, Block, boolean</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Method updateBlock -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.updateBlock_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, Block</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method updateBlock -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.updateBlock_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, Block</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method updateBlock -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.updateBlock_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, Block, boolean</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol
</A></nobr><br>
<!-- Method updateBlockForPipeline -->
<i>updateBlockForPipeline</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.updateBlockForPipeline_added(org.apache.hadoop.hdfs.protocol.Block, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method updateBlockForPipeline -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.updateBlockForPipeline_added(org.apache.hadoop.hdfs.protocol.Block, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method updatePipeline -->
<i>updatePipeline</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.updatePipeline_added(java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeID[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, Block, Block, DatanodeID[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method updatePipeline -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.updatePipeline_added(java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeID[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, Block, Block, DatanodeID[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method updateQuery -->
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.updateQuery_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>updateQuery</b>
(<code>String</code>)</A></nobr><br>
<!-- Method updateRegInfo -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.updateRegInfo_changed(org.apache.hadoop.hdfs.protocol.DatanodeID)" class="hiddenlink" target="rightframe">updateRegInfo
(<code>DatanodeID</code>)</A></nobr><br>
<!-- Method updateReplicaUnderRecovery -->
<i>updateReplicaUnderRecovery</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.updateReplicaUnderRecovery_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Method updateReplicaUnderRecovery -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.updateReplicaUnderRecovery_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method updateReplicaUnderRecovery -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.updateReplicaUnderRecovery_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method updateReplicaUnderRecovery -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.updateReplicaUnderRecovery_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol
</A></nobr><br>
<!-- Class UpgradeManager -->
<A HREF="org.apache.hadoop.hdfs.server.common.UpgradeManager.html" class="hiddenlink" target="rightframe">UpgradeManager</A><br>
<!-- Class UpgradeObjectNamenode -->
<A HREF="org.apache.hadoop.hdfs.server.namenode.UpgradeObjectNamenode.html" class="hiddenlink" target="rightframe">UpgradeObjectNamenode</A><br>
<!-- Class Util -->
<A HREF="org.apache.hadoop.hdfs.server.common.Util.html" class="hiddenlink" target="rightframe">Util</A><br>
<!-- Method validateBlockMetadata -->
<A NAME="V"></A>
<br><font size="+2">V</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>validateBlockMetadata</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.validateBlockMetadata_removed(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method validateBlockMetadata -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.validateBlockMetadata_removed(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method verifyRequest -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.verifyRequest_changed(org.apache.hadoop.hdfs.server.protocol.NodeRegistration)" class="hiddenlink" target="rightframe">verifyRequest
(<code>NodeRegistration</code>)</A></nobr><br>
<!-- Method versionRequest -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.versionRequest_added()" class="hiddenlink" target="rightframe"><b>versionRequest</b>
()</A></nobr><br>
<!-- Field volumeFailures -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.metrics.DataNodeMetrics.html#org.apache.hadoop.hdfs.server.datanode.metrics.DataNodeMetrics.volumeFailures" class="hiddenlink" target="rightframe">volumeFailures</A>
</nobr><br>
<!-- Field WILDCARD_STAMP -->
<A NAME="W"></A>
<br><font size="+2">W</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.GenerationStamp.html#org.apache.hadoop.hdfs.server.common.GenerationStamp.WILDCARD_STAMP" class="hiddenlink" target="rightframe"><strike>WILDCARD_STAMP</strike></A>
</nobr><br>
<!-- Method write -->
<i>write</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.common.GenerationStamp.html#org.apache.hadoop.hdfs.server.common.GenerationStamp.write_removed(java.io.DataOutput)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>DataOutput</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.common.GenerationStamp
</A></nobr><br>
<!-- Method write -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.common.StorageInfo.html#org.apache.hadoop.hdfs.server.common.StorageInfo.write_added(java.io.DataOutput)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>DataOutput</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.common.StorageInfo
</A></nobr><br>
<!-- Method write -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeCommand.html#org.apache.hadoop.hdfs.server.protocol.DatanodeCommand.write_changed(java.io.DataOutput)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>DataOutput</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeCommand
</A></nobr><br>
<!-- Method writeCorruptedData -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.writeCorruptedData_removed(java.io.RandomAccessFile)" class="hiddenlink" target="rightframe"><strike>writeCorruptedData</strike>
(<code>RandomAccessFile</code>)</A></nobr><br>
<!-- Method writeId -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.writeId_added(java.io.DataOutput)" class="hiddenlink" target="rightframe"><b>writeId</b>
(<code>DataOutput</code>)</A></nobr><br>
<!-- Method writeToBlock -->
<i>writeToBlock</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.writeToBlock_removed(org.apache.hadoop.hdfs.protocol.Block, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, boolean</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method writeToBlock -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.writeToBlock_removed(org.apache.hadoop.hdfs.protocol.Block, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, boolean</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
</BODY>
</HTML>
