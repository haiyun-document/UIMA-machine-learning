<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Frameset//EN""http://www.w3.org/TR/REC-html40/frameset.dtd">
<HTML>
<HEAD>
<meta name="generator" content="JDiff v1.0.9">
<!-- Generated by the JDiff Javadoc doclet -->
<!-- (http://www.jdiff.org) -->
<meta name="description" content="JDiff is a Javadoc doclet which generates an HTML report of all the packages, classes, constructors, methods, and fields which have been removed, added or changed in any way, including their documentation, when two APIs are compared.">
<meta name="keywords" content="diff, jdiff, javadiff, java diff, java difference, API difference, difference between two APIs, API diff, Javadoc, doclet">
<TITLE>
All Additions Index
</TITLE>
<LINK REL="stylesheet" TYPE="text/css" HREF="../stylesheet-jdiff.css" TITLE="Style">
</HEAD>
<BODY>
<a NAME="topheader"></a>
<table summary="Index for All Differences" width="100%" border="0" cellspacing="0" cellpadding="0">
  <tr>
  <td bgcolor="#FFFFCC">
<font size="+1"><a href="alldiffs_index_all.html" class="staysblack">All Differences</a></font>
  </td>
  </tr>
  <tr>
  <td bgcolor="#FFFFFF">
  <FONT SIZE="-1">
<A HREF="alldiffs_index_removals.html" class="hiddenlink">Removals</A>
  </FONT>
  </td>
  </tr>
  <tr>
  <td bgcolor="#FFFFFF">
  <FONT SIZE="-1">
<b>Additions</b>
  </FONT>
  </td>
  </tr>
  <tr>
  <td bgcolor="#FFFFFF">
  <FONT SIZE="-1">
<A HREF="alldiffs_index_changes.html"class="hiddenlink">Changes</A>
  </FONT>
  </td>
  </tr>
  <tr>
  <td>
<font size="-2"><b>Bold</b>&nbsp;is&nbsp;New,&nbsp;<strike>strike</strike>&nbsp;is&nbsp;deleted</font>
  </td>
  </tr>
</table><br>
<!-- Field ACT_CHECKPOINT -->
<A NAME="A"></A>
<br><font size="+2">A</font>&nbsp;
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.ACT_CHECKPOINT" class="hiddenlink" target="rightframe">ACT_CHECKPOINT</A>
</nobr><br>
<!-- Field ACT_SHUTDOWN -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.ACT_SHUTDOWN" class="hiddenlink" target="rightframe">ACT_SHUTDOWN</A>
</nobr><br>
<!-- Field ACT_UNKNOWN -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.ACT_UNKNOWN" class="hiddenlink" target="rightframe">ACT_UNKNOWN</A>
</nobr><br>
<!-- Method adjustCrcChannelPosition -->
<i>adjustCrcChannelPosition</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.adjustCrcChannelPosition_added(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, BlockWriteStreams, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method adjustCrcChannelPosition -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.adjustCrcChannelPosition_added(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, BlockWriteStreams, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method append -->
<i>append</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.append_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method append -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.append_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Field BACKUP -->
<A NAME="B"></A>
<br><font size="+2">B</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.HdfsConstants.StartupOption.html#org.apache.hadoop.hdfs.server.common.HdfsConstants.StartupOption.BACKUP" class="hiddenlink" target="rightframe">BACKUP</A>
</nobr><br>
<!-- Class BackupNode -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#BackupNode" class="hiddenlink" target="rightframe"><b>BackupNode</b></A><br>
<!-- Class BackupStorage -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#BackupStorage" class="hiddenlink" target="rightframe"><b>BackupStorage</b></A><br>
<!-- Field BLOCK_FILE_PREFIX -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.BLOCK_FILE_PREFIX" class="hiddenlink" target="rightframe">BLOCK_FILE_PREFIX</A>
</nobr><br>
<!-- Field blockFilePattern -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.blockFilePattern" class="hiddenlink" target="rightframe">blockFilePattern</A>
</nobr><br>
<!-- Constructor BlockListAsLongs -->
<i>BlockListAsLongs</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.html#org.apache.hadoop.hdfs.protocol.BlockListAsLongs.ctor_added(java.util.List, java.util.List)" class="hiddenlink" target="rightframe"><b>BlockListAsLongs</b>
(<code>List, List</code>)</A></nobr>&nbsp;constructor<br>
<!-- Constructor BlockListAsLongs -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.html#org.apache.hadoop.hdfs.protocol.BlockListAsLongs.ctor_added()" class="hiddenlink" target="rightframe"><b>BlockListAsLongs</b>
()</A></nobr>&nbsp;constructor<br>
<!-- Class BlockListAsLongs.BlockReportIterator -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#BlockListAsLongs.BlockReportIterator" class="hiddenlink" target="rightframe"><b>BlockListAsLongs.BlockReportIterator</b></A><br>
<!-- Class BlockManager -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#BlockManager" class="hiddenlink" target="rightframe"><b>BlockManager</b></A><br>
<!-- Class BlockMissingException -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#BlockMissingException" class="hiddenlink" target="rightframe"><b>BlockMissingException</b></A><br>
<!-- Class BlockPlacementPolicy -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#BlockPlacementPolicy" class="hiddenlink" target="rightframe"><b>BlockPlacementPolicy</b></A><br>
<!-- Class BlockPlacementPolicy.NotEnoughReplicasException -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#BlockPlacementPolicy.NotEnoughReplicasException" class="hiddenlink" target="rightframe"><b>BlockPlacementPolicy.NotEnoughReplicasException</b></A><br>
<!-- Class BlockPlacementPolicyDefault -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#BlockPlacementPolicyDefault" class="hiddenlink" target="rightframe"><b>BlockPlacementPolicyDefault</b></A><br>
<!-- Class BlockReader -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#BlockReader" class="hiddenlink" target="rightframe"><b>BlockReader</b></A><br>
<!-- Class BlockRecoveryCommand -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#BlockRecoveryCommand" class="hiddenlink" target="rightframe"><b>BlockRecoveryCommand</b></A><br>
<!-- Class BlockRecoveryCommand.RecoveringBlock -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#BlockRecoveryCommand.RecoveringBlock" class="hiddenlink" target="rightframe"><b>BlockRecoveryCommand.RecoveringBlock</b></A><br>
<!-- Method byteArray2String -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.byteArray2String_added(byte[][])" class="hiddenlink" target="rightframe"><b>byteArray2String</b>
(<code>byte[][]</code>)</A></nobr><br>
<!-- Method bytes2byteArray -->
<i>bytes2byteArray</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.bytes2byteArray_added(byte[], byte)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>byte[], byte</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSUtil
</A></nobr><br>
<!-- Method bytes2byteArray -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.bytes2byteArray_added(byte[], int, byte)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>byte[], int, byte</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSUtil
</A></nobr><br>
<!-- Method bytes2String -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.bytes2String_added(byte[])" class="hiddenlink" target="rightframe"><b>bytes2String</b>
(<code>byte[]</code>)</A></nobr><br>
<!-- Method cancelDelegationToken -->
<A NAME="C"></A>
<br><font size="+2">C</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>cancelDelegationToken</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.cancelDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method cancelDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.cancelDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method cancelDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.cancelDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method cancelDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.cancelDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method cancelDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.cancelDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Class CancelDelegationTokenServlet -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#CancelDelegationTokenServlet" class="hiddenlink" target="rightframe"><b>CancelDelegationTokenServlet</b></A><br>
<!-- Method checkAndUpdate -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.checkAndUpdate_added(long, java.io.File, java.io.File, org.apache.hadoop.hdfs.server.datanode.FSDataset.FSVolume)" class="hiddenlink" target="rightframe"><b>checkAndUpdate</b>
(<code>long, File, File, FSVolume</code>)</A></nobr><br>
<!-- Method checkDiskError -->
<i>checkDiskError</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.checkDiskError_added(java.lang.Exception)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Exception</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Method checkDiskError -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.checkDiskError_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Field CHECKPOINT -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.HdfsConstants.StartupOption.html#org.apache.hadoop.hdfs.server.common.HdfsConstants.StartupOption.CHECKPOINT" class="hiddenlink" target="rightframe">CHECKPOINT</A>
</nobr><br>
<!-- Class CheckpointCommand -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#CheckpointCommand" class="hiddenlink" target="rightframe"><b>CheckpointCommand</b></A><br>
<!-- Constructor CheckpointSignature -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.html#org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.ctor_added()" class="hiddenlink" target="rightframe"><b>CheckpointSignature</b>
()</A></nobr>&nbsp;constructor<br>
<!-- Field ckptState -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.ckptState" class="hiddenlink" target="rightframe">ckptState</A>
</nobr><br>
<!-- Method concat -->
<i>concat</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.concat_added(java.lang.String, java.lang.String[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method concat -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.concat_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path, Path[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method concat -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.concat_added(java.lang.String, java.lang.String[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method concat -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concat_added(java.lang.String, java.lang.String[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method concat -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.concat_added(java.lang.String, java.lang.String[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Field CONTENT_LENGTH -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.StreamFile.html#org.apache.hadoop.hdfs.server.namenode.StreamFile.CONTENT_LENGTH" class="hiddenlink" target="rightframe">CONTENT_LENGTH</A>
</nobr><br>
<!-- Class ContentSummaryServlet -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#ContentSummaryServlet" class="hiddenlink" target="rightframe"><b>ContentSummaryServlet</b></A><br>
<!-- Field count -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.QuotaExceededException.html#org.apache.hadoop.hdfs.protocol.QuotaExceededException.count" class="hiddenlink" target="rightframe">count</A>
</nobr><br>
<!-- Method create -->
<i>create</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.create_added(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, short, long, org.apache.hadoop.util.Progressable, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, FsPermission, EnumSet, boolean, short, long, Progressable, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method create -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.create_added(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, short, long, org.apache.hadoop.util.Progressable, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, FsPermission, EnumSet, short, long, Progressable, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method createDataNode -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode_added(java.lang.String[], org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)" class="hiddenlink" target="rightframe"><b>createDataNode</b>
(<code>String[], Configuration, SecureResources</code>)</A></nobr><br>
<!-- Method createNonRecursive -->
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.createNonRecursive_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, int, short, long, org.apache.hadoop.util.Progressable)" class="hiddenlink" target="rightframe"><b>createNonRecursive</b>
(<code>Path, FsPermission, EnumSet, int, short, long, Progressable</code>)</A></nobr><br>
<!-- Method createRbw -->
<i>createRbw</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.createRbw_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method createRbw -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.createRbw_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method createSymlink -->
<i>createSymlink</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.createSymlink_added(java.lang.String, java.lang.String, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method createSymlink -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.createSymlink_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, FsPermission, boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method createSymlink -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.createSymlink_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.PermissionStatus, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, PermissionStatus, boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method createSymlink -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.createSymlink_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, FsPermission, boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method createTemporary -->
<i>createTemporary</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.createTemporary_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method createTemporary -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.createTemporary_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Constructor DatanodeDescriptor -->
<A NAME="D"></A>
<br><font size="+2">D</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>DatanodeDescriptor</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.ctor_added(org.apache.hadoop.hdfs.protocol.DatanodeID, java.lang.String, java.lang.String, long, long, long, int, int)" class="hiddenlink" target="rightframe"><b>DatanodeDescriptor</b>
(<code>DatanodeID, String, String, long, long, long, int, int</code>)</A></nobr>&nbsp;constructor<br>
<!-- Constructor DatanodeDescriptor -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.ctor_added(org.apache.hadoop.hdfs.protocol.DatanodeID, long, long, long, int, int)" class="hiddenlink" target="rightframe"><b>DatanodeDescriptor</b>
(<code>DatanodeID, long, long, long, int, int</code>)</A></nobr>&nbsp;constructor<br>
<!-- Class DatanodeJspHelper -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html#DatanodeJspHelper" class="hiddenlink" target="rightframe"><b>DatanodeJspHelper</b></A><br>
<!-- Class DataNodeMXBean -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html#DataNodeMXBean" class="hiddenlink" target="rightframe"><b><i>DataNodeMXBean</i></b></A><br>
<!-- Class DataTransferProtocol.BlockConstructionStage -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DataTransferProtocol.BlockConstructionStage" class="hiddenlink" target="rightframe"><b>DataTransferProtocol.BlockConstructionStage</b></A><br>
<!-- Class DataTransferProtocol.Op -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DataTransferProtocol.Op" class="hiddenlink" target="rightframe"><b>DataTransferProtocol.Op</b></A><br>
<!-- Class DataTransferProtocol.PacketHeader -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DataTransferProtocol.PacketHeader" class="hiddenlink" target="rightframe"><b>DataTransferProtocol.PacketHeader</b></A><br>
<!-- Class DataTransferProtocol.PipelineAck -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DataTransferProtocol.PipelineAck" class="hiddenlink" target="rightframe"><b>DataTransferProtocol.PipelineAck</b></A><br>
<!-- Class DataTransferProtocol.Receiver -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DataTransferProtocol.Receiver" class="hiddenlink" target="rightframe"><b>DataTransferProtocol.Receiver</b></A><br>
<!-- Class DataTransferProtocol.Sender -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DataTransferProtocol.Sender" class="hiddenlink" target="rightframe"><b>DataTransferProtocol.Sender</b></A><br>
<!-- Class DataTransferProtocol.Status -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DataTransferProtocol.Status" class="hiddenlink" target="rightframe"><b>DataTransferProtocol.Status</b></A><br>
<!-- Field DEFAULT_BYTES_PER_CHECKSUM -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.FSConstants.html#org.apache.hadoop.hdfs.protocol.FSConstants.DEFAULT_BYTES_PER_CHECKSUM" class="hiddenlink" target="rightframe">DEFAULT_BYTES_PER_CHECKSUM</A>
</nobr><br>
<!-- Field DEFAULT_FILE_BUFFER_SIZE -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.FSConstants.html#org.apache.hadoop.hdfs.protocol.FSConstants.DEFAULT_FILE_BUFFER_SIZE" class="hiddenlink" target="rightframe">DEFAULT_FILE_BUFFER_SIZE</A>
</nobr><br>
<!-- Field DEFAULT_REPLICATION_FACTOR -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.FSConstants.html#org.apache.hadoop.hdfs.protocol.FSConstants.DEFAULT_REPLICATION_FACTOR" class="hiddenlink" target="rightframe">DEFAULT_REPLICATION_FACTOR</A>
</nobr><br>
<!-- Field DEFAULT_WRITE_PACKET_SIZE -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.FSConstants.html#org.apache.hadoop.hdfs.protocol.FSConstants.DEFAULT_WRITE_PACKET_SIZE" class="hiddenlink" target="rightframe">DEFAULT_WRITE_PACKET_SIZE</A>
</nobr><br>
<!-- Class DelegationTokenFetcher -->
<A HREF="pkg_org.apache.hadoop.hdfs.tools.html#DelegationTokenFetcher" class="hiddenlink" target="rightframe"><b>DelegationTokenFetcher</b></A><br>
<!-- Class DeprecatedUTF8 -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#DeprecatedUTF8" class="hiddenlink" target="rightframe"><b>DeprecatedUTF8</b></A><br>
<!-- Constructor DFSck -->
<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSck.html#org.apache.hadoop.hdfs.tools.DFSck.ctor_added(org.apache.hadoop.conf.Configuration, java.io.PrintStream)" class="hiddenlink" target="rightframe"><b>DFSck</b>
(<code>Configuration, PrintStream</code>)</A></nobr>&nbsp;constructor<br>
<!-- Class DFSClient.DFSDataInputStream -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#DFSClient.DFSDataInputStream" class="hiddenlink" target="rightframe"><b>DFSClient.DFSDataInputStream</b></A><br>
<!-- Class DFSConfigKeys -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#DFSConfigKeys" class="hiddenlink" target="rightframe"><b>DFSConfigKeys</b></A><br>
<!-- Class DFSInputStream -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#DFSInputStream" class="hiddenlink" target="rightframe"><b>DFSInputStream</b></A><br>
<!-- Class DFSUtil.ErrorSimulator -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#DFSUtil.ErrorSimulator" class="hiddenlink" target="rightframe"><b>DFSUtil.ErrorSimulator</b></A><br>
<!-- Class DirectoryListing -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DirectoryListing" class="hiddenlink" target="rightframe"><b>DirectoryListing</b></A><br>
<!-- Class DirectoryScanner -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html#DirectoryScanner" class="hiddenlink" target="rightframe"><b>DirectoryScanner</b></A><br>
<!-- Constructor DistributedFileSystem.DiskStatus -->
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.DiskStatus.html#org.apache.hadoop.hdfs.DistributedFileSystem.DiskStatus.ctor_added(org.apache.hadoop.fs.FsStatus)" class="hiddenlink" target="rightframe"><b>DistributedFileSystem.DiskStatus</b>
(<code>FsStatus</code>)</A></nobr>&nbsp;constructor<br>
<!-- Field DN_KEEPALIVE_TIMEOUT -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.HdfsConstants.html#org.apache.hadoop.hdfs.server.common.HdfsConstants.DN_KEEPALIVE_TIMEOUT" class="hiddenlink" target="rightframe">DN_KEEPALIVE_TIMEOUT</A>
</nobr><br>
<!-- Field DNA_ACCESSKEYUPDATE -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.DNA_ACCESSKEYUPDATE" class="hiddenlink" target="rightframe">DNA_ACCESSKEYUPDATE</A>
</nobr><br>
<!-- Method doWork -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.html#org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork_added()" class="hiddenlink" target="rightframe"><b>doWork</b>
()</A></nobr><br>
<!-- Class DSQuotaExceededException -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#DSQuotaExceededException" class="hiddenlink" target="rightframe"><b>DSQuotaExceededException</b></A><br>
<!-- Field editLog -->
<A NAME="E"></A>
<br><font size="+2">E</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.editLog" class="hiddenlink" target="rightframe">editLog</A>
</nobr><br>
<!-- Method endCheckpoint -->
<i>endCheckpoint</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.endCheckpoint_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, CheckpointSignature</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method endCheckpoint -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.endCheckpoint_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, CheckpointSignature</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<!-- Method errorReport -->
<i>errorReport</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.errorReport_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, int, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method errorReport -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.errorReport_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, int, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<!-- Field exportedKeys -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.html#org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.exportedKeys" class="hiddenlink" target="rightframe">exportedKeys</A>
</nobr><br>
<!-- Field FATAL -->
<A NAME="F"></A>
<br><font size="+2">F</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.FATAL" class="hiddenlink" target="rightframe">FATAL</A>
</nobr><br>
<!-- Field FATAL_DISK_ERROR -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.FATAL_DISK_ERROR" class="hiddenlink" target="rightframe">FATAL_DISK_ERROR</A>
</nobr><br>
<!-- Method fileAsURI -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Util.html#org.apache.hadoop.hdfs.server.common.Util.fileAsURI_added(java.io.File)" class="hiddenlink" target="rightframe"><b>fileAsURI</b>
(<code>File</code>)</A></nobr><br>
<!-- Method filename2id -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.filename2id_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>filename2id</b>
(<code>String</code>)</A></nobr><br>
<!-- Class FSClusterStats -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#FSClusterStats" class="hiddenlink" target="rightframe"><b><i>FSClusterStats</i></b></A><br>
<!-- Class FSEditLogLoader -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#FSEditLogLoader" class="hiddenlink" target="rightframe"><b>FSEditLogLoader</b></A><br>
<!-- Class FSImageSerialization -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#FSImageSerialization" class="hiddenlink" target="rightframe"><b>FSImageSerialization</b></A><br>
<!-- Class FSInodeInfo -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#FSInodeInfo" class="hiddenlink" target="rightframe"><b><i>FSInodeInfo</i></b></A><br>
<!-- Method getAddress -->
<A NAME="G"></A>
<br><font size="+2">G</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.html#org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.getAddress_added()" class="hiddenlink" target="rightframe"><b>getAddress</b>
()</A></nobr><br>
<!-- Method getBlockCapacity -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockCapacity_added()" class="hiddenlink" target="rightframe"><b>getBlockCapacity</b>
()</A></nobr><br>
<!-- Method getBlockId -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.getBlockId_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>getBlockId</b>
(<code>String</code>)</A></nobr><br>
<!-- Method getBlockKeys -->
<i>getBlockKeys</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockKeys_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method getBlockKeys -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.getBlockKeys_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<!-- Method getBlockListAsLongs -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.html#org.apache.hadoop.hdfs.protocol.BlockListAsLongs.getBlockListAsLongs_added()" class="hiddenlink" target="rightframe"><b>getBlockListAsLongs</b>
()</A></nobr><br>
<!-- Method getBlockReportIterator -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.html#org.apache.hadoop.hdfs.protocol.BlockListAsLongs.getBlockReportIterator_added()" class="hiddenlink" target="rightframe"><b>getBlockReportIterator</b>
()</A></nobr><br>
<!-- Method getBlockToken -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlock.html#org.apache.hadoop.hdfs.protocol.LocatedBlock.getBlockToken_added()" class="hiddenlink" target="rightframe"><b>getBlockToken</b>
()</A></nobr><br>
<!-- Method getCanonicalServiceName -->
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.getCanonicalServiceName_added()" class="hiddenlink" target="rightframe"><b>getCanonicalServiceName</b>
()</A></nobr><br>
<!-- Method getContentSummary -->
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.getContentSummary_added(org.apache.hadoop.fs.Path)" class="hiddenlink" target="rightframe"><b>getContentSummary</b>
(<code>Path</code>)</A></nobr><br>
<!-- Method getCorruptReplicaBlocks -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getCorruptReplicaBlocks_added()" class="hiddenlink" target="rightframe"><b>getCorruptReplicaBlocks</b>
()</A></nobr><br>
<!-- Method getDatanodeRegistration -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getDatanodeRegistration_added()" class="hiddenlink" target="rightframe"><b>getDatanodeRegistration</b>
()</A></nobr><br>
<!-- Method getDateFormat -->
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.getDateFormat_added()" class="hiddenlink" target="rightframe"><b>getDateFormat</b>
()</A></nobr><br>
<!-- Method getDeadNodes -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDeadNodes_added()" class="hiddenlink" target="rightframe"><b>getDeadNodes</b>
()</A></nobr><br>
<!-- Method getDecommissioningNodes -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDecommissioningNodes_added()" class="hiddenlink" target="rightframe"><b>getDecommissioningNodes</b>
()</A></nobr><br>
<!-- Method getDecomNodes -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDecomNodes_added()" class="hiddenlink" target="rightframe"><b>getDecomNodes</b>
()</A></nobr><br>
<!-- Method getDefaultPort -->
<i>getDefaultPort</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getDefaultPort_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method getDefaultPort -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.getDefaultPort_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.HftpFileSystem
</A></nobr><br>
<!-- Method getDelegationToken -->
<i>getDelegationToken</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getDelegationToken_added(org.apache.hadoop.io.Text)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Text</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method getDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getDelegationToken_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method getDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getDelegationToken_added(org.apache.hadoop.io.Text)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Text</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method getDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.getDelegationToken_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.HftpFileSystem
</A></nobr><br>
<!-- Method getDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getDelegationToken_added(org.apache.hadoop.io.Text)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Text</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method getDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDelegationToken_added(org.apache.hadoop.io.Text)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Text</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method getDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getDelegationToken_added(org.apache.hadoop.io.Text)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Text</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method getDelegationTokenSecretManager -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDelegationTokenSecretManager_added()" class="hiddenlink" target="rightframe"><b>getDelegationTokenSecretManager</b>
()</A></nobr><br>
<!-- Class GetDelegationTokenServlet -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#GetDelegationTokenServlet" class="hiddenlink" target="rightframe"><b>GetDelegationTokenServlet</b></A><br>
<!-- Method getExcessBlocks -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getExcessBlocks_added()" class="hiddenlink" target="rightframe"><b>getExcessBlocks</b>
()</A></nobr><br>
<!-- Method getFileBlockLocations -->
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getFileBlockLocations_added(org.apache.hadoop.fs.Path, long, long)" class="hiddenlink" target="rightframe"><b>getFileBlockLocations</b>
(<code>Path, long, long</code>)</A></nobr><br>
<!-- Method getFileChecksum -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getFileChecksum_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>getFileChecksum</b>
(<code>String</code>)</A></nobr><br>
<!-- Method getFileLinkInfo -->
<i>getFileLinkInfo</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getFileLinkInfo_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method getFileLinkInfo -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileLinkInfo_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method getFileLinkInfo -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getFileLinkInfo_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method getFree -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFree_added()" class="hiddenlink" target="rightframe"><b>getFree</b>
()</A></nobr><br>
<!-- Method getFSNamesystem -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.getFSNamesystem_added()" class="hiddenlink" target="rightframe"><b>getFSNamesystem</b>
()</A></nobr><br>
<!-- Method getGenerationStamp -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.getGenerationStamp_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>getGenerationStamp</b>
(<code>String</code>)</A></nobr><br>
<!-- Method getHostPortString -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getHostPortString_added(java.net.InetSocketAddress)" class="hiddenlink" target="rightframe"><b>getHostPortString</b>
(<code>InetSocketAddress</code>)</A></nobr><br>
<!-- Method getHttpAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.html#org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.getHttpAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getHttpAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method getHttpPort -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getHttpPort_added()" class="hiddenlink" target="rightframe"><b>getHttpPort</b>
()</A></nobr><br>
<!-- Method getHttpServerAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getHttpServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getHttpServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method getInfoAddr -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getInfoAddr_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getInfoAddr</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method getInfoPort -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getInfoPort_added()" class="hiddenlink" target="rightframe"><b>getInfoPort</b>
()</A></nobr><br>
<!-- Method getInfoServer -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getInfoServer_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getInfoServer</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method getLastLocatedBlock -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlocks.html#org.apache.hadoop.hdfs.protocol.LocatedBlocks.getLastLocatedBlock_added()" class="hiddenlink" target="rightframe"><b>getLastLocatedBlock</b>
()</A></nobr><br>
<!-- Method getLinkTarget -->
<i>getLinkTarget</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getLinkTarget_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method getLinkTarget -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getLinkTarget_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method getLinkTarget -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getLinkTarget_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method getLiveNodes -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getLiveNodes_added()" class="hiddenlink" target="rightframe"><b>getLiveNodes</b>
()</A></nobr><br>
<!-- Method getNamenode -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getNamenode_added()" class="hiddenlink" target="rightframe"><b>getNamenode</b>
()</A></nobr><br>
<!-- Method getNamenodeAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddress_added()" class="hiddenlink" target="rightframe"><b>getNamenodeAddress</b>
()</A></nobr><br>
<!-- Method getNameNodeAddrForClient -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getNameNodeAddrForClient_added()" class="hiddenlink" target="rightframe"><b>getNameNodeAddrForClient</b>
()</A></nobr><br>
<!-- Method getNonDfsUsedSpace -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNonDfsUsedSpace_added()" class="hiddenlink" target="rightframe"><b>getNonDfsUsedSpace</b>
()</A></nobr><br>
<!-- Method getNumDeadDataNodes -->
<i>getNumDeadDataNodes</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNumDeadDataNodes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method getNumDeadDataNodes -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.getNumDeadDataNodes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean
</A></nobr><br>
<!-- Method getNumFailedVolumes -->
<i>getNumFailedVolumes</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.getNumFailedVolumes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method getNumFailedVolumes -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.metrics.FSDatasetMBean.html#org.apache.hadoop.hdfs.server.datanode.metrics.FSDatasetMBean.getNumFailedVolumes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.metrics.FSDatasetMBean
</A></nobr><br>
<!-- Method getNumLiveDataNodes -->
<i>getNumLiveDataNodes</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNumLiveDataNodes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method getNumLiveDataNodes -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.getNumLiveDataNodes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean
</A></nobr><br>
<!-- Method getOutputStreamIterator -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html#org.apache.hadoop.hdfs.server.namenode.FSEditLog.getOutputStreamIterator_added(org.apache.hadoop.hdfs.server.namenode.JournalStream.JournalType)" class="hiddenlink" target="rightframe"><b>getOutputStreamIterator</b>
(<code>JournalType</code>)</A></nobr><br>
<!-- Method getPendingDeletionBlocks -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPendingDeletionBlocks_added()" class="hiddenlink" target="rightframe"><b>getPendingDeletionBlocks</b>
()</A></nobr><br>
<!-- Method getPercentRemaining -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPercentRemaining_added()" class="hiddenlink" target="rightframe"><b>getPercentRemaining</b>
()</A></nobr><br>
<!-- Method getPercentUsed -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPercentUsed_added()" class="hiddenlink" target="rightframe"><b>getPercentUsed</b>
()</A></nobr><br>
<!-- Method getReplica -->
<i>getReplica</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.getReplica_added(long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method getReplica -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.getReplica_added(long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method getReplicaVisibleLength -->
<i>getReplicaVisibleLength</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol.html#org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol.getReplicaVisibleLength_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol
</A></nobr><br>
<!-- Method getReplicaVisibleLength -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getReplicaVisibleLength_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Method getReplicaVisibleLength -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.getReplicaVisibleLength_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method getReplicaVisibleLength -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.getReplicaVisibleLength_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method getRestoreFailedStorage -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.getRestoreFailedStorage_added()" class="hiddenlink" target="rightframe"><b>getRestoreFailedStorage</b>
()</A></nobr><br>
<!-- Method getRole -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getRole_added()" class="hiddenlink" target="rightframe"><b>getRole</b>
()</A></nobr><br>
<!-- Method getRpcPort -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getRpcPort_added()" class="hiddenlink" target="rightframe"><b>getRpcPort</b>
()</A></nobr><br>
<!-- Method getRpcServerAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getRpcServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getRpcServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method getSafemode -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getSafemode_added()" class="hiddenlink" target="rightframe"><b>getSafemode</b>
()</A></nobr><br>
<!-- Method getServerDefaults -->
<i>getServerDefaults</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getServerDefaults_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method getServerDefaults -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getServerDefaults_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method getServerDefaults -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getServerDefaults_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method getServerDefaults -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getServerDefaults_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method getServiceAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getServiceAddress_added(org.apache.hadoop.conf.Configuration, boolean)" class="hiddenlink" target="rightframe"><b>getServiceAddress</b>
(<code>Configuration, boolean</code>)</A></nobr><br>
<!-- Method getServiceRpcServerAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getServiceRpcServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getServiceRpcServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method getStatus -->
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getStatus_added(org.apache.hadoop.fs.Path)" class="hiddenlink" target="rightframe"><b>getStatus</b>
(<code>Path</code>)</A></nobr><br>
<!-- Method getStorageDirs -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs_added(org.apache.hadoop.conf.Configuration, java.lang.String)" class="hiddenlink" target="rightframe"><b>getStorageDirs</b>
(<code>Configuration, String</code>)</A></nobr><br>
<!-- Method getStreamingAddr -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getStreamingAddr_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getStreamingAddr</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method getThreads -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getThreads_added()" class="hiddenlink" target="rightframe"><b>getThreads</b>
()</A></nobr><br>
<!-- Method getTotal -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getTotal_added()" class="hiddenlink" target="rightframe"><b>getTotal</b>
()</A></nobr><br>
<!-- Method getTotalBlocks -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getTotalBlocks_added()" class="hiddenlink" target="rightframe"><b>getTotalBlocks</b>
()</A></nobr><br>
<!-- Method getTotalFiles -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getTotalFiles_added()" class="hiddenlink" target="rightframe"><b>getTotalFiles</b>
()</A></nobr><br>
<!-- Method getUsed -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getUsed_added()" class="hiddenlink" target="rightframe"><b>getUsed</b>
()</A></nobr><br>
<!-- Method getVersion -->
<i>getVersion</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getVersion_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Method getVersion -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getVersion_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method getVolumeFailures -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.getVolumeFailures_added()" class="hiddenlink" target="rightframe"><b>getVolumeFailures</b>
()</A></nobr><br>
<!-- Method getVolumeInfo -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getVolumeInfo_added()" class="hiddenlink" target="rightframe"><b>getVolumeInfo</b>
()</A></nobr><br>
<!-- Field GRANDFATHER_GENERATION_STAMP -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.GenerationStamp.html#org.apache.hadoop.hdfs.server.common.GenerationStamp.GRANDFATHER_GENERATION_STAMP" class="hiddenlink" target="rightframe">GRANDFATHER_GENERATION_STAMP</A>
</nobr><br>
<!-- Method hasEnoughResource -->
<A NAME="H"></A>
<br><font size="+2">H</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>hasEnoughResource</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.hasEnoughResource_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method hasEnoughResource -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.hasEnoughResource_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Field HDFS_URI_SCHEME -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.FSConstants.html#org.apache.hadoop.hdfs.protocol.FSConstants.HDFS_URI_SCHEME" class="hiddenlink" target="rightframe">HDFS_URI_SCHEME</A>
</nobr><br>
<!-- Class HDFSConcat -->
<A HREF="pkg_org.apache.hadoop.hdfs.tools.html#HDFSConcat" class="hiddenlink" target="rightframe"><b>HDFSConcat</b></A><br>
<!-- Class HdfsConfiguration -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#HdfsConfiguration" class="hiddenlink" target="rightframe"><b>HdfsConfiguration</b></A><br>
<!-- Class HdfsConstants.BlockUCState -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.common.html#HdfsConstants.BlockUCState" class="hiddenlink" target="rightframe"><b>HdfsConstants.BlockUCState</b></A><br>
<!-- Class HdfsConstants.NamenodeRole -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.common.html#HdfsConstants.NamenodeRole" class="hiddenlink" target="rightframe"><b>HdfsConstants.NamenodeRole</b></A><br>
<!-- Class HdfsConstants.ReplicaState -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.common.html#HdfsConstants.ReplicaState" class="hiddenlink" target="rightframe"><b>HdfsConstants.ReplicaState</b></A><br>
<!-- Class HdfsFileStatus -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#HdfsFileStatus" class="hiddenlink" target="rightframe"><b>HdfsFileStatus</b></A><br>
<!-- Class HdfsLocatedFileStatus -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#HdfsLocatedFileStatus" class="hiddenlink" target="rightframe"><b>HdfsLocatedFileStatus</b></A><br>
<!-- Field HFTP_DATE_FORMAT -->
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.HFTP_DATE_FORMAT" class="hiddenlink" target="rightframe">HFTP_DATE_FORMAT</A>
</nobr><br>
<!-- Field HFTP_SERVICE_NAME_KEY -->
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.HFTP_SERVICE_NAME_KEY" class="hiddenlink" target="rightframe">HFTP_SERVICE_NAME_KEY</A>
</nobr><br>
<!-- Field HFTP_TIMEZONE -->
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.HFTP_TIMEZONE" class="hiddenlink" target="rightframe">HFTP_TIMEZONE</A>
</nobr><br>
<!-- Class HsftpFileSystem.DummyTrustManager -->
<A HREF="pkg_org.apache.hadoop.hdfs.html#HsftpFileSystem.DummyTrustManager" class="hiddenlink" target="rightframe"><b>HsftpFileSystem.DummyTrustManager</b></A><br>
<!-- Field httpAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.httpAddress" class="hiddenlink" target="rightframe">httpAddress</A>
</nobr><br>
<!-- Field httpServer -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.httpServer" class="hiddenlink" target="rightframe">httpServer</A>
</nobr><br>
<!-- Field imageDigest -->
<A NAME="I"></A>
<br><font size="+2">I</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.imageDigest" class="hiddenlink" target="rightframe">imageDigest</A>
</nobr><br>
<!-- Method initialize -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.initialize_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>initialize</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method initReplicaRecovery -->
<i>initReplicaRecovery</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.initReplicaRecovery_added(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>RecoveringBlock</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Method initReplicaRecovery -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.initReplicaRecovery_added(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>RecoveringBlock</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method initReplicaRecovery -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.initReplicaRecovery_added(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>RecoveringBlock</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method initReplicaRecovery -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.initReplicaRecovery_added(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>RecoveringBlock</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol
</A></nobr><br>
<!-- Class INodeSymlink -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#INodeSymlink" class="hiddenlink" target="rightframe"><b>INodeSymlink</b></A><br>
<!-- Method instantiateDataNode -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode_added(java.lang.String[], org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)" class="hiddenlink" target="rightframe"><b>instantiateDataNode</b>
(<code>String[], Configuration, SecureResources</code>)</A></nobr><br>
<!-- Method is203LayoutVersion -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.is203LayoutVersion_added(int)" class="hiddenlink" target="rightframe"><b>is203LayoutVersion</b>
(<code>int</code>)</A></nobr><br>
<!-- Method isLastBlockComplete -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlocks.html#org.apache.hadoop.hdfs.protocol.LocatedBlocks.isLastBlockComplete_added()" class="hiddenlink" target="rightframe"><b>isLastBlockComplete</b>
()</A></nobr><br>
<!-- Method isMetaFilename -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.isMetaFilename_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>isMetaFilename</b>
(<code>String</code>)</A></nobr><br>
<!-- Method isPreUpgradableLayout -->
<i>isPreUpgradableLayout</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.isPreUpgradableLayout_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>StorageDirectory</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.common.Storage
</A></nobr><br>
<!-- Method isPreUpgradableLayout -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataStorage.html#org.apache.hadoop.hdfs.server.datanode.DataStorage.isPreUpgradableLayout_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>StorageDirectory</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataStorage
</A></nobr><br>
<!-- Method isPreUpgradableLayout -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.isPreUpgradableLayout_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>StorageDirectory</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSImage
</A></nobr><br>
<!-- Method isUpgradeFinalized -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.isUpgradeFinalized_added()" class="hiddenlink" target="rightframe"><b>isUpgradeFinalized</b>
()</A></nobr><br>
<!-- Method isValidRequestor -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.GetImageServlet.html#org.apache.hadoop.hdfs.server.namenode.GetImageServlet.isValidRequestor_added(java.lang.String, org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>isValidRequestor</b>
(<code>String, Configuration</code>)</A></nobr><br>
<!-- Method iterator -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.html#org.apache.hadoop.hdfs.protocol.BlockListAsLongs.iterator_added()" class="hiddenlink" target="rightframe"><b>iterator</b>
()</A></nobr><br>
<!-- Field JA_CHECKPOINT_TIME -->
<A NAME="J"></A>
<br><font size="+2">J</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.JA_CHECKPOINT_TIME" class="hiddenlink" target="rightframe">JA_CHECKPOINT_TIME</A>
</nobr><br>
<!-- Field JA_IS_ALIVE -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.JA_IS_ALIVE" class="hiddenlink" target="rightframe">JA_IS_ALIVE</A>
</nobr><br>
<!-- Field JA_JOURNAL -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.JA_JOURNAL" class="hiddenlink" target="rightframe">JA_JOURNAL</A>
</nobr><br>
<!-- Field JA_JSPOOL_START -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.JA_JSPOOL_START" class="hiddenlink" target="rightframe">JA_JSPOOL_START</A>
</nobr><br>
<!-- Class JMXGet -->
<A HREF="pkg_org.apache.hadoop.hdfs.tools.html#JMXGet" class="hiddenlink" target="rightframe"><b>JMXGet</b></A><br>
<!-- Method journal -->
<i>journal</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.journal_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, int, byte[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, int, int, byte[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method journal -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.journal_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, int, byte[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, int, int, byte[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<!-- Method journalSize -->
<i>journalSize</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.journalSize_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method journalSize -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.journalSize_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<!-- Class JspHelper -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.common.html#JspHelper" class="hiddenlink" target="rightframe"><b>JspHelper</b></A><br>
<!-- Class KeyUpdateCommand -->
<A NAME="K"></A>
<br><font size="+2">K</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#KeyUpdateCommand" class="hiddenlink" target="rightframe"><b>KeyUpdateCommand</b></A><br>
<!-- Field LAYOUT_VERSIONS_203 -->
<A NAME="L"></A>
<br><font size="+2">L</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.LAYOUT_VERSIONS_203" class="hiddenlink" target="rightframe">LAYOUT_VERSIONS_203</A>
</nobr><br>
<!-- Class LayoutVersion -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#LayoutVersion" class="hiddenlink" target="rightframe"><b>LayoutVersion</b></A><br>
<!-- Class LayoutVersion.Feature -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#LayoutVersion.Feature" class="hiddenlink" target="rightframe"><b>LayoutVersion.Feature</b></A><br>
<!-- Method listCorruptFileBlocks -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.listCorruptFileBlocks_added(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe"><b>listCorruptFileBlocks</b>
(<code>String, String</code>)</A></nobr><br>
<!-- Method listLocatedStatus -->
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.listLocatedStatus_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.PathFilter)" class="hiddenlink" target="rightframe"><b>listLocatedStatus</b>
(<code>Path, PathFilter</code>)</A></nobr><br>
<!-- Method listPaths -->
<i>listPaths</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.listPaths_added(java.lang.String, byte[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, byte[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method listPaths -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.listPaths_added(java.lang.String, byte[], boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, byte[], boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method listStorageDirectories -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.listStorageDirectories_added()" class="hiddenlink" target="rightframe"><b>listStorageDirectories</b>
()</A></nobr><br>
<!-- Method loadNamesystem -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>loadNamesystem</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Constructor LocatedBlocks -->
<i>LocatedBlocks</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlocks.html#org.apache.hadoop.hdfs.protocol.LocatedBlocks.ctor_added(long, boolean, java.util.List, org.apache.hadoop.hdfs.protocol.LocatedBlock, boolean)" class="hiddenlink" target="rightframe"><b>LocatedBlocks</b>
(<code>long, boolean, List, LocatedBlock, boolean</code>)</A></nobr>&nbsp;constructor<br>
<!-- Constructor LocatedBlocks -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlocks.html#org.apache.hadoop.hdfs.protocol.LocatedBlocks.ctor_added()" class="hiddenlink" target="rightframe"><b>LocatedBlocks</b>
()</A></nobr>&nbsp;constructor<br>
<!-- Method locatedBlocks2Locations -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.locatedBlocks2Locations_added(org.apache.hadoop.hdfs.protocol.LocatedBlocks)" class="hiddenlink" target="rightframe"><b>locatedBlocks2Locations</b>
(<code>LocatedBlocks</code>)</A></nobr><br>
<!-- Method logUpdateMasterKey -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.logUpdateMasterKey_added(org.apache.hadoop.security.token.delegation.DelegationKey)" class="hiddenlink" target="rightframe"><b>logUpdateMasterKey</b>
(<code>DelegationKey</code>)</A></nobr><br>
<!-- Field METADATA_EXTENSION -->
<A NAME="M"></A>
<br><font size="+2">M</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.METADATA_EXTENSION" class="hiddenlink" target="rightframe">METADATA_EXTENSION</A>
</nobr><br>
<!-- Field metaFilePattern -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.metaFilePattern" class="hiddenlink" target="rightframe">metaFilePattern</A>
</nobr><br>
<!-- Method mkdir -->
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.mkdir_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)" class="hiddenlink" target="rightframe"><b>mkdir</b>
(<code>Path, FsPermission</code>)</A></nobr><br>
<!-- Method moveCurrent -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.moveCurrent_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe"><b>moveCurrent</b>
(<code>StorageDirectory</code>)</A></nobr><br>
<!-- Method moveLastCheckpoint -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.moveLastCheckpoint_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe"><b>moveLastCheckpoint</b>
(<code>StorageDirectory</code>)</A></nobr><br>
<!-- Constructor NameNode -->
<A NAME="N"></A>
<br><font size="+2">N</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.ctor_added(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.common.HdfsConstants.NamenodeRole)" class="hiddenlink" target="rightframe"><b>NameNode</b>
(<code>Configuration, NamenodeRole</code>)</A></nobr>&nbsp;constructor<br>
<!-- Class NameNodeActivityMBean -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.metrics.html#NameNodeActivityMBean" class="hiddenlink" target="rightframe"><b>NameNodeActivityMBean</b></A><br>
<!-- Class NamenodeCommand -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#NamenodeCommand" class="hiddenlink" target="rightframe"><b>NamenodeCommand</b></A><br>
<!-- Class NameNodeMXBean -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#NameNodeMXBean" class="hiddenlink" target="rightframe"><b><i>NameNodeMXBean</i></b></A><br>
<!-- Class NamenodeProtocols -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#NamenodeProtocols" class="hiddenlink" target="rightframe"><b><i>NamenodeProtocols</i></b></A><br>
<!-- Class NamenodeRegistration -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#NamenodeRegistration" class="hiddenlink" target="rightframe"><b>NamenodeRegistration</b></A><br>
<!-- Field namesystem -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.namesystem" class="hiddenlink" target="rightframe">namesystem</A>
</nobr><br>
<!-- Field needKeyUpdate -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.needKeyUpdate" class="hiddenlink" target="rightframe">needKeyUpdate</A>
</nobr><br>
<!-- Field newImageDigest -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.newImageDigest" class="hiddenlink" target="rightframe">newImageDigest</A>
</nobr><br>
<!-- Class NodeRegistration -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#NodeRegistration" class="hiddenlink" target="rightframe"><b><i>NodeRegistration</i></b></A><br>
<!-- Field nodeRegistration -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.nodeRegistration" class="hiddenlink" target="rightframe">nodeRegistration</A>
</nobr><br>
<!-- Field NOTIFY -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.NOTIFY" class="hiddenlink" target="rightframe">NOTIFY</A>
</nobr><br>
<!-- Class NSQuotaExceededException -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#NSQuotaExceededException" class="hiddenlink" target="rightframe"><b>NSQuotaExceededException</b></A><br>
<!-- Method numCorruptReplicas -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.numCorruptReplicas_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe"><b>numCorruptReplicas</b>
(<code>Block</code>)</A></nobr><br>
<!-- Field numcreateSymlinkOps -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.numcreateSymlinkOps" class="hiddenlink" target="rightframe">numcreateSymlinkOps</A>
</nobr><br>
<!-- Field numExpiredHeartbeats -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics.numExpiredHeartbeats" class="hiddenlink" target="rightframe">numExpiredHeartbeats</A>
</nobr><br>
<!-- Field numFileInfoOps -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.numFileInfoOps" class="hiddenlink" target="rightframe">numFileInfoOps</A>
</nobr><br>
<!-- Field numFilesDeleted -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.numFilesDeleted" class="hiddenlink" target="rightframe">numFilesDeleted</A>
</nobr><br>
<!-- Field numFilesInGetListingOps -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.numFilesInGetListingOps" class="hiddenlink" target="rightframe">numFilesInGetListingOps</A>
</nobr><br>
<!-- Field numgetLinkTargetOps -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.html#org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.numgetLinkTargetOps" class="hiddenlink" target="rightframe">numgetLinkTargetOps</A>
</nobr><br>
<!-- Field OP_STATUS_ERROR_ACCESS_TOKEN -->
<A NAME="O"></A>
<br><font size="+2">O</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DataTransferProtocol.html#org.apache.hadoop.hdfs.protocol.DataTransferProtocol.OP_STATUS_ERROR_ACCESS_TOKEN" class="hiddenlink" target="rightframe">OP_STATUS_ERROR_ACCESS_TOKEN</A>
</nobr><br>
<!-- Method open -->
<i>open</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.open_added(java.lang.String, int, boolean, org.apache.hadoop.fs.FileSystem.Statistics)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, int, boolean, Statistics</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method open -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.open_added(java.lang.String, int, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, int, boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Package org.apache.hadoop.fs -->
<A HREF="changes-summary.html#org.apache.hadoop.fs" class="hiddenlink" target="rightframe"><b>org.apache.hadoop.fs</b></A><br>
<!-- Package org.apache.hadoop.hdfs.security.token.block -->
<A HREF="changes-summary.html#org.apache.hadoop.hdfs.security.token.block" class="hiddenlink" target="rightframe"><b>org.apache.hadoop.hdfs.security.token.block</b></A><br>
<!-- Package org.apache.hadoop.hdfs.security.token.delegation -->
<A HREF="changes-summary.html#org.apache.hadoop.hdfs.security.token.delegation" class="hiddenlink" target="rightframe"><b>org.apache.hadoop.hdfs.security.token.delegation</b></A><br>
<!-- Package org.apache.hadoop.hdfs.tools.offlineImageViewer -->
<A HREF="changes-summary.html#org.apache.hadoop.hdfs.tools.offlineImageViewer" class="hiddenlink" target="rightframe"><b>org.apache.hadoop.hdfs.tools.offlineImageViewer</b></A><br>
<!-- Package org.apache.hadoop.hdfs.util -->
<A HREF="changes-summary.html#org.apache.hadoop.hdfs.util" class="hiddenlink" target="rightframe"><b>org.apache.hadoop.hdfs.util</b></A><br>
<!-- Field pathName -->
<A NAME="P"></A>
<br><font size="+2">P</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.QuotaExceededException.html#org.apache.hadoop.hdfs.protocol.QuotaExceededException.pathName" class="hiddenlink" target="rightframe">pathName</A>
</nobr><br>
<!-- Method primitiveCreate -->
<i>primitiveCreate</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.primitiveCreate_added(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, short, long, org.apache.hadoop.util.Progressable, int, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, FsPermission, EnumSet, boolean, short, long, Progressable, int, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method primitiveCreate -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.primitiveCreate_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, int, short, long, org.apache.hadoop.util.Progressable, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path, FsPermission, EnumSet, int, short, long, Progressable, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method primitiveMkdir -->
<i>primitiveMkdir</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.primitiveMkdir_added(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, FsPermission</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method primitiveMkdir -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.primitiveMkdir_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path, FsPermission</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method printTopology -->
<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSAdmin.html#org.apache.hadoop.hdfs.tools.DFSAdmin.printTopology_added()" class="hiddenlink" target="rightframe"><b>printTopology</b>
()</A></nobr><br>
<!-- Field quota -->
<A NAME="Q"></A>
<br><font size="+2">Q</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.QuotaExceededException.html#org.apache.hadoop.hdfs.protocol.QuotaExceededException.quota" class="hiddenlink" target="rightframe">quota</A>
</nobr><br>
<!-- Constructor QuotaExceededException -->
<i>QuotaExceededException</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.QuotaExceededException.html#org.apache.hadoop.hdfs.protocol.QuotaExceededException.ctor_added(long, long)" class="hiddenlink" target="rightframe"><b>QuotaExceededException</b>
(<code>long, long</code>)</A></nobr>&nbsp;constructor<br>
<!-- Constructor QuotaExceededException -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.QuotaExceededException.html#org.apache.hadoop.hdfs.protocol.QuotaExceededException.ctor_added()" class="hiddenlink" target="rightframe"><b>QuotaExceededException</b>
()</A></nobr>&nbsp;constructor<br>
<!-- Method read -->
<A NAME="R"></A>
<br><font size="+2">R</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>read</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DatanodeInfo.html#org.apache.hadoop.hdfs.protocol.DatanodeInfo.read_added(java.io.DataInput)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>DataInput</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.DatanodeInfo
</A></nobr><br>
<!-- Method read -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlock.html#org.apache.hadoop.hdfs.protocol.LocatedBlock.read_added(java.io.DataInput)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>DataInput</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.LocatedBlock
</A></nobr><br>
<!-- Field READ_TIMEOUT_EXTENSION -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.HdfsConstants.html#org.apache.hadoop.hdfs.server.common.HdfsConstants.READ_TIMEOUT_EXTENSION" class="hiddenlink" target="rightframe">READ_TIMEOUT_EXTENSION</A>
</nobr><br>
<!-- Method readFields -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.StorageInfo.html#org.apache.hadoop.hdfs.server.common.StorageInfo.readFields_added(java.io.DataInput)" class="hiddenlink" target="rightframe"><b>readFields</b>
(<code>DataInput</code>)</A></nobr><br>
<!-- Method readId -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.readId_added(java.io.DataInput)" class="hiddenlink" target="rightframe"><b>readId</b>
(<code>DataInput</code>)</A></nobr><br>
<!-- Method recoverAppend -->
<i>recoverAppend</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.recoverAppend_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method recoverAppend -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.recoverAppend_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method recoverClose -->
<i>recoverClose</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.recoverClose_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method recoverClose -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.recoverClose_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method recoverLease -->
<i>recoverLease</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.recoverLease_added(org.apache.hadoop.fs.Path)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method recoverLease -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.recoverLease_added(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method recoverLease -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.recoverLease_added(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method recoverRbw -->
<i>recoverRbw</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.recoverRbw_added(org.apache.hadoop.hdfs.protocol.Block, long, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method recoverRbw -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.recoverRbw_added(org.apache.hadoop.hdfs.protocol.Block, long, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Class RecoveryInProgressException -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#RecoveryInProgressException" class="hiddenlink" target="rightframe"><b>RecoveryInProgressException</b></A><br>
<!-- Method refreshSuperUserGroupsConfiguration -->
<i>refreshSuperUserGroupsConfiguration</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.refreshSuperUserGroupsConfiguration_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method refreshSuperUserGroupsConfiguration -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSAdmin.html#org.apache.hadoop.hdfs.tools.DFSAdmin.refreshSuperUserGroupsConfiguration_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.tools.DFSAdmin
</A></nobr><br>
<!-- Method refreshUserToGroupsMappings -->
<i>refreshUserToGroupsMappings</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.refreshUserToGroupsMappings_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method refreshUserToGroupsMappings -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSAdmin.html#org.apache.hadoop.hdfs.tools.DFSAdmin.refreshUserToGroupsMappings_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.tools.DFSAdmin
</A></nobr><br>
<!-- Method register -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.register_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe"><b>register</b>
(<code>NamenodeRegistration</code>)</A></nobr><br>
<!-- Method registerDatanode -->
<i>registerDatanode</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.registerDatanode_added(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>DatanodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method registerDatanode -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.registerDatanode_added(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>DatanodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol
</A></nobr><br>
<!-- Method rename -->
<i>rename</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.rename_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, Rename[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method rename -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.rename_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Options.Rename[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path, Path, Rename[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method rename -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.rename_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, Rename[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method rename -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.rename_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, Rename[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method renewDelegationToken -->
<i>renewDelegationToken</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.renewDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<!-- Method renewDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.renewDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method renewDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.renewDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method renewDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<!-- Method renewDelegationToken -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.renewDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Class RenewDelegationTokenServlet -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#RenewDelegationTokenServlet" class="hiddenlink" target="rightframe"><b>RenewDelegationTokenServlet</b></A><br>
<!-- Class Replica -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html#Replica" class="hiddenlink" target="rightframe"><b><i>Replica</i></b></A><br>
<!-- Class ReplicaInfo -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html#ReplicaInfo" class="hiddenlink" target="rightframe"><b>ReplicaInfo</b></A><br>
<!-- Class ReplicaNotFoundException -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html#ReplicaNotFoundException" class="hiddenlink" target="rightframe"><b>ReplicaNotFoundException</b></A><br>
<!-- Class ReplicaRecoveryInfo -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#ReplicaRecoveryInfo" class="hiddenlink" target="rightframe"><b>ReplicaRecoveryInfo</b></A><br>
<!-- Method restoreFailedStorage -->
<i>restoreFailedStorage</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.restoreFailedStorage_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<!-- Method restoreFailedStorage -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.restoreFailedStorage_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method restoreFailedStorage -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.restoreFailedStorage_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method restoreFaileStorage -->
<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSAdmin.html#org.apache.hadoop.hdfs.tools.DFSAdmin.restoreFaileStorage_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>restoreFaileStorage</b>
(<code>String</code>)</A></nobr><br>
<!-- Field role -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.role" class="hiddenlink" target="rightframe">role</A>
</nobr><br>
<!-- Field rpcAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.rpcAddress" class="hiddenlink" target="rightframe">rpcAddress</A>
</nobr><br>
<!-- Constructor SafeModeException -->
<A NAME="S"></A>
<br><font size="+2">S</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.SafeModeException.html#org.apache.hadoop.hdfs.server.namenode.SafeModeException.ctor_added()" class="hiddenlink" target="rightframe"><b>SafeModeException</b>
()</A></nobr>&nbsp;constructor<br>
<!-- Method saveCurrent -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.saveCurrent_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe"><b>saveCurrent</b>
(<code>StorageDirectory</code>)</A></nobr><br>
<!-- Class SecureDataNodeStarter -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html#SecureDataNodeStarter" class="hiddenlink" target="rightframe"><b>SecureDataNodeStarter</b></A><br>
<!-- Class SecureDataNodeStarter.SecureResources -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.datanode.html#SecureDataNodeStarter.SecureResources" class="hiddenlink" target="rightframe"><b>SecureDataNodeStarter.SecureResources</b></A><br>
<!-- Method secureMain -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain_added(java.lang.String[], org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)" class="hiddenlink" target="rightframe"><b>secureMain</b>
(<code>String[], SecureResources</code>)</A></nobr><br>
<!-- Field serialVersionUID -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.QuotaExceededException.html#org.apache.hadoop.hdfs.protocol.QuotaExceededException.serialVersionUID" class="hiddenlink" target="rightframe">serialVersionUID</A>
</nobr><br>
<!-- Field SERVER_DEFAULTS_VALIDITY_PERIOD -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.SERVER_DEFAULTS_VALIDITY_PERIOD" class="hiddenlink" target="rightframe">SERVER_DEFAULTS_VALIDITY_PERIOD</A>
</nobr><br>
<!-- Class ServerCommand -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.protocol.html#ServerCommand" class="hiddenlink" target="rightframe"><b>ServerCommand</b></A><br>
<!-- Field serviceRPCAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.serviceRPCAddress" class="hiddenlink" target="rightframe">serviceRPCAddress</A>
</nobr><br>
<!-- Field serviceRpcServer -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.serviceRpcServer" class="hiddenlink" target="rightframe">serviceRpcServer</A>
</nobr><br>
<!-- Method setBlockToken -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlock.html#org.apache.hadoop.hdfs.protocol.LocatedBlock.setBlockToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe"><b>setBlockToken</b>
(<code>Token</code>)</A></nobr><br>
<!-- Method setBufferCapacity -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html#org.apache.hadoop.hdfs.server.namenode.FSEditLog.setBufferCapacity_added(int)" class="hiddenlink" target="rightframe"><b>setBufferCapacity</b>
(<code>int</code>)</A></nobr><br>
<!-- Method setHttpServerAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.setHttpServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>setHttpServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method setImageDigest -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.setImageDigest_added(org.apache.hadoop.io.MD5Hash)" class="hiddenlink" target="rightframe"><b>setImageDigest</b>
(<code>MD5Hash</code>)</A></nobr><br>
<!-- Method setRestoreFailedStorage -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.setRestoreFailedStorage_added(boolean)" class="hiddenlink" target="rightframe"><b>setRestoreFailedStorage</b>
(<code>boolean</code>)</A></nobr><br>
<!-- Method setRpcServerAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.setRpcServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>setRpcServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method setRpcServiceServerAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.setRpcServiceServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>setRpcServiceServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<!-- Method setServiceAddress -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.setServiceAddress_added(org.apache.hadoop.conf.Configuration, java.lang.String)" class="hiddenlink" target="rightframe"><b>setServiceAddress</b>
(<code>Configuration, String</code>)</A></nobr><br>
<!-- Method startCheckpoint -->
<i>startCheckpoint</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.startCheckpoint_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method startCheckpoint -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.startCheckpoint_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<!-- Field stopRequested -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.stopRequested" class="hiddenlink" target="rightframe">stopRequested</A>
</nobr><br>
<!-- Method string2Bytes -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.string2Bytes_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>string2Bytes</b>
(<code>String</code>)</A></nobr><br>
<!-- Method stringAsURI -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Util.html#org.apache.hadoop.hdfs.server.common.Util.stringAsURI_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>stringAsURI</b>
(<code>String</code>)</A></nobr><br>
<!-- Method stringCollectionAsURIs -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Util.html#org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs_added(java.util.Collection)" class="hiddenlink" target="rightframe"><b>stringCollectionAsURIs</b>
(<code>Collection</code>)</A></nobr><br>
<!-- Method stringifyToken -->
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.stringifyToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe"><b>stringifyToken</b>
(<code>Token</code>)</A></nobr><br>
<!-- Method toNodeRole -->
<A NAME="T"></A>
<br><font size="+2">T</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.HdfsConstants.StartupOption.html#org.apache.hadoop.hdfs.server.common.HdfsConstants.StartupOption.toNodeRole_added()" class="hiddenlink" target="rightframe"><b>toNodeRole</b>
()</A></nobr><br>
<!-- Method toString -->
<i>toString</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlock.html#org.apache.hadoop.hdfs.protocol.LocatedBlock.toString_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.LocatedBlock
</A></nobr><br>
<!-- Method toString -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlocks.html#org.apache.hadoop.hdfs.protocol.LocatedBlocks.toString_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.LocatedBlocks
</A></nobr><br>
<!-- Method toString -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.html#org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.toString_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode
</A></nobr><br>
<!-- Method unlinkBlock -->
<A NAME="U"></A>
<br><font size="+2">U</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.unlinkBlock_added(org.apache.hadoop.hdfs.protocol.Block, int)" class="hiddenlink" target="rightframe"><b>unlinkBlock</b>
(<code>Block, int</code>)</A></nobr><br>
<!-- Class UnregisteredNodeException -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#UnregisteredNodeException" class="hiddenlink" target="rightframe"><b>UnregisteredNodeException</b></A><br>
<!-- Class UnresolvedPathException -->
<A HREF="pkg_org.apache.hadoop.hdfs.protocol.html#UnresolvedPathException" class="hiddenlink" target="rightframe"><b>UnresolvedPathException</b></A><br>
<!-- Class UnsupportedActionException -->
<A HREF="pkg_org.apache.hadoop.hdfs.server.namenode.html#UnsupportedActionException" class="hiddenlink" target="rightframe"><b>UnsupportedActionException</b></A><br>
<!-- Method updateBlockForPipeline -->
<i>updateBlockForPipeline</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.updateBlockForPipeline_added(org.apache.hadoop.hdfs.protocol.Block, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method updateBlockForPipeline -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.updateBlockForPipeline_added(org.apache.hadoop.hdfs.protocol.Block, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method updatePipeline -->
<i>updatePipeline</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.updatePipeline_added(java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeID[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, Block, Block, DatanodeID[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<!-- Method updatePipeline -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.updatePipeline_added(java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeID[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, Block, Block, DatanodeID[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<!-- Method updateQuery -->
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.updateQuery_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>updateQuery</b>
(<code>String</code>)</A></nobr><br>
<!-- Method updateReplicaUnderRecovery -->
<i>updateReplicaUnderRecovery</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.updateReplicaUnderRecovery_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<!-- Method updateReplicaUnderRecovery -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.updateReplicaUnderRecovery_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
<!-- Method updateReplicaUnderRecovery -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.updateReplicaUnderRecovery_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<!-- Method updateReplicaUnderRecovery -->
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.updateReplicaUnderRecovery_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol
</A></nobr><br>
<!-- Method versionRequest -->
<A NAME="V"></A>
<br><font size="+2">V</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.versionRequest_added()" class="hiddenlink" target="rightframe"><b>versionRequest</b>
()</A></nobr><br>
<!-- Field volumeFailures -->
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.metrics.DataNodeMetrics.html#org.apache.hadoop.hdfs.server.datanode.metrics.DataNodeMetrics.volumeFailures" class="hiddenlink" target="rightframe">volumeFailures</A>
</nobr><br>
<!-- Method write -->
<A NAME="W"></A>
<br><font size="+2">W</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#K"><font size="-2">K</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#Q"><font size="-2">Q</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.StorageInfo.html#org.apache.hadoop.hdfs.server.common.StorageInfo.write_added(java.io.DataOutput)" class="hiddenlink" target="rightframe"><b>write</b>
(<code>DataOutput</code>)</A></nobr><br>
<!-- Method writeId -->
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.writeId_added(java.io.DataOutput)" class="hiddenlink" target="rightframe"><b>writeId</b>
(<code>DataOutput</code>)</A></nobr><br>
</BODY>
</HTML>
