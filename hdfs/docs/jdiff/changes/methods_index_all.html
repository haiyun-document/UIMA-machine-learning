<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Frameset//EN""http://www.w3.org/TR/REC-html40/frameset.dtd">
<HTML>
<HEAD>
<meta name="generator" content="JDiff v1.0.9">
<!-- Generated by the JDiff Javadoc doclet -->
<!-- (http://www.jdiff.org) -->
<meta name="description" content="JDiff is a Javadoc doclet which generates an HTML report of all the packages, classes, constructors, methods, and fields which have been removed, added or changed in any way, including their documentation, when two APIs are compared.">
<meta name="keywords" content="diff, jdiff, javadiff, java diff, java difference, API difference, difference between two APIs, API diff, Javadoc, doclet">
<TITLE>
Method Differences Index
</TITLE>
<LINK REL="stylesheet" TYPE="text/css" HREF="../stylesheet-jdiff.css" TITLE="Style">
</HEAD>
<BODY>
<a NAME="topheader"></a>
<table summary="Index for Methods" width="100%" border="0" cellspacing="0" cellpadding="0">
  <tr>
  <td bgcolor="#FFFFCC">
<font size="+1"><a href="methods_index_all.html" class="staysblack">All Methods</a></font>
  </td>
  </tr>
  <tr>
  <td bgcolor="#FFFFFF">
  <FONT SIZE="-1">
<A HREF="methods_index_removals.html" class="hiddenlink">Removals</A>
  </FONT>
  </td>
  </tr>
  <tr>
  <td bgcolor="#FFFFFF">
  <FONT SIZE="-1">
<A HREF="methods_index_additions.html"class="hiddenlink">Additions</A>
  </FONT>
  </td>
  </tr>
  <tr>
  <td bgcolor="#FFFFFF">
  <FONT SIZE="-1">
<A HREF="methods_index_changes.html"class="hiddenlink">Changes</A>
  </FONT>
  </td>
  </tr>
  <tr>
  <td>
<font size="-2"><b>Bold</b>&nbsp;is&nbsp;New,&nbsp;<strike>strike</strike>&nbsp;is&nbsp;deleted</font>
  </td>
  </tr>
</table><br>
<A NAME="A"></A>
<br><font size="+2">A</font>&nbsp;
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>abandonBlock</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.abandonBlock_changed(org.apache.hadoop.hdfs.protocol.Block, java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>Block, String, String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.abandonBlock_changed(org.apache.hadoop.hdfs.protocol.Block, java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>Block, String, String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<i>addBlock</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock_changed(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo[])" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String, Block, DatanodeInfo[]</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock_changed(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo[])" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String, Block, DatanodeInfo[]</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<i>adjustCrcChannelPosition</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.adjustCrcChannelPosition_added(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, BlockWriteStreams, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.adjustCrcChannelPosition_added(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, BlockWriteStreams, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<i>append</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.append_changed(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.append_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.append_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<A NAME="B"></A>
<br><font size="+2">B</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.byteArray2String_added(byte[][])" class="hiddenlink" target="rightframe"><b>byteArray2String</b>
(<code>byte[][]</code>)</A></nobr><br>
<i>bytes2byteArray</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.bytes2byteArray_added(byte[], byte)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>byte[], byte</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSUtil
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.bytes2byteArray_added(byte[], int, byte)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>byte[], int, byte</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSUtil
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.bytes2String_added(byte[])" class="hiddenlink" target="rightframe"><b>bytes2String</b>
(<code>byte[]</code>)</A></nobr><br>
<A NAME="C"></A>
<br><font size="+2">C</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>cancelDelegationToken</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.cancelDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.cancelDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.cancelDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.cancelDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.cancelDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.checkAndUpdate_added(long, java.io.File, java.io.File, org.apache.hadoop.hdfs.server.datanode.FSDataset.FSVolume)" class="hiddenlink" target="rightframe"><b>checkAndUpdate</b>
(<code>long, File, File, FSVolume</code>)</A></nobr><br>
<i>checkDiskError</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.checkDiskError_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.checkDiskError_removed(java.io.IOException)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>IOException</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.checkDiskError_added(java.lang.Exception)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Exception</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.checkDiskError_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html#org.apache.hadoop.hdfs.server.namenode.FSEditLog.close_removed()" class="hiddenlink" target="rightframe"><strike>close</strike>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.GenerationStamp.html#org.apache.hadoop.hdfs.server.common.GenerationStamp.compare_removed(long, long)" class="hiddenlink" target="rightframe"><strike>compare</strike>
(<code>long, long</code>)</A></nobr><br>
<i>complete</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.complete_changed(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String, Block</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.complete_changed(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String, Block</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile_changed(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">completeFile
(<code>String, String, Block</code>)</A></nobr><br>
<i>concat</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.concat_added(java.lang.String, java.lang.String[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.concat_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path, Path[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.concat_added(java.lang.String, java.lang.String[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concat_added(java.lang.String, java.lang.String[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.concat_added(java.lang.String, java.lang.String[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.html#org.apache.hadoop.hdfs.protocol.BlockListAsLongs.convertToArrayLongs_removed(org.apache.hadoop.hdfs.protocol.Block[])" class="hiddenlink" target="rightframe"><strike>convertToArrayLongs</strike>
(<code>Block[]</code>)</A></nobr><br>
<i>corruptPreUpgradeStorage</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.corruptPreUpgradeStorage_removed(java.io.File)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>File</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.common.Storage
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataStorage.html#org.apache.hadoop.hdfs.server.datanode.DataStorage.corruptPreUpgradeStorage_removed(java.io.File)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>File</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataStorage
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.corruptPreUpgradeStorage_removed(java.io.File)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>File</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSImage
</A></nobr><br>
<i>create</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.create_removed(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean, short, long, org.apache.hadoop.util.Progressable, int)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>String, FsPermission, boolean, short, long, Progressable, int</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.create_added(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, short, long, org.apache.hadoop.util.Progressable, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, FsPermission, EnumSet, boolean, short, long, Progressable, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.create_added(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, short, long, org.apache.hadoop.util.Progressable, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, FsPermission, EnumSet, short, long, Progressable, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.create_changed(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, org.apache.hadoop.io.EnumSetWritable, boolean, short, long)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, FsPermission, String, EnumSetWritable, boolean, short, long</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.create_changed(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, org.apache.hadoop.io.EnumSetWritable, boolean, short, long)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, FsPermission, String, EnumSetWritable, boolean, short, long</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode_added(java.lang.String[], org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)" class="hiddenlink" target="rightframe"><b>createDataNode</b>
(<code>String[], Configuration, SecureResources</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html#org.apache.hadoop.hdfs.server.namenode.FSEditLog.createEditLogFile_removed(java.io.File)" class="hiddenlink" target="rightframe"><strike>createEditLogFile</strike>
(<code>File</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.createInterDataNodeProtocolProxy_changed(org.apache.hadoop.hdfs.protocol.DatanodeID, org.apache.hadoop.conf.Configuration, int)" class="hiddenlink" target="rightframe">createInterDataNodeProtocolProxy
(<code>DatanodeID, Configuration, int</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.createNonRecursive_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, int, short, long, org.apache.hadoop.util.Progressable)" class="hiddenlink" target="rightframe"><b>createNonRecursive</b>
(<code>Path, FsPermission, EnumSet, int, short, long, Progressable</code>)</A></nobr><br>
<i>createRbw</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.createRbw_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.createRbw_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<i>createSymlink</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.createSymlink_added(java.lang.String, java.lang.String, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.createSymlink_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, FsPermission, boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.createSymlink_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.PermissionStatus, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, PermissionStatus, boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.createSymlink_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, FsPermission, boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<i>createTemporary</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.createTemporary_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.createTemporary_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FileDataServlet.html#org.apache.hadoop.hdfs.server.namenode.FileDataServlet.createUri_changed(java.lang.String, org.apache.hadoop.hdfs.protocol.HdfsFileStatus, org.apache.hadoop.security.UserGroupInformation, org.apache.hadoop.hdfs.protocol.ClientProtocol, javax.servlet.http.HttpServletRequest, java.lang.String)" class="hiddenlink" target="rightframe">createUri
(<code>String, HdfsFileStatus, UserGroupInformation, ClientProtocol, HttpServletRequest, String</code>)</A></nobr><br>
<A NAME="D"></A>
<br><font size="+2">D</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>delete</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.delete_removed(org.apache.hadoop.fs.Path)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Path</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.delete_removed(org.apache.hadoop.fs.Path)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Path</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.HftpFileSystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.delete_changed(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.delete_changed(java.lang.String, boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete_changed(java.lang.String, boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.detachBlock_removed(org.apache.hadoop.hdfs.protocol.Block, int)" class="hiddenlink" target="rightframe"><strike>detachBlock</strike>
(<code>Block, int</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FsckServlet.html#org.apache.hadoop.hdfs.server.namenode.FsckServlet.doGet_changed(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)" class="hiddenlink" target="rightframe">doGet
(<code>HttpServletRequest, HttpServletResponse</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.html#org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork_added()" class="hiddenlink" target="rightframe"><b>doWork</b>
()</A></nobr><br>
<A NAME="E"></A>
<br><font size="+2">E</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>endCheckpoint</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.endCheckpoint_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, CheckpointSignature</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.endCheckpoint_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, CheckpointSignature</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<i>equals</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DatanodeInfo.html#org.apache.hadoop.hdfs.protocol.DatanodeInfo.equals_changed(java.lang.Object)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>Object</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.DatanodeInfo
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.equals_changed(java.lang.Object)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>Object</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.html#org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.equals_changed(java.lang.Object)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>Object</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.GenerationStamp.html#org.apache.hadoop.hdfs.server.common.GenerationStamp.equalsWithWildcard_removed(long, long)" class="hiddenlink" target="rightframe"><strike>equalsWithWildcard</strike>
(<code>long, long</code>)</A></nobr><br>
<i>errorReport</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.errorReport_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, int, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.errorReport_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, int, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<A NAME="F"></A>
<br><font size="+2">F</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Util.html#org.apache.hadoop.hdfs.server.common.Util.fileAsURI_added(java.io.File)" class="hiddenlink" target="rightframe"><b>fileAsURI</b>
(<code>File</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.filename2id_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>filename2id</b>
(<code>String</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.html#org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.fsck_changed()" class="hiddenlink" target="rightframe">fsck
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.fsync_changed(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">fsync
(<code>String, String</code>)</A></nobr><br>
<A NAME="G"></A>
<br><font size="+2">G</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeCommand.html#org.apache.hadoop.hdfs.server.protocol.DatanodeCommand.getAction_changed()" class="hiddenlink" target="rightframe">getAction
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock_changed(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, java.util.HashMap)" class="hiddenlink" target="rightframe">getAdditionalBlock
(<code>String, String, Block, HashMap</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.html#org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.getAddress_added()" class="hiddenlink" target="rightframe"><b>getAddress</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockCapacity_added()" class="hiddenlink" target="rightframe"><b>getBlockCapacity</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.getBlockId_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>getBlockId</b>
(<code>String</code>)</A></nobr><br>
<i>getBlockKeys</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getBlockKeys_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.getBlockKeys_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.html#org.apache.hadoop.hdfs.protocol.BlockListAsLongs.getBlockListAsLongs_added()" class="hiddenlink" target="rightframe"><b>getBlockListAsLongs</b>
()</A></nobr><br>
<i>getBlockLocations</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getBlockLocations_changed(java.lang.String, long, long)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, long, long</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations_changed(java.lang.String, long, long)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, long, long</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations_removed(java.lang.String, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>String, long, long</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations_removed(java.lang.String, long, long, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>String, long, long, boolean</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<i>getBlockMetaDataInfo</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getBlockMetaDataInfo_removed(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.getBlockMetaDataInfo_removed(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol
</A></nobr><br>
<i>getBlockReport</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.getBlockReport_changed()" class="hiddenlink" target="rightframe">type&nbsp;
()&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.getBlockReport_changed()" class="hiddenlink" target="rightframe">type&nbsp;
()&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.html#org.apache.hadoop.hdfs.protocol.BlockListAsLongs.getBlockReportIterator_added()" class="hiddenlink" target="rightframe"><b>getBlockReportIterator</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlock.html#org.apache.hadoop.hdfs.protocol.LocatedBlock.getBlockToken_added()" class="hiddenlink" target="rightframe"><b>getBlockToken</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.getCanonicalServiceName_added()" class="hiddenlink" target="rightframe"><b>getCanonicalServiceName</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.DiskStatus.html#org.apache.hadoop.hdfs.DistributedFileSystem.DiskStatus.getCapacity_removed()" class="hiddenlink" target="rightframe"><strike>getCapacity</strike>
()</A></nobr><br>
<i>getChannelPosition</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.getChannelPosition_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, BlockWriteStreams</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.getChannelPosition_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, BlockWriteStreams</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<i>getContentSummary</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.getContentSummary_added(org.apache.hadoop.fs.Path)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.HftpFileSystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getContentSummary_changed(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getCorruptReplicaBlocks_added()" class="hiddenlink" target="rightframe"><b>getCorruptReplicaBlocks</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getCorruptReplicaBlocksCount_removed()" class="hiddenlink" target="rightframe"><strike>getCorruptReplicaBlocksCount</strike>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getDatanodeRegistration_added()" class="hiddenlink" target="rightframe"><b>getDatanodeRegistration</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.getDateFormat_added()" class="hiddenlink" target="rightframe"><b>getDateFormat</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDeadNodes_added()" class="hiddenlink" target="rightframe"><b>getDeadNodes</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDecommissioningNodes_added()" class="hiddenlink" target="rightframe"><b>getDecommissioningNodes</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDecomNodes_added()" class="hiddenlink" target="rightframe"><b>getDecomNodes</b>
()</A></nobr><br>
<i>getDefaultPort</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getDefaultPort_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.getDefaultPort_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.HftpFileSystem
</A></nobr><br>
<i>getDelegationToken</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getDelegationToken_added(org.apache.hadoop.io.Text)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Text</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getDelegationToken_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getDelegationToken_added(org.apache.hadoop.io.Text)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Text</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.getDelegationToken_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.HftpFileSystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getDelegationToken_added(org.apache.hadoop.io.Text)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Text</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDelegationToken_added(org.apache.hadoop.io.Text)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Text</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getDelegationToken_added(org.apache.hadoop.io.Text)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Text</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDelegationTokenSecretManager_added()" class="hiddenlink" target="rightframe"><b>getDelegationTokenSecretManager</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.StreamFile.html#org.apache.hadoop.hdfs.server.namenode.StreamFile.getDFSClient_changed(javax.servlet.http.HttpServletRequest)" class="hiddenlink" target="rightframe">getDFSClient
(<code>HttpServletRequest</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDFSNameNodeAddress_removed()" class="hiddenlink" target="rightframe"><strike>getDFSNameNodeAddress</strike>
()</A></nobr><br>
<i>getDiskStatus</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getDiskStatus_changed()" class="hiddenlink" target="rightframe">type&nbsp;
()&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getDiskStatus_changed()" class="hiddenlink" target="rightframe">type&nbsp;
()&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.getEditLogSize_changed()" class="hiddenlink" target="rightframe">getEditLogSize
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getExcessBlocks_added()" class="hiddenlink" target="rightframe"><b>getExcessBlocks</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getFileBlockLocations_added(org.apache.hadoop.fs.Path, long, long)" class="hiddenlink" target="rightframe"><b>getFileBlockLocations</b>
(<code>Path, long, long</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getFileChecksum_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>getFileChecksum</b>
(<code>String</code>)</A></nobr><br>
<i>getFileInfo</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getFileInfo_changed(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo_changed(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo_changed(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<i>getFileLinkInfo</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getFileLinkInfo_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileLinkInfo_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getFileLinkInfo_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFree_added()" class="hiddenlink" target="rightframe"><b>getFree</b>
()</A></nobr><br>
<i>getFSNamesystem</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.getFSNamesystem_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSImage
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFSNamesystem_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.UpgradeObjectNamenode.html#org.apache.hadoop.hdfs.server.namenode.UpgradeObjectNamenode.getFSNamesystem_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.UpgradeObjectNamenode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.getGenerationStamp_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>getGenerationStamp</b>
(<code>String</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getHints_removed(java.lang.String, long, long)" class="hiddenlink" target="rightframe"><strike>getHints</strike>
(<code>String, long, long</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getHostPortString_added(java.net.InetSocketAddress)" class="hiddenlink" target="rightframe"><b>getHostPortString</b>
(<code>InetSocketAddress</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.html#org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.getHttpAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getHttpAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getHttpPort_added()" class="hiddenlink" target="rightframe"><b>getHttpPort</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getHttpServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getHttpServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getInfoAddr_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getInfoAddr</b>
(<code>Configuration</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getInfoPort_added()" class="hiddenlink" target="rightframe"><b>getInfoPort</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getInfoServer_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getInfoServer</b>
(<code>Configuration</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlocks.html#org.apache.hadoop.hdfs.protocol.LocatedBlocks.getLastLocatedBlock_added()" class="hiddenlink" target="rightframe"><b>getLastLocatedBlock</b>
()</A></nobr><br>
<i>getLinkTarget</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getLinkTarget_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getLinkTarget_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getLinkTarget_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<i>getListing</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getListing_changed(java.lang.String, byte[], boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, byte[], boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing_changed(java.lang.String, byte[], boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, byte[], boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getListing_changed(java.lang.String, byte[], boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, byte[], boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getLiveNodes_added()" class="hiddenlink" target="rightframe"><b>getLiveNodes</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getName_removed()" class="hiddenlink" target="rightframe"><strike>getName</strike>
()</A></nobr><br>
<i>getNamenode</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getNamenode_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenode_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddress_added()" class="hiddenlink" target="rightframe"><b>getNamenodeAddress</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getNameNodeAddrForClient_added()" class="hiddenlink" target="rightframe"><b>getNameNodeAddrForClient</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getNamesystem_removed()" class="hiddenlink" target="rightframe"><strike>getNamesystem</strike>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNonDfsUsedSpace_added()" class="hiddenlink" target="rightframe"><b>getNonDfsUsedSpace</b>
()</A></nobr><br>
<i>getNumDeadDataNodes</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNumDeadDataNodes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.getNumDeadDataNodes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean
</A></nobr><br>
<i>getNumFailedVolumes</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.getNumFailedVolumes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.metrics.FSDatasetMBean.html#org.apache.hadoop.hdfs.server.datanode.metrics.FSDatasetMBean.getNumFailedVolumes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.metrics.FSDatasetMBean
</A></nobr><br>
<i>getNumLiveDataNodes</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNumLiveDataNodes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.getNumLiveDataNodes_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html#org.apache.hadoop.hdfs.server.namenode.FSEditLog.getOutputStreamIterator_added(org.apache.hadoop.hdfs.server.namenode.JournalStream.JournalType)" class="hiddenlink" target="rightframe"><b>getOutputStreamIterator</b>
(<code>JournalType</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPendingDeletionBlocks_added()" class="hiddenlink" target="rightframe"><b>getPendingDeletionBlocks</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPercentRemaining_added()" class="hiddenlink" target="rightframe"><b>getPercentRemaining</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPercentUsed_added()" class="hiddenlink" target="rightframe"><b>getPercentUsed</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getPreferredBlockSize_changed(java.lang.String)" class="hiddenlink" target="rightframe">getPreferredBlockSize
(<code>String</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getRandomDatanode_removed()" class="hiddenlink" target="rightframe"><strike>getRandomDatanode</strike>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getRawCapacity_changed()" class="hiddenlink" target="rightframe">getRawCapacity
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getRawUsed_changed()" class="hiddenlink" target="rightframe">getRawUsed
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.DiskStatus.html#org.apache.hadoop.hdfs.DistributedFileSystem.DiskStatus.getRemaining_removed()" class="hiddenlink" target="rightframe"><strike>getRemaining</strike>
()</A></nobr><br>
<i>getReplica</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.getReplica_added(long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.getReplica_added(long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<i>getReplicaVisibleLength</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol.html#org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol.getReplicaVisibleLength_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getReplicaVisibleLength_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.getReplicaVisibleLength_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.getReplicaVisibleLength_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.getRestoreFailedStorage_added()" class="hiddenlink" target="rightframe"><b>getRestoreFailedStorage</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getRole_added()" class="hiddenlink" target="rightframe"><b>getRole</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getRpcPort_added()" class="hiddenlink" target="rightframe"><b>getRpcPort</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getRpcServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getRpcServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getSafemode_added()" class="hiddenlink" target="rightframe"><b>getSafemode</b>
()</A></nobr><br>
<i>getServerDefaults</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.getServerDefaults_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getServerDefaults_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.getServerDefaults_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getServerDefaults_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getServiceAddress_added(org.apache.hadoop.conf.Configuration, boolean)" class="hiddenlink" target="rightframe"><b>getServiceAddress</b>
(<code>Configuration, boolean</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getServiceRpcServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getServiceRpcServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.getStats_changed()" class="hiddenlink" target="rightframe">getStats
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.getStatus_added(org.apache.hadoop.fs.Path)" class="hiddenlink" target="rightframe"><b>getStatus</b>
(<code>Path</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs_added(org.apache.hadoop.conf.Configuration, java.lang.String)" class="hiddenlink" target="rightframe"><b>getStorageDirs</b>
(<code>Configuration, String</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getStreamingAddr_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>getStreamingAddr</b>
(<code>Configuration</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getThreads_added()" class="hiddenlink" target="rightframe"><b>getThreads</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getTotal_added()" class="hiddenlink" target="rightframe"><b>getTotal</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getTotalBlocks_added()" class="hiddenlink" target="rightframe"><b>getTotalBlocks</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getTotalFiles_added()" class="hiddenlink" target="rightframe"><b>getTotalFiles</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getUsed_added()" class="hiddenlink" target="rightframe"><b>getUsed</b>
()</A></nobr><br>
<i>getVersion</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getVersion_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getVersion_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.getVolumeFailures_added()" class="hiddenlink" target="rightframe"><b>getVolumeFailures</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.getVolumeInfo_added()" class="hiddenlink" target="rightframe"><b>getVolumeInfo</b>
()</A></nobr><br>
<A NAME="H"></A>
<br><font size="+2">H</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>hasEnoughResource</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.hasEnoughResource_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.hasEnoughResource_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<i>hashCode</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DatanodeInfo.html#org.apache.hadoop.hdfs.protocol.DatanodeInfo.hashCode_changed()" class="hiddenlink" target="rightframe">type&nbsp;
()&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.DatanodeInfo
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.hashCode_changed()" class="hiddenlink" target="rightframe">type&nbsp;
()&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.html#org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.hashCode_changed()" class="hiddenlink" target="rightframe">type&nbsp;
()&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration
</A></nobr><br>
<A NAME="I"></A>
<br><font size="+2">I</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.initialize_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>initialize</b>
(<code>Configuration</code>)</A></nobr><br>
<i>initReplicaRecovery</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.initReplicaRecovery_added(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>RecoveringBlock</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.initReplicaRecovery_added(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>RecoveringBlock</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.initReplicaRecovery_added(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>RecoveringBlock</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.initReplicaRecovery_added(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>RecoveringBlock</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode_added(java.lang.String[], org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)" class="hiddenlink" target="rightframe"><b>instantiateDataNode</b>
(<code>String[], Configuration, SecureResources</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateBlock_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo)" class="hiddenlink" target="rightframe"><strike>invalidateBlock</strike>
(<code>Block, DatanodeInfo</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.is203LayoutVersion_added(int)" class="hiddenlink" target="rightframe"><b>is203LayoutVersion</b>
(<code>int</code>)</A></nobr><br>
<i>isConversionNeeded</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.isConversionNeeded_removed(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>StorageDirectory</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.common.Storage
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataStorage.html#org.apache.hadoop.hdfs.server.datanode.DataStorage.isConversionNeeded_removed(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>StorageDirectory</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataStorage
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.isConversionNeeded_removed(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>StorageDirectory</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSImage
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.isDirectory_removed(java.lang.String)" class="hiddenlink" target="rightframe"><strike>isDirectory</strike>
(<code>String</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlocks.html#org.apache.hadoop.hdfs.protocol.LocatedBlocks.isLastBlockComplete_added()" class="hiddenlink" target="rightframe"><b>isLastBlockComplete</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.isMetaFilename_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>isMetaFilename</b>
(<code>String</code>)</A></nobr><br>
<i>isPreUpgradableLayout</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.isPreUpgradableLayout_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>StorageDirectory</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.common.Storage
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataStorage.html#org.apache.hadoop.hdfs.server.datanode.DataStorage.isPreUpgradableLayout_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>StorageDirectory</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataStorage
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.isPreUpgradableLayout_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>StorageDirectory</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSImage
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.isUpgradeFinalized_added()" class="hiddenlink" target="rightframe"><b>isUpgradeFinalized</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.GetImageServlet.html#org.apache.hadoop.hdfs.server.namenode.GetImageServlet.isValidRequestor_added(java.lang.String, org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>isValidRequestor</b>
(<code>String, Configuration</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.html#org.apache.hadoop.hdfs.protocol.BlockListAsLongs.iterator_added()" class="hiddenlink" target="rightframe"><b>iterator</b>
()</A></nobr><br>
<A NAME="J"></A>
<br><font size="+2">J</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>journal</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.journal_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, int, byte[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, int, int, byte[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.journal_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, int, byte[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration, int, int, byte[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<i>journalSize</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.journalSize_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.journalSize_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<A NAME="L"></A>
<br><font size="+2">L</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.listCorruptFileBlocks_added(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe"><b>listCorruptFileBlocks</b>
(<code>String, String</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.listLocatedStatus_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.PathFilter)" class="hiddenlink" target="rightframe"><b>listLocatedStatus</b>
(<code>Path, PathFilter</code>)</A></nobr><br>
<i>listPaths</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.listPaths_removed(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>String</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.listPaths_added(java.lang.String, byte[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, byte[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.listPaths_added(java.lang.String, byte[], boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, byte[], boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.listStorageDirectories_added()" class="hiddenlink" target="rightframe"><b>listStorageDirectories</b>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>loadNamesystem</b>
(<code>Configuration</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.locatedBlocks2Locations_added(org.apache.hadoop.hdfs.protocol.LocatedBlocks)" class="hiddenlink" target="rightframe"><b>locatedBlocks2Locations</b>
(<code>LocatedBlocks</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html#org.apache.hadoop.hdfs.server.namenode.FSEditLog.logOpenFile_changed(java.lang.String, org.apache.hadoop.hdfs.server.namenode.INodeFileUnderConstruction)" class="hiddenlink" target="rightframe">logOpenFile
(<code>String, INodeFileUnderConstruction</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html#org.apache.hadoop.hdfs.server.namenode.FSEditLog.logSync_changed()" class="hiddenlink" target="rightframe">logSync
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.logUpdateMasterKey_added(org.apache.hadoop.security.token.delegation.DelegationKey)" class="hiddenlink" target="rightframe"><b>logUpdateMasterKey</b>
(<code>DelegationKey</code>)</A></nobr><br>
<A NAME="M"></A>
<br><font size="+2">M</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance_removed(java.lang.String[], org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><strike>makeInstance</strike>
(<code>String[], Configuration</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.mkdir_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)" class="hiddenlink" target="rightframe"><b>mkdir</b>
(<code>Path, FsPermission</code>)</A></nobr><br>
<i>mkdirs</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.mkdirs_changed(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, FsPermission, boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs_changed(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, FsPermission, boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs_changed(java.lang.String, org.apache.hadoop.fs.permission.PermissionStatus, boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, PermissionStatus, boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.mkdirs_changed(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, FsPermission, boolean</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.moveCurrent_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe"><b>moveCurrent</b>
(<code>StorageDirectory</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.moveLastCheckpoint_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe"><b>moveLastCheckpoint</b>
(<code>StorageDirectory</code>)</A></nobr><br>
<A NAME="N"></A>
<br><font size="+2">N</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>nextGenerationStamp</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp_removed(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.nextGenerationStamp_removed(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.numCorruptReplicas_added(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe"><b>numCorruptReplicas</b>
(<code>Block</code>)</A></nobr><br>
<i>numDeadDataNodes</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.numDeadDataNodes_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.numDeadDataNodes_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean
</A></nobr><br>
<i>numLiveDataNodes</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.numLiveDataNodes_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.html#org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean.numLiveDataNodes_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean
</A></nobr><br>
<A NAME="O"></A>
<br><font size="+2">O</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>open</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.open_added(java.lang.String, int, boolean, org.apache.hadoop.fs.FileSystem.Statistics)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, int, boolean, Statistics</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.open_added(java.lang.String, int, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, int, boolean</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.open_changed(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html#org.apache.hadoop.hdfs.server.namenode.FSEditLog.open_removed()" class="hiddenlink" target="rightframe">type&nbsp;<strike>
()</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSEditLog
</A></nobr><br>
<A NAME="P"></A>
<br><font size="+2">P</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.pickOneAddress_removed(java.lang.String)" class="hiddenlink" target="rightframe"><strike>pickOneAddress</strike>
(<code>String</code>)</A></nobr><br>
<i>primitiveCreate</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.primitiveCreate_added(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, short, long, org.apache.hadoop.util.Progressable, int, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, FsPermission, EnumSet, boolean, short, long, Progressable, int, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.primitiveCreate_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, int, short, long, org.apache.hadoop.util.Progressable, int)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path, FsPermission, EnumSet, int, short, long, Progressable, int</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<i>primitiveMkdir</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.primitiveMkdir_added(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, FsPermission</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.primitiveMkdir_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path, FsPermission</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSAdmin.html#org.apache.hadoop.hdfs.tools.DFSAdmin.printTopology_added()" class="hiddenlink" target="rightframe"><b>printTopology</b>
()</A></nobr><br>
<A NAME="R"></A>
<br><font size="+2">R</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.randomDataNode_removed()" class="hiddenlink" target="rightframe"><strike>randomDataNode</strike>
()</A></nobr><br>
<i>read</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.DatanodeInfo.html#org.apache.hadoop.hdfs.protocol.DatanodeInfo.read_added(java.io.DataInput)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>DataInput</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.DatanodeInfo
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlock.html#org.apache.hadoop.hdfs.protocol.LocatedBlock.read_added(java.io.DataInput)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>DataInput</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.LocatedBlock
</A></nobr><br>
<i>readFields</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.common.GenerationStamp.html#org.apache.hadoop.hdfs.server.common.GenerationStamp.readFields_removed(java.io.DataInput)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>DataInput</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.common.GenerationStamp
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.common.StorageInfo.html#org.apache.hadoop.hdfs.server.common.StorageInfo.readFields_added(java.io.DataInput)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>DataInput</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.common.StorageInfo
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeCommand.html#org.apache.hadoop.hdfs.server.protocol.DatanodeCommand.readFields_changed(java.io.DataInput)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>DataInput</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeCommand
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.readId_added(java.io.DataInput)" class="hiddenlink" target="rightframe"><b>readId</b>
(<code>DataInput</code>)</A></nobr><br>
<i>recoverAppend</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.recoverAppend_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.recoverAppend_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<i>recoverBlock</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol.html#org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol.recoverBlock_removed(org.apache.hadoop.hdfs.protocol.Block, boolean, org.apache.hadoop.hdfs.protocol.DatanodeInfo[])" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, boolean, DatanodeInfo[]</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock_removed(org.apache.hadoop.hdfs.protocol.Block, boolean, org.apache.hadoop.hdfs.protocol.DatanodeInfo[])" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, boolean, DatanodeInfo[]</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlocks_changed(java.util.Collection)" class="hiddenlink" target="rightframe">recoverBlocks
(<code>Collection</code>)</A></nobr><br>
<i>recoverClose</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.recoverClose_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.recoverClose_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<i>recoverLease</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.recoverLease_added(org.apache.hadoop.fs.Path)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.recoverLease_added(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.recoverLease_added(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<i>recoverRbw</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.recoverRbw_added(org.apache.hadoop.hdfs.protocol.Block, long, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.recoverRbw_added(org.apache.hadoop.hdfs.protocol.Block, long, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<i>refreshSuperUserGroupsConfiguration</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.refreshSuperUserGroupsConfiguration_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSAdmin.html#org.apache.hadoop.hdfs.tools.DFSAdmin.refreshSuperUserGroupsConfiguration_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.tools.DFSAdmin
</A></nobr><br>
<i>refreshUserToGroupsMappings</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.refreshUserToGroupsMappings_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSAdmin.html#org.apache.hadoop.hdfs.tools.DFSAdmin.refreshUserToGroupsMappings_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.tools.DFSAdmin
</A></nobr><br>
<i>register</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.register_changed(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>NamenodeRegistration</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.register_removed(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>DatanodeRegistration</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.register_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<i>registerDatanode</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.registerDatanode_added(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>DatanodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.registerDatanode_added(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>DatanodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol
</A></nobr><br>
<i>rename</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.rename_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, Rename[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.rename_changed(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.rename_added(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Options.Rename[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Path, Path, Rename[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.rename_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, Rename[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.rename_changed(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.rename_added(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, String, Rename[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo_removed(java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe"><strike>renameTo</strike>
(<code>String, String</code>)</A></nobr><br>
<i>renewDelegationToken</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.renewDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DFSClient
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.renewDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.renewDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.renewDelegationToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Token</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease_changed(java.lang.String)" class="hiddenlink" target="rightframe">renewLease
(<code>String</code>)</A></nobr><br>
<i>restoreFailedStorage</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.DistributedFileSystem.html#org.apache.hadoop.hdfs.DistributedFileSystem.restoreFailedStorage_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.DistributedFileSystem
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.restoreFailedStorage_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.restoreFailedStorage_added(java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSAdmin.html#org.apache.hadoop.hdfs.tools.DFSAdmin.restoreFaileStorage_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>restoreFaileStorage</b>
(<code>String</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog_changed()" class="hiddenlink" target="rightframe">rollEditLog
()</A></nobr><br>
<i>rollFsImage</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.rollFsImage_changed(org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>CheckpointSignature</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollFsImage_changed(org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>CheckpointSignature</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<i>run</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.html#org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.run_removed(java.lang.String[])" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>String[]</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NamenodeFsck
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.tools.DFSck.html#org.apache.hadoop.hdfs.tools.DFSck.run_changed(java.lang.String[])" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String[]</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.tools.DFSck
</A></nobr><br>
<A NAME="S"></A>
<br><font size="+2">S</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.saveCurrent_added(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)" class="hiddenlink" target="rightframe"><b>saveCurrent</b>
(<code>StorageDirectory</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.saveFSImage_removed()" class="hiddenlink" target="rightframe"><strike>saveFSImage</strike>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.saveNamespace_changed()" class="hiddenlink" target="rightframe">saveNamespace
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain_added(java.lang.String[], org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)" class="hiddenlink" target="rightframe"><b>secureMain</b>
(<code>String[], SecureResources</code>)</A></nobr><br>
<i>sendHeartbeat</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.sendHeartbeat_changed(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, long, long, long, int, int, int)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>DatanodeRegistration, long, long, long, int, int, int</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.sendHeartbeat_changed(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, long, long, long, int, int, int)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>DatanodeRegistration, long, long, long, int, int, int</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlock.html#org.apache.hadoop.hdfs.protocol.LocatedBlock.setBlockToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe"><b>setBlockToken</b>
(<code>Token</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSEditLog.html#org.apache.hadoop.hdfs.server.namenode.FSEditLog.setBufferCapacity_added(int)" class="hiddenlink" target="rightframe"><b>setBufferCapacity</b>
(<code>int</code>)</A></nobr><br>
<i>setChannelPosition</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.setChannelPosition_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, BlockWriteStreams, long, long</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.setChannelPosition_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, BlockWriteStreams, long, long</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.setHttpServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>setHttpServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.setImageDigest_added(org.apache.hadoop.io.MD5Hash)" class="hiddenlink" target="rightframe"><b>setImageDigest</b>
(<code>MD5Hash</code>)</A></nobr><br>
<i>setOwner</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.setOwner_changed(java.lang.String, java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String, String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setOwner_changed(java.lang.String, java.lang.String, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, String, String</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<i>setPermission</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.setPermission_changed(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, FsPermission</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setPermission_changed(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, FsPermission</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.setQuota_changed(java.lang.String, long, long)" class="hiddenlink" target="rightframe">setQuota
(<code>String, long, long</code>)</A></nobr><br>
<i>setReplication</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.setReplication_changed(java.lang.String, short)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, short</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setReplication_changed(java.lang.String, short)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, short</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSImage.html#org.apache.hadoop.hdfs.server.namenode.FSImage.setRestoreFailedStorage_added(boolean)" class="hiddenlink" target="rightframe"><b>setRestoreFailedStorage</b>
(<code>boolean</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.setRpcServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>setRpcServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.setRpcServiceServerAddress_added(org.apache.hadoop.conf.Configuration)" class="hiddenlink" target="rightframe"><b>setRpcServiceServerAddress</b>
(<code>Configuration</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.setServiceAddress_added(org.apache.hadoop.conf.Configuration, java.lang.String)" class="hiddenlink" target="rightframe"><b>setServiceAddress</b>
(<code>Configuration, String</code>)</A></nobr><br>
<i>setTimes</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.setTimes_changed(java.lang.String, long, long)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, long, long</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.FSNamesystem.html#org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setTimes_changed(java.lang.String, long, long)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>String, long, long</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.FSNamesystem
</A></nobr><br>
<i>startCheckpoint</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.startCheckpoint_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.startCheckpoint_added(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>NamenodeRegistration</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DFSUtil.html#org.apache.hadoop.hdfs.DFSUtil.string2Bytes_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>string2Bytes</b>
(<code>String</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Util.html#org.apache.hadoop.hdfs.server.common.Util.stringAsURI_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>stringAsURI</b>
(<code>String</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Util.html#org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs_added(java.util.Collection)" class="hiddenlink" target="rightframe"><b>stringCollectionAsURIs</b>
(<code>Collection</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.stringifyToken_added(org.apache.hadoop.security.token.Token)" class="hiddenlink" target="rightframe"><b>stringifyToken</b>
(<code>Token</code>)</A></nobr><br>
<A NAME="T"></A>
<br><font size="+2">T</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.HdfsConstants.StartupOption.html#org.apache.hadoop.hdfs.server.common.HdfsConstants.StartupOption.toNodeRole_added()" class="hiddenlink" target="rightframe"><b>toNodeRole</b>
()</A></nobr><br>
<i>toString</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlock.html#org.apache.hadoop.hdfs.protocol.LocatedBlock.toString_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.LocatedBlock
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.LocatedBlocks.html#org.apache.hadoop.hdfs.protocol.LocatedBlocks.toString_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.LocatedBlocks
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.html#org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.toString_added()" class="hiddenlink" target="rightframe">type&nbsp;<b>
()</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.totalRawCapacity_removed()" class="hiddenlink" target="rightframe"><strike>totalRawCapacity</strike>
()</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.DFSClient.html#org.apache.hadoop.hdfs.DFSClient.totalRawUsed_removed()" class="hiddenlink" target="rightframe"><strike>totalRawUsed</strike>
()</A></nobr><br>
<A NAME="U"></A>
<br><font size="+2">U</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#V"><font size="-2">V</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.unlinkBlock_added(org.apache.hadoop.hdfs.protocol.Block, int)" class="hiddenlink" target="rightframe"><b>unlinkBlock</b>
(<code>Block, int</code>)</A></nobr><br>
<i>updateBlock</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.updateBlock_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, Block, boolean</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.updateBlock_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, Block</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.updateBlock_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, Block</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.updateBlock_removed(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, Block, boolean</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol
</A></nobr><br>
<i>updateBlockForPipeline</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.updateBlockForPipeline_added(org.apache.hadoop.hdfs.protocol.Block, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.updateBlockForPipeline_added(org.apache.hadoop.hdfs.protocol.Block, java.lang.String)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, String</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<i>updatePipeline</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.protocol.ClientProtocol.html#org.apache.hadoop.hdfs.protocol.ClientProtocol.updatePipeline_added(java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeID[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, Block, Block, DatanodeID[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.protocol.ClientProtocol
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.updatePipeline_added(java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeID[])" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>String, Block, Block, DatanodeID[]</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.namenode.NameNode
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.HftpFileSystem.html#org.apache.hadoop.hdfs.HftpFileSystem.updateQuery_added(java.lang.String)" class="hiddenlink" target="rightframe"><b>updateQuery</b>
(<code>String</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.html#org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor.updateRegInfo_changed(org.apache.hadoop.hdfs.protocol.DatanodeID)" class="hiddenlink" target="rightframe">updateRegInfo
(<code>DatanodeID</code>)</A></nobr><br>
<i>updateReplicaUnderRecovery</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.DataNode.html#org.apache.hadoop.hdfs.server.datanode.DataNode.updateReplicaUnderRecovery_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.DataNode
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.updateReplicaUnderRecovery_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.updateReplicaUnderRecovery_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol.updateReplicaUnderRecovery_added(org.apache.hadoop.hdfs.protocol.Block, long, long)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>Block, long, long</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol
</A></nobr><br>
<A NAME="V"></A>
<br><font size="+2">V</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#W"><font size="-2">W</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>validateBlockMetadata</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.validateBlockMetadata_removed(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.validateBlockMetadata_removed(org.apache.hadoop.hdfs.protocol.Block)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.namenode.NameNode.html#org.apache.hadoop.hdfs.server.namenode.NameNode.verifyRequest_changed(org.apache.hadoop.hdfs.server.protocol.NodeRegistration)" class="hiddenlink" target="rightframe">verifyRequest
(<code>NodeRegistration</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.html#org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.versionRequest_added()" class="hiddenlink" target="rightframe"><b>versionRequest</b>
()</A></nobr><br>
<A NAME="W"></A>
<br><font size="+2">W</font>&nbsp;
<a href="#A"><font size="-2">A</font></a> 
<a href="#B"><font size="-2">B</font></a> 
<a href="#C"><font size="-2">C</font></a> 
<a href="#D"><font size="-2">D</font></a> 
<a href="#E"><font size="-2">E</font></a> 
<a href="#F"><font size="-2">F</font></a> 
<a href="#G"><font size="-2">G</font></a> 
<a href="#H"><font size="-2">H</font></a> 
<a href="#I"><font size="-2">I</font></a> 
<a href="#J"><font size="-2">J</font></a> 
<a href="#L"><font size="-2">L</font></a> 
<a href="#M"><font size="-2">M</font></a> 
<a href="#N"><font size="-2">N</font></a> 
<a href="#O"><font size="-2">O</font></a> 
<a href="#P"><font size="-2">P</font></a> 
<a href="#R"><font size="-2">R</font></a> 
<a href="#S"><font size="-2">S</font></a> 
<a href="#T"><font size="-2">T</font></a> 
<a href="#U"><font size="-2">U</font></a> 
<a href="#V"><font size="-2">V</font></a> 
 <a href="#topheader"><font size="-2">TOP</font></a>
<br>
<i>write</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.common.GenerationStamp.html#org.apache.hadoop.hdfs.server.common.GenerationStamp.write_removed(java.io.DataOutput)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>DataOutput</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.common.GenerationStamp
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.common.StorageInfo.html#org.apache.hadoop.hdfs.server.common.StorageInfo.write_added(java.io.DataOutput)" class="hiddenlink" target="rightframe">type&nbsp;<b>
(<code>DataOutput</code>)</b>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.common.StorageInfo
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.protocol.DatanodeCommand.html#org.apache.hadoop.hdfs.server.protocol.DatanodeCommand.write_changed(java.io.DataOutput)" class="hiddenlink" target="rightframe">type&nbsp;
(<code>DataOutput</code>)&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.protocol.DatanodeCommand
</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.server.common.Storage.html#org.apache.hadoop.hdfs.server.common.Storage.writeCorruptedData_removed(java.io.RandomAccessFile)" class="hiddenlink" target="rightframe"><strike>writeCorruptedData</strike>
(<code>RandomAccessFile</code>)</A></nobr><br>
<nobr><A HREF="org.apache.hadoop.hdfs.protocol.Block.html#org.apache.hadoop.hdfs.protocol.Block.writeId_added(java.io.DataOutput)" class="hiddenlink" target="rightframe"><b>writeId</b>
(<code>DataOutput</code>)</A></nobr><br>
<i>writeToBlock</i><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDataset.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.writeToBlock_removed(org.apache.hadoop.hdfs.protocol.Block, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, boolean</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDataset
</A></nobr><br>
&nbsp;&nbsp;<nobr><A HREF="org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.html#org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.writeToBlock_removed(org.apache.hadoop.hdfs.protocol.Block, boolean)" class="hiddenlink" target="rightframe">type&nbsp;<strike>
(<code>Block, boolean</code>)</strike>&nbsp;in&nbsp;org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface
</A></nobr><br>
</BODY>
</HTML>
